import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans, DBSCAN
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.datasets import make_blobs

# Táº£i dá»¯ liá»‡u MNIST tá»« OpenML
def data():
    st.header("MNIST Dataset")
    st.write("""
      **MNIST** lÃ  má»™t trong nhá»¯ng bá»™ dá»¯ liá»‡u ná»•i tiáº¿ng vÃ  phá»• biáº¿n nháº¥t trong cá»™ng Ä‘á»“ng há»c mÃ¡y, 
      Ä‘áº·c biá»‡t lÃ  trong cÃ¡c nghiÃªn cá»©u vá» nháº­n diá»‡n máº«u vÃ  phÃ¢n loáº¡i hÃ¬nh áº£nh.
  
      - Bá»™ dá»¯ liá»‡u bao gá»“m tá»•ng cá»™ng **70.000 áº£nh chá»¯ sá»‘ viáº¿t tay** tá»« **0** Ä‘áº¿n **9**, 
        má»—i áº£nh cÃ³ kÃ­ch thÆ°á»›c **28 x 28 pixel**.
      - Chia thÃ nh:
        - **Training set**: 60.000 áº£nh Ä‘á»ƒ huáº¥n luyá»‡n.
        - **Test set**: 10.000 áº£nh Ä‘á»ƒ kiá»ƒm tra.
      - Má»—i hÃ¬nh áº£nh lÃ  má»™t chá»¯ sá»‘ viáº¿t tay, Ä‘Æ°á»£c chuáº©n hÃ³a vÃ  chuyá»ƒn thÃ nh dáº¡ng grayscale (Ä‘en tráº¯ng).
  
      Dá»¯ liá»‡u nÃ y Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i Ä‘á»ƒ xÃ¢y dá»±ng cÃ¡c mÃ´ hÃ¬nh nháº­n diá»‡n chá»¯ sá»‘.
      """)

    st.subheader("Má»™t sá»‘ hÃ¬nh áº£nh tá»« MNIST Dataset")
    st.image("buoi4/img3.png", caption="Má»™t sá»‘ hÃ¬nh áº£nh tá»« MNIST Dataset", use_container_width=True)

    st.subheader("á»¨ng dá»¥ng thá»±c táº¿ cá»§a MNIST")
    st.write("""
      Bá»™ dá»¯ liá»‡u MNIST Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng trong nhiá»u á»©ng dá»¥ng nháº­n dáº¡ng chá»¯ sá»‘ viáº¿t tay, cháº³ng háº¡n nhÆ°:
      - Nháº­n diá»‡n sá»‘ trÃªn cÃ¡c hoÃ¡ Ä‘Æ¡n thanh toÃ¡n, biÃªn lai cá»­a hÃ ng.
      - Xá»­ lÃ½ chá»¯ sá»‘ trÃªn cÃ¡c bÆ°u kiá»‡n gá»­i qua bÆ°u Ä‘iá»‡n.
      - á»¨ng dá»¥ng trong cÃ¡c há»‡ thá»‘ng nháº­n diá»‡n tÃ i liá»‡u tá»± Ä‘á»™ng.
    """)

    st.subheader("VÃ­ dá»¥ vá» cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y vá»›i MNIST")
    st.write("""
      CÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y phá»• biáº¿n Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i bá»™ dá»¯ liá»‡u MNIST bao gá»“m:
      - **Logistic Regression**
      - **Decision Trees**
      - **K-Nearest Neighbors (KNN)**
      - **Support Vector Machines (SVM)**
      - **Convolutional Neural Networks (CNNs)**
    """)

    st.subheader("Káº¿t quáº£ cá»§a má»™t sá»‘ mÃ´ hÃ¬nh trÃªn MNIST ")
    st.write("""
      Äá»ƒ Ä‘Ã¡nh giÃ¡ hiá»‡u quáº£ cá»§a cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y vá»›i MNIST, ngÆ°á»i ta thÆ°á»ng sá»­ dá»¥ng Ä‘á»™ chÃ­nh xÃ¡c (accuracy) trÃªn táº­p test:
      
      - **Decision Tree**: 0.8574
      - **SVM (Linear)**: 0.9253
      - **SVM (poly)**: 0.9774
      - **SVM (sigmoid)**: 0.7656
      - **SVM (rbf)**: 0.9823
      
      
      
    """)

def ly_thuyet_K_means():
    
    st.title("ğŸ“Œ K-Means Clustering")

    # ğŸ”¹ Giá»›i thiá»‡u vá» K-Means
    st.markdown("""
    **K-Means Clustering** lÃ  thuáº­t toÃ¡n phÃ¢n cá»¥m **khÃ´ng giÃ¡m sÃ¡t**, giÃºp chia dá»¯ liá»‡u thÃ nh **K cá»¥m** sao cho cÃ¡c Ä‘iá»ƒm trong cÃ¹ng má»™t cá»¥m cÃ³ Ä‘áº·c trÆ°ng giá»‘ng nhau nháº¥t.  
    - ğŸ“Œ **Ã tÆ°á»Ÿng chÃ­nh**:  
        1. Chá»n ngáº«u nhiÃªn **K tÃ¢m cá»¥m (centroids)**.  
        2. GÃ¡n má»—i Ä‘iá»ƒm dá»¯ liá»‡u vÃ o cá»¥m cÃ³ tÃ¢m gáº§n nháº¥t.  
        3. Cáº­p nháº­t láº¡i tÃ¢m cá»¥m báº±ng cÃ¡ch láº¥y trung bÃ¬nh cÃ¡c Ä‘iá»ƒm trong cá»¥m.  
        4. Láº·p láº¡i quÃ¡ trÃ¬nh trÃªn cho Ä‘áº¿n khi cÃ¡c tÃ¢m cá»¥m khÃ´ng thay Ä‘á»•i hoáº·c sá»‘ vÃ²ng láº·p Ä‘áº¡t giá»›i háº¡n.  
    """)

    # ğŸ”¹ CÃ´ng thá»©c khoáº£ng cÃ¡ch Euclidean
    st.latex(r"""
    d(p, q) = \sqrt{\sum_{i=1}^{n} (p_i - q_i)^2}
    """)
    st.markdown("""
    Trong Ä‘Ã³:
    - \( p, q \) lÃ  hai Ä‘iá»ƒm trong khÃ´ng gian \( n \) chiá»u.
    - \( d(p, q) \) lÃ  khoáº£ng cÃ¡ch giá»¯a hai Ä‘iá»ƒm.
    """)

    # ğŸ”¹ Æ¯u Ä‘iá»ƒm vÃ  NhÆ°á»£c Ä‘iá»ƒm
    st.markdown("### âœ… **Æ¯u Ä‘iá»ƒm & âŒ NhÆ°á»£c Ä‘iá»ƒm**")
    st.markdown("""
    âœ… **Æ¯u Ä‘iá»ƒm:**  
    - ÄÆ¡n giáº£n, dá»… hiá»ƒu vÃ  hiá»‡u quáº£ trÃªn táº­p dá»¯ liá»‡u lá»›n.  
    - Cháº¡y nhanh vÃ¬ thuáº­t toÃ¡n cÃ³ Ä‘á»™ phá»©c táº¡p tháº¥p.  

    âŒ **NhÆ°á»£c Ä‘iá»ƒm:**  
    - Cáº§n xÃ¡c Ä‘á»‹nh sá»‘ cá»¥m \( K \) trÆ°á»›c.  
    - Nháº¡y cáº£m vá»›i giÃ¡ trá»‹ outlier vÃ  cÃ¡ch chá»n Ä‘iá»ƒm ban Ä‘áº§u.  
    """)

    def euclidean_distance(a, b):
        return np.linalg.norm(a - b, axis=1)

    # Táº¡o dá»¯ liá»‡u ngáº«u nhiÃªn
    def generate_data(n_samples, n_clusters, cluster_std):
        np.random.seed(42)
        X = []
        centers = np.random.uniform(-10, 10, size=(n_clusters, 2))  # Chá»n tÃ¢m cá»¥m ngáº«u nhiÃªn
        for c in centers:
            X.append(c + np.random.randn(n_samples // n_clusters, 2) * cluster_std)
        return np.vstack(X)

    # HÃ m khá»Ÿi táº¡o tÃ¢m cá»¥m ngáº«u nhiÃªn
    def initialize_centroids(X, k):
        np.random.seed(None)  # Chá»n ngáº«u nhiÃªn má»—i láº§n cháº¡y
        return X[np.random.choice(X.shape[0], k, replace=False)]

    # HÃ m gÃ¡n Ä‘iá»ƒm vÃ o cá»¥m gáº§n nháº¥t
    def assign_clusters(X, centroids):
        labels = np.array([np.argmin(euclidean_distance(x, centroids)) for x in X])
        return labels

    # HÃ m cáº­p nháº­t tÃ¢m cá»¥m má»›i
    def update_centroids(X, labels, k):
        new_centroids = np.array([X[labels == i].mean(axis=0) if len(X[labels == i]) > 0 else np.random.uniform(-10, 10, 2) for i in range(k)])
        return new_centroids

    # Táº¡o giao diá»‡n Streamlit
    st.title("ğŸ¯ Minh há»a thuáº­t toÃ¡n K-Means tá»«ng bÆ°á»›c")

    # Tham sá»‘ Ä‘iá»u chá»‰nh
    num_samples = st.slider("Sá»‘ Ä‘iá»ƒm dá»¯ liá»‡u", 50, 500, 200, step=10)
    num_clusters = st.slider("Sá»‘ cá»¥m (K)", 2, 10, 3)
    cluster_std = st.slider("Äá»™ rá»i ráº¡c cá»§a cá»¥m", 0.5, 3.0, 1.0)

    # NÃºt Reset Ä‘á»ƒ khá»Ÿi Ä‘á»™ng láº¡i dá»¯ liá»‡u
    if st.button("ğŸ”„ Reset"):
        st.session_state.X = generate_data(num_samples, num_clusters, cluster_std)
        st.session_state.centroids = initialize_centroids(st.session_state.X, num_clusters)
        st.session_state.iteration = 0  # Äáº¿m sá»‘ láº§n cáº­p nháº­t
        st.session_state.labels = assign_clusters(st.session_state.X, st.session_state.centroids)

    # Kiá»ƒm tra náº¿u chÆ°a cÃ³ dá»¯ liá»‡u trong session_state
    if "X" not in st.session_state:
        st.session_state.X = generate_data(num_samples, num_clusters, cluster_std)

    X = st.session_state.X  # Dá»¯ liá»‡u Ä‘iá»ƒm

    # Khá»Ÿi táº¡o hoáº·c cáº­p nháº­t tÃ¢m cá»¥m
    if "centroids" not in st.session_state:
        st.session_state.centroids = initialize_centroids(X, num_clusters)
        st.session_state.iteration = 0
        st.session_state.labels = assign_clusters(X, st.session_state.centroids)

    # NÃºt cáº­p nháº­t tá»«ng bÆ°á»›c
    if st.button("ğŸ”„ Cáº­p nháº­t vá»‹ trÃ­ tÃ¢m cá»¥m"):
        st.session_state.labels = assign_clusters(X, st.session_state.centroids)
        new_centroids = update_centroids(X, st.session_state.labels, num_clusters)
        
        # Kiá»ƒm tra xem cÃ³ thay Ä‘á»•i khÃ´ng, náº¿u khÃ´ng thÃ¬ Ä‘Ã£ há»™i tá»¥
        if np.all(new_centroids == st.session_state.centroids):
            st.warning("âš ï¸ TÃ¢m cá»¥m khÃ´ng thay Ä‘á»•i, thuáº­t toÃ¡n Ä‘Ã£ há»™i tá»¥!")
        else:
            st.session_state.centroids = new_centroids
            st.session_state.iteration += 1

    # Váº½ biá»ƒu Ä‘á»“
    fig, ax = plt.subplots(figsize=(6, 6))
    labels = st.session_state.labels
    centroids = st.session_state.centroids

    # Váº½ Ä‘iá»ƒm dá»¯ liá»‡u
    for i in range(num_clusters):
        ax.scatter(X[labels == i][:, 0], X[labels == i][:, 1], label=f"Cá»¥m {i}", alpha=0.6, edgecolors="k")

    # Váº½ tÃ¢m cá»¥m
    ax.scatter(centroids[:, 0], centroids[:, 1], s=200, c="red", marker="X", label="TÃ¢m cá»¥m")
    ax.set_title(f"Minh há»a K-Means (Láº§n cáº­p nháº­t: {st.session_state.iteration})")
    ax.legend()

    # Hiá»ƒn thá»‹ biá»ƒu Ä‘á»“
    st.pyplot(fig)


from sklearn.datasets import make_moons, make_blobs
from sklearn.cluster import DBSCAN

def ly_thuyet_DBSCAN():



# Táº¡o dá»¯ liá»‡u ngáº«u nhiÃªn
    def generate_data(n_samples, noise, dataset_type):
        if dataset_type == "Cá»¥m Gauss":
            X, _ = make_blobs(n_samples=n_samples, centers=3, cluster_std=noise, random_state=42)
        else:
            X, _ = make_moons(n_samples=n_samples, noise=noise, random_state=42)
        return X

    # HÃ m cháº¡y DBSCAN
    def run_dbscan(X, eps, min_samples):
        dbscan = DBSCAN(eps=eps, min_samples=min_samples)
        labels = dbscan.fit_predict(X)
        return labels

    # Giao diá»‡n Streamlit
    st.title("ğŸ” Minh há»a thuáº­t toÃ¡n DBSCAN")

    # TÃ¹y chá»‰nh tham sá»‘
    num_samples = st.slider("Sá»‘ Ä‘iá»ƒm dá»¯ liá»‡u", 50, 500, 200, step=10)
    noise = st.slider("Má»©c nhiá»…u", 0.05, 1.0, 0.2)
    dataset_type = st.radio("Chá»n kiá»ƒu dá»¯ liá»‡u", ["Cá»¥m Gauss", "Hai vÃ²ng trÄƒng (Moons)"])
    eps = st.slider("BÃ¡n kÃ­nh cá»¥m (eps)", 0.1, 2.0, 0.5, step=0.1)
    min_samples = st.slider("Sá»‘ Ä‘iá»ƒm tá»‘i thiá»ƒu Ä‘á»ƒ táº¡o cá»¥m (min_samples)", 2, 20, 5)

    # NÃºt Reset Ä‘á»ƒ táº¡o láº¡i dá»¯ liá»‡u
    if st.button("ğŸ”„ Reset"):
        st.session_state.X = generate_data(num_samples, noise, dataset_type)
        st.session_state.labels = np.full(num_samples, -1)  # ChÆ°a cÃ³ cá»¥m nÃ o

    # Kiá»ƒm tra dá»¯ liá»‡u trong session_state
    if "X" not in st.session_state:
        st.session_state.X = generate_data(num_samples, noise, dataset_type)
        st.session_state.labels = np.full(num_samples, -1)

    X = st.session_state.X

    # NÃºt cháº¡y DBSCAN
    if st.button("â¡ï¸ Cháº¡y DBSCAN"):
        st.session_state.labels = run_dbscan(X, eps, min_samples)

    # Váº½ biá»ƒu Ä‘á»“
    fig, ax = plt.subplots(figsize=(6, 6))
    labels = st.session_state.labels
    unique_labels = set(labels)

    # MÃ u cho cÃ¡c cá»¥m
    colors = plt.cm.get_cmap("tab10", len(unique_labels))

    for label in unique_labels:
        mask = labels == label
        color = "black" if label == -1 else colors(label)
        ax.scatter(X[mask, 0], X[mask, 1], color=color, label=f"Cá»¥m {label}" if label != -1 else "Nhiá»…u", edgecolors="k", alpha=0.7)

    ax.set_title(f"Káº¿t quáº£ DBSCAN (eps={eps}, min_samples={min_samples})")
    ax.legend()

    # Hiá»ƒn thá»‹ biá»ƒu Ä‘á»“
    st.pyplot(fig)




# HÃ m váº½ biá»ƒu Ä‘á»“
def split_data():
    
    st.title("ğŸ“Œ Chia dá»¯ liá»‡u Train/Test")

    # Äá»c dá»¯ liá»‡u
    X = np.load("buoi4/X.npy")
    y = np.load("buoi4/y.npy")
    total_samples = X.shape[0]

    # Thanh kÃ©o chá»n sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ train
    num_samples = st.slider("Chá»n sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ train:", 1000, total_samples, 10000)

    # Thanh kÃ©o chá»n tá»· lá»‡ Train/Test
    test_size = st.slider("Chá»n tá»· lá»‡ test:", 0.1, 0.5, 0.2)

    if st.button("âœ… XÃ¡c nháº­n & LÆ°u"):
        # Láº¥y sá»‘ lÆ°á»£ng áº£nh mong muá»‘n
        X_selected, y_selected = X[:num_samples], y[:num_samples]

        # Chia train/test theo tá»· lá»‡ Ä‘Ã£ chá»n
        X_train, X_test, y_train, y_test = train_test_split(X_selected, y_selected, test_size=test_size, random_state=42)

        # LÆ°u vÃ o session_state Ä‘á»ƒ sá»­ dá»¥ng sau
        st.session_state["X_train"] = X_train
        st.session_state["y_train"] = y_train
        st.session_state["X_test"] = X_test
        st.session_state["y_test"] = y_test

        st.success(f"ğŸ”¹ Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia: Train ({len(X_train)}), Test ({len(X_test)})")

    # Kiá»ƒm tra náº¿u Ä‘Ã£ lÆ°u dá»¯ liá»‡u vÃ o session_state
    if "X_train" in st.session_state:
        st.write("ğŸ“Œ Dá»¯ liá»‡u train/test Ä‘Ã£ sáºµn sÃ ng Ä‘á»ƒ sá»­ dá»¥ng!")
        
def train():
    # ğŸ“¥ **Táº£i dá»¯ liá»‡u MNIST**
    if "X_train" in st.session_state:
        X_train = st.session_state["X_train"]
        y_train = st.session_state["y_train"]
        X_test = st.session_state["X_test"]
        y_test = st.session_state["y_test"]
    else:
        st.error("âš ï¸ ChÆ°a cÃ³ dá»¯ liá»‡u! HÃ£y chia dá»¯ liá»‡u trÆ°á»›c.")
        return

    # ğŸŒŸ Chuáº©n hÃ³a dá»¯ liá»‡u
    X_train = X_train.reshape(-1, 28 * 28) / 255.0
    X_test = X_test.reshape(-1, 28 * 28) / 255.0

    st.header("âš™ï¸ Chá»n mÃ´ hÃ¬nh & Huáº¥n luyá»‡n")

    # ğŸ“Œ **Chá»n mÃ´ hÃ¬nh**
    model_choice = st.selectbox("Chá»n mÃ´ hÃ¬nh:", ["K-Means", "DBSCAN"])

    if model_choice == "K-Means":
        st.markdown("""
        - **ğŸ”¹ K-Means** lÃ  thuáº­t toÃ¡n phÃ¢n cá»¥m phá»• biáº¿n, chia dá»¯ liá»‡u thÃ nh K cá»¥m dá»±a trÃªn khoáº£ng cÃ¡ch.
        - **Tham sá»‘ cáº§n chá»n:**  
            - **n_clusters**: Sá»‘ lÆ°á»£ng cá»¥m (k).  
        """)
        
        n_clusters = st.slider("n_clusters", 2, 20, 10)
        model = KMeans(n_clusters=n_clusters, random_state=42)
    
    elif model_choice == "DBSCAN":
        st.markdown("""
        - **ğŸ› ï¸ DBSCAN (Density-Based Spatial Clustering of Applications with Noise)** lÃ  thuáº­t toÃ¡n phÃ¢n cá»¥m dá»±a trÃªn máº­t Ä‘á»™.
        - **Tham sá»‘ cáº§n chá»n:**  
            - **eps**: BÃ¡n kÃ­nh lÃ¢n cáº­n.  
            - **min_samples**: Sá»‘ lÆ°á»£ng Ä‘iá»ƒm tá»‘i thiá»ƒu Ä‘á»ƒ táº¡o cá»¥m.  
        """)
        eps = st.slider("eps", 0.1, 10.0, 0.5)
        min_samples = st.slider("min_samples", 2, 20, 5)
        model = DBSCAN(eps=eps, min_samples=min_samples)

    if st.button("Huáº¥n luyá»‡n mÃ´ hÃ¬nh"):
        model.fit(X_train)
        labels = model.labels_
        st.success("âœ… Huáº¥n luyá»‡n thÃ nh cÃ´ng!")

        # LÆ°u mÃ´ hÃ¬nh vÃ o session_state dÆ°á»›i dáº¡ng danh sÃ¡ch náº¿u chÆ°a cÃ³
        if "models" not in st.session_state:
            st.session_state["models"] = []

        model_name = model_choice.lower().replace(" ", "_")

        existing_model = next((item for item in st.session_state["models"] if item["name"] == model_name), None)
        
        if existing_model:
            count = 1
            new_model_name = f"{model_name}_{count}"
            while any(item["name"] == new_model_name for item in st.session_state["models"]):
                count += 1
                new_model_name = f"{model_name}_{count}"
            model_name = new_model_name
            st.warning(f"âš ï¸ MÃ´ hÃ¬nh Ä‘Æ°á»£c lÆ°u vá»›i tÃªn lÃ : {model_name}")

        st.session_state["models"].append({"name": model_name, "model": model})
        st.write(f"ğŸ”¹ MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vá»›i tÃªn: {model_name}")
        st.write(f"Tá»•ng sá»‘ mÃ´ hÃ¬nh hiá»‡n táº¡i: {len(st.session_state['models'])}")

        st.write("ğŸ“‹ Danh sÃ¡ch cÃ¡c mÃ´ hÃ¬nh Ä‘Ã£ lÆ°u:")
        model_names = [model["name"] for model in st.session_state["models"]]
        st.write(", ".join(model_names))
        


def ClusteringAlgorithms():
  

    st.title("ğŸ–Šï¸ MNIST Classification App")

    ### **Pháº§n 1: Hiá»ƒn thá»‹ dá»¯ liá»‡u MNIST**
    
    ### **Pháº§n 2: TrÃ¬nh bÃ y lÃ½ thuyáº¿t vá» Decision Tree & SVM*
    
    # 1ï¸âƒ£ Pháº§n giá»›i thiá»‡u
    
    # === Sidebar Ä‘á»ƒ chá»n trang ===
    # === Táº¡o Tabs ===
    tab1, tab2, tab3, tab4,tab5 = st.tabs(["ğŸ“˜ LÃ½ thuyáº¿t K-means", "ğŸ“˜ LÃ½ thuyáº¿t DBSCAN", "ğŸ“˜ Data" ,"âš™ï¸ Huáº¥n luyá»‡n", "ğŸ”¢ Dá»± Ä‘oÃ¡n"])

    with tab1:
        ly_thuyet_K_means()

    with tab2:
        ly_thuyet_DBSCAN()
    
    with tab3:
        data()
        
    with tab4:
       # plot_tree_metrics()
        
        
        
        split_data()
        train()
        
    
    with tab5:
        pass  





            
if __name__ == "__main__":
    ClusteringAlgorithms()