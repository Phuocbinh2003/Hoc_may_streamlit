import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans, DBSCAN
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.datasets import make_blobs

# Táº£i dá»¯ liá»‡u MNIST tá»« OpenML
def data():
    st.header("MNIST Dataset")
    st.write("""
      **MNIST** lÃ  má»™t trong nhá»¯ng bá»™ dá»¯ liá»‡u ná»•i tiáº¿ng vÃ  phá»• biáº¿n nháº¥t trong cá»™ng Ä‘á»“ng há»c mÃ¡y, 
      Ä‘áº·c biá»‡t lÃ  trong cÃ¡c nghiÃªn cá»©u vá» nháº­n diá»‡n máº«u vÃ  phÃ¢n loáº¡i hÃ¬nh áº£nh.
  
      - Bá»™ dá»¯ liá»‡u bao gá»“m tá»•ng cá»™ng **70.000 áº£nh chá»¯ sá»‘ viáº¿t tay** tá»« **0** Ä‘áº¿n **9**, 
        má»—i áº£nh cÃ³ kÃ­ch thÆ°á»›c **28 x 28 pixel**.
      - Chia thÃ nh:
        - **Training set**: 60.000 áº£nh Ä‘á»ƒ huáº¥n luyá»‡n.
        - **Test set**: 10.000 áº£nh Ä‘á»ƒ kiá»ƒm tra.
      - Má»—i hÃ¬nh áº£nh lÃ  má»™t chá»¯ sá»‘ viáº¿t tay, Ä‘Æ°á»£c chuáº©n hÃ³a vÃ  chuyá»ƒn thÃ nh dáº¡ng grayscale (Ä‘en tráº¯ng).
  
      Dá»¯ liá»‡u nÃ y Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i Ä‘á»ƒ xÃ¢y dá»±ng cÃ¡c mÃ´ hÃ¬nh nháº­n diá»‡n chá»¯ sá»‘.
      """)

    st.subheader("Má»™t sá»‘ hÃ¬nh áº£nh tá»« MNIST Dataset")
    st.image("buoi4/img3.png", caption="Má»™t sá»‘ hÃ¬nh áº£nh tá»« MNIST Dataset", use_container_width=True)

    st.subheader("á»¨ng dá»¥ng thá»±c táº¿ cá»§a MNIST")
    st.write("""
      Bá»™ dá»¯ liá»‡u MNIST Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng trong nhiá»u á»©ng dá»¥ng nháº­n dáº¡ng chá»¯ sá»‘ viáº¿t tay, cháº³ng háº¡n nhÆ°:
      - Nháº­n diá»‡n sá»‘ trÃªn cÃ¡c hoÃ¡ Ä‘Æ¡n thanh toÃ¡n, biÃªn lai cá»­a hÃ ng.
      - Xá»­ lÃ½ chá»¯ sá»‘ trÃªn cÃ¡c bÆ°u kiá»‡n gá»­i qua bÆ°u Ä‘iá»‡n.
      - á»¨ng dá»¥ng trong cÃ¡c há»‡ thá»‘ng nháº­n diá»‡n tÃ i liá»‡u tá»± Ä‘á»™ng.
    """)

    st.subheader("VÃ­ dá»¥ vá» cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y vá»›i MNIST")
    st.write("""
      CÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y phá»• biáº¿n Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i bá»™ dá»¯ liá»‡u MNIST bao gá»“m:
      - **Logistic Regression**
      - **Decision Trees**
      - **K-Nearest Neighbors (KNN)**
      - **Support Vector Machines (SVM)**
      - **Convolutional Neural Networks (CNNs)**
    """)

    st.subheader("Káº¿t quáº£ cá»§a má»™t sá»‘ mÃ´ hÃ¬nh trÃªn MNIST ")
    st.write("""
      Äá»ƒ Ä‘Ã¡nh giÃ¡ hiá»‡u quáº£ cá»§a cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y vá»›i MNIST, ngÆ°á»i ta thÆ°á»ng sá»­ dá»¥ng Ä‘á»™ chÃ­nh xÃ¡c (accuracy) trÃªn táº­p test:
      
      - **Decision Tree**: 0.8574
      - **SVM (Linear)**: 0.9253
      - **SVM (poly)**: 0.9774
      - **SVM (sigmoid)**: 0.7656
      - **SVM (rbf)**: 0.9823
      
      
      
    """)

def ly_thuyet_K_means():
    
    st.title("ğŸ“Œ K-Means Clustering")

    # ğŸ”¹ Giá»›i thiá»‡u vá» K-Means
    st.markdown("""
    **K-Means Clustering** lÃ  thuáº­t toÃ¡n phÃ¢n cá»¥m **khÃ´ng giÃ¡m sÃ¡t**, giÃºp chia dá»¯ liá»‡u thÃ nh **K cá»¥m** sao cho cÃ¡c Ä‘iá»ƒm trong cÃ¹ng má»™t cá»¥m cÃ³ Ä‘áº·c trÆ°ng giá»‘ng nhau nháº¥t.  
    - ğŸ“Œ **Ã tÆ°á»Ÿng chÃ­nh**:  
        1. Chá»n ngáº«u nhiÃªn **K tÃ¢m cá»¥m (centroids)**.  
        2. GÃ¡n má»—i Ä‘iá»ƒm dá»¯ liá»‡u vÃ o cá»¥m cÃ³ tÃ¢m gáº§n nháº¥t.  
        3. Cáº­p nháº­t láº¡i tÃ¢m cá»¥m báº±ng cÃ¡ch láº¥y trung bÃ¬nh cÃ¡c Ä‘iá»ƒm trong cá»¥m.  
        4. Láº·p láº¡i quÃ¡ trÃ¬nh trÃªn cho Ä‘áº¿n khi cÃ¡c tÃ¢m cá»¥m khÃ´ng thay Ä‘á»•i hoáº·c sá»‘ vÃ²ng láº·p Ä‘áº¡t giá»›i háº¡n.  
    """)

    # ğŸ”¹ CÃ´ng thá»©c khoáº£ng cÃ¡ch Euclidean
    st.latex(r"""
    d(p, q) = \sqrt{\sum_{i=1}^{n} (p_i - q_i)^2}
    """)
    st.markdown("""
    Trong Ä‘Ã³:
    - \( p, q \) lÃ  hai Ä‘iá»ƒm trong khÃ´ng gian \( n \) chiá»u.
    - \( d(p, q) \) lÃ  khoáº£ng cÃ¡ch giá»¯a hai Ä‘iá»ƒm.
    """)

    # ğŸ”¹ Æ¯u Ä‘iá»ƒm vÃ  NhÆ°á»£c Ä‘iá»ƒm
    st.markdown("### âœ… **Æ¯u Ä‘iá»ƒm & âŒ NhÆ°á»£c Ä‘iá»ƒm**")
    st.markdown("""
    âœ… **Æ¯u Ä‘iá»ƒm:**  
    - ÄÆ¡n giáº£n, dá»… hiá»ƒu vÃ  hiá»‡u quáº£ trÃªn táº­p dá»¯ liá»‡u lá»›n.  
    - Cháº¡y nhanh vÃ¬ thuáº­t toÃ¡n cÃ³ Ä‘á»™ phá»©c táº¡p tháº¥p.  

    âŒ **NhÆ°á»£c Ä‘iá»ƒm:**  
    - Cáº§n xÃ¡c Ä‘á»‹nh sá»‘ cá»¥m \( K \) trÆ°á»›c.  
    - Nháº¡y cáº£m vá»›i giÃ¡ trá»‹ outlier vÃ  cÃ¡ch chá»n Ä‘iá»ƒm ban Ä‘áº§u.  
    """)

    def euclidean_distance(a, b):
        return np.linalg.norm(a - b, axis=1)

    # Táº¡o dá»¯ liá»‡u ngáº«u nhiÃªn
    def generate_data(n_samples, n_clusters, cluster_std):
        np.random.seed(42)
        X = []
        centers = np.random.uniform(-10, 10, size=(n_clusters, 2))  # Chá»n tÃ¢m cá»¥m ngáº«u nhiÃªn
        for c in centers:
            X.append(c + np.random.randn(n_samples // n_clusters, 2) * cluster_std)
        return np.vstack(X)

    # HÃ m khá»Ÿi táº¡o tÃ¢m cá»¥m ngáº«u nhiÃªn
    def initialize_centroids(X, k):
        np.random.seed(None)  # Chá»n ngáº«u nhiÃªn má»—i láº§n cháº¡y
        return X[np.random.choice(X.shape[0], k, replace=False)]

    # HÃ m gÃ¡n Ä‘iá»ƒm vÃ o cá»¥m gáº§n nháº¥t
    def assign_clusters(X, centroids):
        labels = np.array([np.argmin(euclidean_distance(x, centroids)) for x in X])
        return labels

    # HÃ m cáº­p nháº­t tÃ¢m cá»¥m má»›i
    def update_centroids(X, labels, k):
        new_centroids = np.array([X[labels == i].mean(axis=0) if len(X[labels == i]) > 0 else np.random.uniform(-10, 10, 2) for i in range(k)])
        return new_centroids

    # Táº¡o giao diá»‡n Streamlit
    st.title("ğŸ¯ Minh há»a thuáº­t toÃ¡n K-Means tá»«ng bÆ°á»›c")

    # Tham sá»‘ Ä‘iá»u chá»‰nh
    num_samples_kmeans = st.slider("Sá»‘ Ä‘iá»ƒm dá»¯ liá»‡u", 50, 500, 200, step=10, key="num_samples_kmeans")
    cluster_kmeans = st.slider("Sá»‘ cá»¥m", 2, 10, 3, key="clusters_kmeans")
    spread_kmeans = st.slider("Äá»™ rá»i ráº¡c", 0.1, 2.0, 1.0, key="spread_kmeans")


    # NÃºt Reset Ä‘á»ƒ khá»Ÿi Ä‘á»™ng láº¡i dá»¯ liá»‡u
    if st.button("ğŸ”„ Reset", key="reset_kmeans"):
        st.session_state.X = generate_data(num_samples_kmeans, cluster_kmeans, spread_kmeans)
        st.session_state.centroids = initialize_centroids(st.session_state.X, cluster_kmeans)
        st.session_state.iteration = 0  # Äáº¿m sá»‘ láº§n cáº­p nháº­t
        st.session_state.labels = assign_clusters(st.session_state.X, st.session_state.centroids)

    # Kiá»ƒm tra náº¿u chÆ°a cÃ³ dá»¯ liá»‡u trong session_state
    if "X" not in st.session_state:
        st.session_state.X = generate_data(num_samples_kmeans, cluster_kmeans, spread_kmeans)

    X = st.session_state.X  # Dá»¯ liá»‡u Ä‘iá»ƒm

    # Khá»Ÿi táº¡o hoáº·c cáº­p nháº­t tÃ¢m cá»¥m
    if "centroids" not in st.session_state:
        st.session_state.centroids = initialize_centroids(X, cluster_kmeans)
        st.session_state.iteration = 0
        st.session_state.labels = assign_clusters(X, st.session_state.centroids)

    # NÃºt cáº­p nháº­t tá»«ng bÆ°á»›c
    if st.button("ğŸ”„ Cáº­p nháº­t vá»‹ trÃ­ tÃ¢m cá»¥m"):
        st.session_state.labels = assign_clusters(X, st.session_state.centroids)
        new_centroids = update_centroids(X, st.session_state.labels, cluster_kmeans)
        
        # Kiá»ƒm tra xem cÃ³ thay Ä‘á»•i khÃ´ng, náº¿u khÃ´ng thÃ¬ Ä‘Ã£ há»™i tá»¥
        if np.all(new_centroids == st.session_state.centroids):
            st.warning("âš ï¸ TÃ¢m cá»¥m khÃ´ng thay Ä‘á»•i, thuáº­t toÃ¡n Ä‘Ã£ há»™i tá»¥!")
        else:
            st.session_state.centroids = new_centroids
            st.session_state.iteration += 1

    # Váº½ biá»ƒu Ä‘á»“
    fig, ax = plt.subplots(figsize=(6, 6))
    labels = st.session_state.labels
    centroids = st.session_state.centroids

    # Váº½ Ä‘iá»ƒm dá»¯ liá»‡u
    for i in range(cluster_kmeans):
        ax.scatter(X[labels == i][:, 0], X[labels == i][:, 1], label=f"Cá»¥m {i}", alpha=0.6, edgecolors="k")

    # Váº½ tÃ¢m cá»¥m
    ax.scatter(centroids[:, 0], centroids[:, 1], s=200, c="red", marker="X", label="TÃ¢m cá»¥m")
    ax.set_title(f"Minh há»a K-Means (Láº§n cáº­p nháº­t: {st.session_state.iteration})")
    ax.legend()

    # Hiá»ƒn thá»‹ biá»ƒu Ä‘á»“
    st.pyplot(fig)


from sklearn.datasets import make_moons, make_blobs
from sklearn.cluster import DBSCAN

def ly_thuyet_DBSCAN():



# Táº¡o dá»¯ liá»‡u ngáº«u nhiÃªn
    def generate_data(n_samples, noise, dataset_type):
        if dataset_type == "Cá»¥m Gauss":
            X, _ = make_blobs(n_samples=n_samples, centers=3, cluster_std=noise, random_state=42)
        else:
            X, _ = make_moons(n_samples=n_samples, noise=noise, random_state=42)
        return X

    # HÃ m cháº¡y DBSCAN
    def run_dbscan(X, eps, min_samples):
        dbscan = DBSCAN(eps=eps, min_samples=min_samples)
        labels = dbscan.fit_predict(X)
        return labels

    # Giao diá»‡n Streamlit
    st.title("ğŸ” Minh há»a thuáº­t toÃ¡n DBSCAN")

    # TÃ¹y chá»‰nh tham sá»‘
    # TÃ¹y chá»‰nh tham sá»‘ vá»›i key Ä‘á»ƒ trÃ¡nh lá»—i trÃ¹ng ID
    
    dataset_type = st.radio("Chá»n kiá»ƒu dá»¯ liá»‡u", ["Cá»¥m Gauss", "Hai vÃ²ng trÄƒng (Moons)"], key="dataset_type")
    

    num_samples_dbscan = st.slider("Sá»‘ Ä‘iá»ƒm dá»¯ liá»‡u", 50, 500, 200, step=10, key="num_samples_dbscan")
    noise_dbscan = st.slider("Má»©c nhiá»…u", 0.05, 1.0, 0.2, key="noise_dbscan")
    eps_dbscan = st.slider("BÃ¡n kÃ­nh cá»¥m (eps)", 0.1, 2.0, 0.5, step=0.1, key="eps_dbscan")
    min_samples_dbscan = st.slider("Sá»‘ Ä‘iá»ƒm tá»‘i thiá»ƒu Ä‘á»ƒ táº¡o cá»¥m", 2, 20, 5, key="min_samples_dbscan")

    # NÃºt Reset Ä‘á»ƒ táº¡o láº¡i dá»¯ liá»‡u
    if st.button("ğŸ”„ Reset", key="reset_dbscan"):
        st.session_state.X = generate_data(num_samples_dbscan, noise_dbscan, dataset_type)
        st.session_state.labels = np.full(num_samples_dbscan, -1)  # ChÆ°a cÃ³ cá»¥m nÃ o

    # Kiá»ƒm tra dá»¯ liá»‡u trong session_state
    if "X" not in st.session_state:
        st.session_state.X = generate_data(num_samples_dbscan, noise_dbscan, dataset_type)
        st.session_state.labels = np.full(num_samples_dbscan, -1)

    X = st.session_state.X

    # NÃºt cháº¡y DBSCAN
    if st.button("â¡ï¸ Cháº¡y DBSCAN"):
        st.session_state.labels = run_dbscan(X, eps_dbscan, min_samples_dbscan)

    # Váº½ biá»ƒu Ä‘á»“
    fig, ax = plt.subplots(figsize=(6, 6))
    labels = st.session_state.labels
    unique_labels = set(labels)

    # MÃ u cho cÃ¡c cá»¥m
    colors = plt.cm.get_cmap("tab10", len(unique_labels))

    for label in unique_labels:
        mask = labels == label
        color = "black" if label == -1 else colors(label)
        ax.scatter(X[mask, 0], X[mask, 1], color=color, label=f"Cá»¥m {label}" if label != -1 else "Nhiá»…u", edgecolors="k", alpha=0.7)

    ax.set_title(f"Káº¿t quáº£ DBSCAN (eps={eps_dbscan}, min_samples={min_samples_dbscan})")
    ax.legend()

    # Hiá»ƒn thá»‹ biá»ƒu Ä‘á»“
    st.pyplot(fig)




# HÃ m váº½ biá»ƒu Ä‘á»“
def split_data():
    
    st.title("ğŸ“Œ Chia dá»¯ liá»‡u Train/Test")

    # Äá»c dá»¯ liá»‡u
    X = np.load("buoi4/X.npy")
    y = np.load("buoi4/y.npy")
    total_samples = X.shape[0]

    # Thanh kÃ©o chá»n sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ train
    num_samples = st.slider("Chá»n sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ train:", 1000, total_samples, 10000)

    # Thanh kÃ©o chá»n tá»· lá»‡ Train/Test
    test_size = st.slider("Chá»n tá»· lá»‡ test:", 0.1, 0.5, 0.2)

    if st.button("âœ… XÃ¡c nháº­n & LÆ°u"):
        # Láº¥y sá»‘ lÆ°á»£ng áº£nh mong muá»‘n
        X_selected, y_selected = X[:num_samples], y[:num_samples]

        # Chia train/test theo tá»· lá»‡ Ä‘Ã£ chá»n
        X_train, X_test, y_train, y_test = train_test_split(X_selected, y_selected, test_size=test_size, random_state=42)

        # LÆ°u vÃ o session_state Ä‘á»ƒ sá»­ dá»¥ng sau
        st.session_state["X_train"] = X_train
        st.session_state["y_train"] = y_train
        st.session_state["X_test"] = X_test
        st.session_state["y_test"] = y_test

        st.success(f"ğŸ”¹ Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia: Train ({len(X_train)}), Test ({len(X_test)})")

    # Kiá»ƒm tra náº¿u Ä‘Ã£ lÆ°u dá»¯ liá»‡u vÃ o session_state
    if "X_train" in st.session_state:
        st.write("ğŸ“Œ Dá»¯ liá»‡u train/test Ä‘Ã£ sáºµn sÃ ng Ä‘á»ƒ sá»­ dá»¥ng!")
        
import streamlit as st
import numpy as np
from tensorflow.keras.datasets import mnist
from sklearn.cluster import KMeans, DBSCAN
from sklearn.decomposition import PCA

# ğŸš€ **Load dá»¯ liá»‡u MNIST**


def train():
    # ğŸ“¥ **Táº£i dá»¯ liá»‡u MNIST tá»« session_state**
    if "X_train" in st.session_state:
        X_train = st.session_state["X_train"]
        y_train = st.session_state["y_train"]
        
        X_test=st.session_state["X_test"]
        y_test=st.session_state["y_test"]

    # ğŸŒŸ **Chuáº©n hÃ³a dá»¯ liá»‡u**
    X_train = X_train.reshape(-1, 28 * 28) / 255.0

    st.header("âš™ï¸ Chá»n mÃ´ hÃ¬nh & Huáº¥n luyá»‡n")

    # ğŸ“Œ **Chá»n mÃ´ hÃ¬nh**
    model_choice = st.selectbox("Chá»n mÃ´ hÃ¬nh:", ["K-Means", "DBSCAN"])

    if model_choice == "K-Means":
        st.markdown("""**ğŸ”¹ K-Means**: Thuáº­t toÃ¡n phÃ¢n cá»¥m chia dá»¯ liá»‡u thÃ nh K nhÃ³m dá»±a trÃªn khoáº£ng cÃ¡ch.""")

        n_clusters = st.slider("ğŸ”¢ Chá»n sá»‘ cá»¥m (K):", 2, 20, 10)

        # ğŸ“‰ Giáº£m chiá»u dá»¯ liá»‡u báº±ng PCA trÆ°á»›c khi huáº¥n luyá»‡n
        pca = PCA(n_components=2)
        X_train_pca = pca.fit_transform(X_train)

        model = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)

    elif model_choice == "DBSCAN":
        st.markdown("""**ğŸ› ï¸ DBSCAN**: Thuáº­t toÃ¡n phÃ¢n cá»¥m dá»±a trÃªn máº­t Ä‘á»™.""")

        eps = st.slider("ğŸ“ BÃ¡n kÃ­nh lÃ¢n cáº­n (eps):", 0.1, 10.0, 0.5)
        min_samples = st.slider("ğŸ‘¥ Sá»‘ Ä‘iá»ƒm tá»‘i thiá»ƒu trong cá»¥m:", 2, 20, 5)

        # ğŸ“‰ Giáº£m chiá»u dá»¯ liá»‡u báº±ng PCA trÆ°á»›c khi huáº¥n luyá»‡n
        pca = PCA(n_components=2)
        X_train_pca = pca.fit_transform(X_train)

        model = DBSCAN(eps=eps, min_samples=min_samples)

    if st.button("ğŸš€ Huáº¥n luyá»‡n mÃ´ hÃ¬nh"):
        model.fit(X_train_pca)

        st.success("âœ… Huáº¥n luyá»‡n thÃ nh cÃ´ng!")

        # ğŸ” LÆ°u mÃ´ hÃ¬nh vÃ o session_state
        if "models" not in st.session_state:
            st.session_state["models"] = []

        model_name = model_choice.lower().replace(" ", "_")

        # Kiá»ƒm tra tÃªn Ä‘á»ƒ trÃ¡nh trÃ¹ng láº·p
        count = 1
        new_model_name = model_name
        while any(m["name"] == new_model_name for m in st.session_state["models"]):
            new_model_name = f"{model_name}_{count}"
            count += 1

        st.session_state["models"].append({"name": new_model_name, "model": model})

        st.write(f"ğŸ”¹ **MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vá»›i tÃªn:** `{new_model_name}`")
        st.write(f"ğŸ“‹ **Danh sÃ¡ch cÃ¡c mÃ´ hÃ¬nh:** {[m['name'] for m in st.session_state['models']]}")


import streamlit as st
import numpy as np
import random
from sklearn.cluster import KMeans, DBSCAN
import matplotlib.pyplot as plt
from streamlit_drawable_canvas import st_canvas
from PIL import Image, ImageOps

def preprocess_canvas_image(canvas_result):
    if canvas_result.image_data is not None:
        img = Image.fromarray(canvas_result.image_data[:, :, 0].astype(np.uint8))
        img = img.resize((28, 28)).convert("L")  # Resize vÃ  chuyá»ƒn thÃ nh grayscale
        img = np.array(img, dtype=np.float32) / 255.0  # Chuáº©n hÃ³a vá» [0, 1]
        return img.reshape(1, -1)  # Chuyá»ƒn thÃ nh vector 1D
    return None
def du_doan():
    st.header("âœï¸ Váº½ dá»¯ liá»‡u Ä‘á»ƒ dá»± Ä‘oÃ¡n cá»¥m")

    # Kiá»ƒm tra náº¿u chÆ°a cÃ³ danh sÃ¡ch mÃ´ hÃ¬nh trong session_state thÃ¬ khá»Ÿi táº¡o
    if "models" not in st.session_state:
        st.session_state["models"] = []

    # Láº¥y danh sÃ¡ch mÃ´ hÃ¬nh Ä‘Ã£ lÆ°u
    model_names = [model["name"] for model in st.session_state["models"]]

    # ğŸ“Œ Chá»n mÃ´ hÃ¬nh
    if model_names:
        model_option = st.selectbox("ğŸ” Chá»n mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n:", model_names)
        model = next(model["model"] for model in st.session_state["models"] if model["name"] == model_option)
    else:
        st.warning("âš ï¸ KhÃ´ng cÃ³ mÃ´ hÃ¬nh nÃ o Ä‘Æ°á»£c lÆ°u! HÃ£y train trÆ°á»›c.")
        return

    # ğŸ†• Cáº­p nháº­t key cho canvas khi nháº¥n "Táº£i láº¡i"
    if "key_value" not in st.session_state:
        st.session_state.key_value = str(random.randint(0, 1000000))  

    if st.button("ğŸ”„ Táº£i láº¡i"):
        st.session_state.key_value = str(random.randint(0, 1000000))  
        st.rerun()

    # âœï¸ Váº½ dá»¯ liá»‡u
    canvas_result = st_canvas(
        fill_color="black",
        stroke_width=10,
        stroke_color="white",
        background_color="black",
        height=150,
        width=150,
        drawing_mode="freedraw",
        key=st.session_state.key_value,
        update_streamlit=True
    )

    if st.button("Dá»± Ä‘oÃ¡n sá»‘"):
        img = preprocess_canvas_image(canvas_result)

        if img is not None:
            # Hiá»ƒn thá»‹ áº£nh sau xá»­ lÃ½
            st.image(Image.fromarray((img.reshape(28, 28) * 255).astype(np.uint8)), caption="áº¢nh sau xá»­ lÃ½", width=100)

            # Dá»± Ä‘oÃ¡n
            prediction = model.predict(img)
            predicted_label = np.argmax(prediction)

            st.subheader(f"ğŸ”¢ Dá»± Ä‘oÃ¡n: {predicted_label}")
        else:
            st.error("âš ï¸ HÃ£y váº½ má»™t sá»‘ trÆ°á»›c khi báº¥m Dá»± Ä‘oÃ¡n!")



def ClusteringAlgorithms():
  

    st.title("ğŸ–Šï¸ MNIST Classification App")

    ### **Pháº§n 1: Hiá»ƒn thá»‹ dá»¯ liá»‡u MNIST**
    
    ### **Pháº§n 2: TrÃ¬nh bÃ y lÃ½ thuyáº¿t vá» Decision Tree & SVM*
    
    # 1ï¸âƒ£ Pháº§n giá»›i thiá»‡
    
    # === Sidebar Ä‘á»ƒ chá»n trang ===
    # === Táº¡o Tabs ===
    tab1, tab2, tab3, tab4,tab5 = st.tabs(["ğŸ“˜ LÃ½ thuyáº¿t K-means", "ğŸ“˜ LÃ½ thuyáº¿t DBSCAN", "ğŸ“˜ Data" ,"âš™ï¸ Huáº¥n luyá»‡n", "ğŸ”¢ Dá»± Ä‘oÃ¡n"])

    with tab1:
        ly_thuyet_K_means()

    with tab2:
        ly_thuyet_DBSCAN()
    
    with tab3:
        data()
        
    with tab4:
       # plot_tree_metrics()
        
        
        
        split_data()
        train()
        
    
    with tab5:
        du_doan() 





            
if __name__ == "__main__":
    ClusteringAlgorithms()