import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
import mlflow
import mlflow.sklearn
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from streamlit_drawable_canvas import st_canvas
from PIL import Image, ImageOps


# Khá»Ÿi táº¡o MLflow
# mlflow.set_tracking_uri("sqlite:///mlruns.db")  # LÆ°u trá»¯ local
# mlflow.set_experiment("MNIST Classification")

# Load dá»¯ liá»‡u MNIST
def ly_thuyet_Decision_tree():
    st.header("ğŸ“– LÃ½ thuyáº¿t vá» Decision Tree")

    # 1ï¸âƒ£ Giá»›i thiá»‡u vá» Decision Tree
    st.subheader("1ï¸âƒ£ Giá»›i thiá»‡u vá» Decision Tree")
    st.write("""
    - **Decision Tree** hoáº¡t Ä‘á»™ng báº±ng cÃ¡ch chia nhá» dá»¯ liá»‡u theo Ä‘iá»u kiá»‡n Ä‘á»ƒ phÃ¢n loáº¡i chÃ­nh xÃ¡c.
    - Má»—i nhÃ¡nh trong cÃ¢y lÃ  má»™t cÃ¢u há»i "CÃ³/KhÃ´ng" dá»±a trÃªn Ä‘áº·c trÆ°ng dá»¯ liá»‡u.
    - MÃ´ hÃ¬nh nÃ y dá»… hiá»ƒu vÃ  trá»±c quan nhÆ°ng cÃ³ thá»ƒ bá»‹ **overfitting** náº¿u khÃ´ng giá»›i háº¡n Ä‘á»™ sÃ¢u.
    """)

    # Hiá»ƒn thá»‹ áº£nh minh há»a Decision Tree
    st.image("buoi4/img1.png", caption="VÃ­ dá»¥ vá» cÃ¡ch Decision Tree phÃ¢n chia dá»¯ liá»‡u", use_column_width=True)

    st.write("""
    ### ğŸ” CÃ¡ch Decision Tree hoáº¡t Ä‘á»™ng vá»›i MNIST:
    - Má»—i áº£nh trong MNIST cÃ³ kÃ­ch thÆ°á»›c **28Ã—28 pixels**, má»—i pixel cÃ³ thá»ƒ xem lÃ  má»™t **Ä‘áº·c trÆ°ng (feature)**.
    - MÃ´ hÃ¬nh sáº½ quyáº¿t Ä‘á»‹nh phÃ¢n tÃ¡ch dá»¯ liá»‡u báº±ng cÃ¡ch **chá»n nhá»¯ng pixels quan trá»ng nháº¥t** Ä‘á»ƒ táº¡o nhÃ¡nh.
    - VÃ­ dá»¥, Ä‘á»ƒ phÃ¢n biá»‡t chá»¯ sá»‘ **0** vÃ  **1**, Decision Tree cÃ³ thá»ƒ kiá»ƒm tra:
        - Pixel á»Ÿ giá»¯a cÃ³ sÃ¡ng khÃ´ng?
        - Pixel dá»c hai bÃªn cÃ³ sÃ¡ng khÃ´ng?
    - Dá»±a trÃªn cÃ¢u tráº£ lá»i, mÃ´ hÃ¬nh sáº½ tiáº¿p tá»¥c chia nhá» táº­p dá»¯ liá»‡u.
    """)

    # 2ï¸âƒ£ CÃ´ng thá»©c toÃ¡n há»
    st.subheader("2ï¸âƒ£ CÃ¡c bÆ°á»›c tÃ­nh toÃ¡n trong Decision Tree")

    st.markdown(r"""
    ### ğŸ“Œ **CÃ´ng thá»©c chÃ­nh**
    - **Entropy (Äá»™ há»—n loáº¡n cá»§a dá»¯ liá»‡u)**:
    $$
    H(S) = - \sum_{i=1}^{c} p_i \log_2 p_i
    $$
    â†’ **Äo lÆ°á»ng má»©c Ä‘á»™ há»—n loáº¡n cá»§a táº­p dá»¯ liá»‡u**. Náº¿u dá»¯ liá»‡u hoÃ n toÃ n Ä‘á»“ng nháº¥t, Entropy = 0. Náº¿u dá»¯ liá»‡u Ä‘Æ°á»£c phÃ¢n bá»‘ Ä‘á»u giá»¯a cÃ¡c lá»›p, Entropy Ä‘áº¡t giÃ¡ trá»‹ lá»›n nháº¥t.

    **Trong Ä‘Ã³:**  
    - \( c \) : sá»‘ lÆ°á»£ng lá»›p trong táº­p dá»¯ liá»‡u.  
    - \( $$p_i$$ \) : xÃ¡c suáº¥t xuáº¥t hiá»‡n cá»§a lá»›p \( i \), Ä‘Æ°á»£c tÃ­nh báº±ng tá»· lá»‡ sá»‘ máº«u cá»§a lá»›p \( i \) trÃªn tá»•ng sá»‘ máº«u.

    - **Information Gain (Lá»£i Ã­ch thÃ´ng tin sau khi chia tÃ¡ch)**:
    $$
    IG = H(S) - \sum_{j=1}^{k} \frac{|S_j|}{|S|} H(S_j)
    $$
    â†’ **Äo lÆ°á»ng má»©c Ä‘á»™ giáº£m Entropy khi chia táº­p dá»¯ liá»‡u** theo má»™t thuá»™c tÃ­nh nÃ o Ä‘Ã³.  
    - Náº¿u **IG cao**, nghÄ©a lÃ  thuá»™c tÃ­nh Ä‘Ã³ giÃºp phÃ¢n loáº¡i tá»‘t hÆ¡n.  
    - Náº¿u **IG tháº¥p**, nghÄ©a lÃ  thuá»™c tÃ­nh Ä‘Ã³ khÃ´ng cÃ³ nhiá»u Ã½ nghÄ©a Ä‘á»ƒ phÃ¢n tÃ¡ch dá»¯ liá»‡u.

    **Trong Ä‘Ã³:**  
    - \( S \) : táº­p dá»¯ liá»‡u ban Ä‘áº§u.  
    - \( $$S_j$$ \) : táº­p con sau khi chia theo thuá»™c tÃ­nh Ä‘ang xÃ©t.  
    - \( $$|S_j| / |S|$$ \) : tá»· lá»‡ sá»‘ lÆ°á»£ng máº«u trong táº­p con \( $$S_j$$ \) so vá»›i tá»•ng sá»‘ máº«u.  
    - \( H(S) \) : Entropy cá»§a táº­p dá»¯ liá»‡u ban Ä‘áº§u.  
    - \( $$H(S_j)$$ \) : Entropy cá»§a táº­p con \( $$S_j$$ \).

    ğŸ’¡ **CÃ¡ch Ã¡p dá»¥ng**:.
    
    1ï¸âƒ£ **TÃ­nh Entropy \( H(S) \) cá»§a táº­p dá»¯ liá»‡u ban Ä‘áº§u**.  
    2ï¸âƒ£ **TÃ­nh Entropy \( $$H(S_j)$$ \) cá»§a tá»«ng táº­p con khi chia theo tá»«ng thuá»™c tÃ­nh**.  
    3ï¸âƒ£ **TÃ­nh Information Gain cho má»—i thuá»™c tÃ­nh**.  
    4ï¸âƒ£ **Chá»n thuá»™c tÃ­nh cÃ³ Information Gain cao nháº¥t Ä‘á»ƒ chia nhÃ¡nh**.  
    5ï¸âƒ£ **Láº·p láº¡i quy trÃ¬nh trÃªn cho Ä‘áº¿n khi dá»¯ liá»‡u Ä‘Æ°á»£c phÃ¢n loáº¡i hoÃ n toÃ n**.  
    """)
    
    
    
def ly_thuyet_SVM():
    st.subheader("2ï¸âƒ£ Support Vector Machine (SVM)")

    st.write("""
    - **Support Vector Machine (SVM)** lÃ  má»™t thuáº­t toÃ¡n há»c mÃ¡y máº¡nh máº½ Ä‘á»ƒ phÃ¢n loáº¡i dá»¯ liá»‡u.
    - **Má»¥c tiÃªu chÃ­nh**: TÃ¬m má»™t **siÃªu pháº³ng (hyperplane)** tá»‘i Æ°u Ä‘á»ƒ phÃ¢n tÃ¡ch cÃ¡c lá»›p dá»¯ liá»‡u.
    - **á»¨ng dá»¥ng**: Nháº­n diá»‡n khuÃ´n máº·t, phÃ¡t hiá»‡n thÆ° rÃ¡c, phÃ¢n loáº¡i vÄƒn báº£n, v.v.
    - **Æ¯u Ä‘iá»ƒm**:
        - Hiá»‡u quáº£ trÃªn dá»¯ liá»‡u cÃ³ Ä‘á»™ nhiá»…u tháº¥p.
        - Há»— trá»£ dá»¯ liá»‡u khÃ´ng tuyáº¿n tÃ­nh báº±ng **kernel trick**.
    - **NhÆ°á»£c Ä‘iá»ƒm**:
        - Cháº­m trÃªn táº­p dá»¯ liá»‡u lá»›n do tÃ­nh toÃ¡n phá»©c táº¡p.
        - Nháº¡y cáº£m vá»›i lá»±a chá»n tham sá»‘ (C, Kernel).
    """)

    # Hiá»ƒn thá»‹ hÃ¬nh áº£nh minh há»a SV
    st.image("buoi4/img2.png", caption="SVM tÃ¬m siÃªu pháº³ng tá»‘i Æ°u Ä‘á»ƒ phÃ¢n tÃ¡ch dá»¯ liá»‡u", use_column_width=True)

    st.write("""
    ### ğŸ” **CÃ¡ch hoáº¡t Ä‘á»™ng cá»§a SVM**
    - Dá»¯ liá»‡u Ä‘Æ°á»£c biá»ƒu diá»…n trong khÃ´ng gian nhiá»u chiá»u.
    - MÃ´ hÃ¬nh tÃ¬m má»™t siÃªu pháº³ng Ä‘á»ƒ phÃ¢n tÃ¡ch dá»¯ liá»‡u sao cho khoáº£ng cÃ¡ch tá»« siÃªu pháº³ng Ä‘áº¿n cÃ¡c Ä‘iá»ƒm gáº§n nháº¥t (support vectors) lÃ  lá»›n nháº¥t.
    - Náº¿u dá»¯ liá»‡u **khÃ´ng thá»ƒ phÃ¢n tÃ¡ch tuyáº¿n tÃ­nh**, ta cÃ³ thá»ƒ:
        - **DÃ¹ng Kernel Trick** Ä‘á»ƒ Ã¡nh xáº¡ dá»¯ liá»‡u sang khÃ´ng gian cao hÆ¡n.
        - **ThÃªm soft margin** Ä‘á»ƒ cháº¥p nháº­n má»™t sá»‘ Ä‘iá»ƒm bá»‹ phÃ¢n loáº¡i sai.
    """)

    # ğŸ“Œ 2ï¸âƒ£ CÃ´ng thá»©c toÃ¡n há»c
    st.subheader("ğŸ“Œ CÃ´ng thá»©c toÃ¡n há»c")

    st.markdown(r"""
    - **HÃ m má»¥c tiÃªu cáº§n tá»‘i Æ°u**:  
    $$\min_{w, b} \frac{1}{2} ||w||^2$$  
    â†’ MÃ´ hÃ¬nh cá»‘ gáº¯ng tÃ¬m **siÃªu pháº³ng phÃ¢n cÃ¡ch** sao cho **vector trá»ng sá»‘ \( w \) cÃ³ Ä‘á»™ lá»›n nhá» nháº¥t**, giÃºp tÄƒng Ä‘á»™ tá»•ng quÃ¡t.  

    **Trong Ä‘Ã³:**  
    - \( w \) : vector trá»ng sá»‘ xÃ¡c Ä‘á»‹nh hÆ°á»›ng cá»§a siÃªu pháº³ng.  
    - \( b \) : bias (Ä‘á»™ dá»‹ch cá»§a siÃªu pháº³ng).  

    - **RÃ ng buá»™c**:  
    $$y_i (w \cdot x_i + b) \geq 1, \forall i$$  
    â†’ Má»i Ä‘iá»ƒm dá»¯ liá»‡u **pháº£i náº±m Ä‘Ãºng phÃ­a** cá»§a siÃªu pháº³ng, Ä‘áº£m báº£o phÃ¢n loáº¡i chÃ­nh xÃ¡c.  

    **Trong Ä‘Ã³:**  
    - \( $$xi$$ \) : Ä‘iá»ƒm dá»¯ liá»‡u Ä‘áº§u vÃ o.  
    - \( $$yi$$ \) : nhÃ£n cá»§a Ä‘iá»ƒm dá»¯ liá»‡u (\(+1\) hoáº·c \(-1\)).  

    - **Khoáº£ng cÃ¡ch tá»« má»™t Ä‘iá»ƒm Ä‘áº¿n siÃªu pháº³ng**:  
    $$d = \frac{|w \cdot x + b|}{||w||}$$  
    â†’ Äo **khoáº£ng cÃ¡ch vuÃ´ng gÃ³c** tá»« má»™t Ä‘iá»ƒm Ä‘áº¿n siÃªu pháº³ng, khoáº£ng cÃ¡ch cÃ ng lá»›n thÃ¬ mÃ´ hÃ¬nh cÃ ng Ä‘Ã¡ng tin cáº­y.  

    - **HÃ m máº¥t mÃ¡t vá»›i soft margin (SVM khÃ´ng tuyáº¿n tÃ­nh)**:  
    $$\min_{w, b} \frac{1}{2} ||w||^2 + C \sum_{i=1}^{n} \xi_i$$  
    â†’ Náº¿u dá»¯ liá»‡u **khÃ´ng thá»ƒ phÃ¢n tÃ¡ch hoÃ n háº£o**, cho phÃ©p má»™t sá»‘ Ä‘iá»ƒm bá»‹ phÃ¢n loáº¡i sai vá»›i **biáº¿n slack \( $$\xi_i$$ \)**.  

    **Trong Ä‘Ã³:**  
    - $$C$$ : há»‡ sá»‘ Ä‘iá»u chá»‰nh giá»¯a viá»‡c tá»‘i Æ°u hÃ³a margin vÃ  cháº¥p nháº­n lá»—i.  
    - $$\xi_i$$ : biáº¿n slack cho phÃ©p má»™t sá»‘ Ä‘iá»ƒm bá»‹ phÃ¢n loáº¡i sai.  
    """)

    st.write("""
    ğŸ’¡ **Ã nghÄ©a cá»§a cÃ´ng thá»©c:**
    - SVM tá»‘i Æ°u hÃ³a khoáº£ng cÃ¡ch giá»¯a hai lá»›p dá»¯ liá»‡u (margin).
    - Náº¿u dá»¯ liá»‡u khÃ´ng tuyáº¿n tÃ­nh, kernel trick giÃºp Ã¡nh xáº¡ dá»¯ liá»‡u lÃªn khÃ´ng gian cao hÆ¡n.
    - \( C \) lÃ  há»‡ sá»‘ Ä‘iá»u chá»‰nh giá»¯a viá»‡c tá»‘i Æ°u margin vÃ  cháº¥p nháº­n lá»—i.
    """)


# def train():
#     digits = datasets.load_digits()
#     X, y = digits.data, digits.target

#     # Chia táº­p train/test
#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
#     y_train = np.ravel(y_train)
#     y_test = np.ravel(y_test)  # Äáº£m báº£o y_test cÅ©ng cÃ³ Ä‘Ãºng dáº¡ng
#     ### **Pháº§n 3: Chá»n mÃ´ hÃ¬nh & Train**
    
    
    
    
#     st.header("âš™ï¸ Chá»n mÃ´ hÃ¬nh & Huáº¥n luyá»‡n")

#     # Lá»±a chá»n mÃ´ hÃ¬nh
#     model_choice = st.selectbox("Chá»n mÃ´ hÃ¬nh:", ["Decision Tree", "SVM"])

#     if model_choice == "Decision Tree":
#         st.markdown("""
#         - **ğŸŒ³ Decision Tree (CÃ¢y quyáº¿t Ä‘á»‹nh)** giÃºp chia dá»¯ liá»‡u thÃ nh cÃ¡c nhÃ³m báº±ng cÃ¡ch Ä‘áº·t cÃ¢u há»i nhá»‹ phÃ¢n dá»±a trÃªn Ä‘áº·c trÆ°ng.
#         - **Tham sá»‘ cáº§n chá»n:**  
#             - **max_depth**: Giá»›i háº¡n Ä‘á»™ sÃ¢u tá»‘i Ä‘a cá»§a cÃ¢y.  
#                 - **GiÃ¡ trá»‹ nhá»**: TrÃ¡nh overfitting nhÆ°ng cÃ³ thá»ƒ underfitting.  
#                 - **GiÃ¡ trá»‹ lá»›n**: CÃ¢y cÃ³ thá»ƒ há»c tá»‘t hÆ¡n nhÆ°ng dá»… bá»‹ overfitting.  
#         """)

#         max_depth = st.slider("max_depth", 1, 20, 5)
#         model = DecisionTreeClassifier(max_depth=max_depth)



#     elif model_choice == "SVM":
#         st.markdown("""
#         - **ğŸ› ï¸ SVM (Support Vector Machine)** lÃ  mÃ´ hÃ¬nh tÃ¬m siÃªu pháº³ng tá»‘t nháº¥t Ä‘á»ƒ phÃ¢n tÃ¡ch dá»¯ liá»‡u.
#         - **Tham sá»‘ cáº§n chá»n:**  
#             - **C (Regularization)**: Há»‡ sá»‘ Ä‘iá»u chá»‰nh Ä‘á»™ pháº¡t lá»—i.  
#                 - **C nhá»**: MÃ´ hÃ¬nh cÃ³ thá»ƒ bá» qua má»™t sá»‘ lá»—i nhÆ°ng tá»•ng thá»ƒ á»•n Ä‘á»‹nh hÆ¡n.  
#                 - **C lá»›n**: MÃ´ hÃ¬nh cá»‘ gáº¯ng phÃ¢n loáº¡i chÃ­nh xÃ¡c tá»«ng Ä‘iá»ƒm nhÆ°ng dá»… bá»‹ overfitting.  
#             - **Kernel**: HÃ m Ã¡nh xáº¡ dá»¯ liá»‡u lÃªn khÃ´ng gian Ä‘áº·c trÆ°ng cao hÆ¡n.  
#                 - `"linear"` â†’ MÃ´ hÃ¬nh dÃ¹ng siÃªu pháº³ng tuyáº¿n tÃ­nh Ä‘á»ƒ phÃ¢n lá»›p.  
#                 - `"rbf"` â†’ Kernel Gaussian giÃºp phÃ¢n tÃ¡ch dá»¯ liá»‡u phi tuyáº¿n tÃ­nh tá»‘t hÆ¡n.  
#                 - `"poly"` â†’ Sá»­ dá»¥ng Ä‘a thá»©c báº­c cao Ä‘á»ƒ phÃ¢n lá»›p.  
#                 - `"sigmoid"` â†’ Biáº¿n Ä‘á»•i giá»‘ng nhÆ° máº¡ng nÆ¡-ron nhÃ¢n táº¡o.  
#         """)

#         C = st.slider("C (Regularization)", 0.1, 10.0, 1.0)
#         kernel = st.selectbox("Kernel", ["linear", "rbf", "poly", "sigmoid"])
#         model = SVC(C=C, kernel=kernel)



#     if st.button("Huáº¥n luyá»‡n mÃ´ hÃ¬nh"):
#         model.fit(X_train, y_train)
#         y_pred = model.predict(X_test)
#         acc = accuracy_score(y_test, y_pred)
#         st.success(f"âœ… Äá»™ chÃ­nh xÃ¡c: {acc:.4f}")
#         st.session_state["model"] = model
        
    


import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC

def load_data():
    # Äá»c dá»¯ liá»‡u tá»« file
    X = np.load("buoi4/X.npy")
    y = np.load("buoi4/y.npy")
    return X, y
def split_data():
    
    st.title("ğŸ“Œ Chia dá»¯ liá»‡u Train/Test")

    # Äá»c dá»¯ liá»‡u
    X, y = load_data()
    total_samples = X.shape[0]

    # Thanh kÃ©o chá»n sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ train
    num_samples = st.slider("Chá»n sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ train:", 1000, total_samples, 10000)

    # Thanh kÃ©o chá»n tá»· lá»‡ Train/Test
    test_size = st.slider("Chá»n tá»· lá»‡ test:", 0.1, 0.5, 0.2)

    if st.button("âœ… XÃ¡c nháº­n & LÆ°u"):
        # Láº¥y sá»‘ lÆ°á»£ng áº£nh mong muá»‘n
        X_selected, y_selected = X[:num_samples], y[:num_samples]

        # Chia train/test theo tá»· lá»‡ Ä‘Ã£ chá»n
        X_train, X_test, y_train, y_test = train_test_split(X_selected, y_selected, test_size=test_size, random_state=42)

        # LÆ°u vÃ o session_state Ä‘á»ƒ sá»­ dá»¥ng sau
        st.session_state["X_train"] = X_train
        st.session_state["y_train"] = y_train
        st.session_state["X_test"] = X_test
        st.session_state["y_test"] = y_test

        st.success(f"ğŸ”¹ Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia: Train ({len(X_train)}), Test ({len(X_test)})")

    # Kiá»ƒm tra náº¿u Ä‘Ã£ lÆ°u dá»¯ liá»‡u vÃ o session_state
    if "X_train" in st.session_state:
        st.write("ğŸ“Œ Dá»¯ liá»‡u train/test Ä‘Ã£ sáºµn sÃ ng Ä‘á»ƒ sá»­ dá»¥ng!")
        
    
    
    
    
    
    
def train():
    # ğŸ“¥ **Táº£i dá»¯ liá»‡u MNIST**
    (X_train, y_train), (X_test, y_test) = mnist.load_data()

    # ğŸŒŸ Chuáº©n hÃ³a dá»¯ liá»‡u
    X_train = X_train.reshape(-1, 28 * 28) / 255.0  # Chuyá»ƒn vá» vector 1D vÃ  chuáº©n hÃ³a
    X_test = X_test.reshape(-1, 28 * 28) / 255.0

    st.header("âš™ï¸ Chá»n mÃ´ hÃ¬nh & Huáº¥n luyá»‡n")

    # ğŸ“Œ **Chá»n mÃ´ hÃ¬nh**
    model_choice = st.selectbox("Chá»n mÃ´ hÃ¬nh:", ["Decision Tree", "SVM"])

    if model_choice == "Decision Tree":
        max_depth = st.slider("max_depth", 1, 20, 5)
        model = DecisionTreeClassifier(max_depth=max_depth)

    elif model_choice == "SVM":
        C = st.slider("C (Regularization)", 0.1, 10.0, 1.0)
        kernel = st.selectbox("Kernel", ["linear", "rbf", "poly", "sigmoid"])
        model = SVC(C=C, kernel=kernel)

    if st.button("Huáº¥n luyá»‡n mÃ´ hÃ¬nh"):
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        acc = accuracy_score(y_test, y_pred)
        st.success(f"âœ… Äá»™ chÃ­nh xÃ¡c: {acc:.4f}")
        st.session_state["model"] = model

        # ğŸ“¸ **1. Hiá»ƒn thá»‹ má»™t sá»‘ áº£nh trong táº­p train**
        st.subheader("ğŸ“¸ Má»™t sá»‘ áº£nh tá»« táº­p train:")
        fig, axes = plt.subplots(1, 5, figsize=(10, 2))
        for i, ax in enumerate(axes):
            ax.imshow(X_train[i].reshape(28, 28), cmap="gray")  # Chuyá»ƒn vá» 28x28
            ax.set_title(f"Label: {y_train[i]}")
            ax.axis("off")
        st.pyplot(fig)

        # ğŸ“Š **2. Hiá»ƒn thá»‹ sá»‘ lÆ°á»£ng máº«u cá»§a tá»«ng nhÃ£n**
        st.subheader("ğŸ“Š PhÃ¢n bá»‘ dá»¯ liá»‡u theo nhÃ£n:")
        label_counts = pd.Series(y_train).value_counts().sort_index()
        fig, ax = plt.subplots(figsize=(8, 4))
        sns.barplot(x=label_counts.index, y=label_counts.values, palette="viridis", ax=ax)
        ax.set_xlabel("NhÃ£n (Sá»‘ tá»« 0-9)")
        ax.set_ylabel("Sá»‘ lÆ°á»£ng máº«u")
        ax.set_title("Sá»‘ lÆ°á»£ng máº«u trong táº­p train")
        st.pyplot(fig)

  
        
        
import joblib
def du_doan():
    st.header("âœï¸ Váº½ sá»‘ Ä‘á»ƒ dá»± Ä‘oÃ¡n")

    # ğŸ”¹ Danh sÃ¡ch mÃ´ hÃ¬nh máº·c Ä‘á»‹nh
    default_models = {
        "SVM Linear": "buoi4/svm_mnist_linear.joblib",
        "SVM Poly": "buoi4/svm_mnist_poly.joblib",
        "SVM Sigmoid": "buoi4/svm_mnist_sigmoid.joblib",
        "SVM RBF": "buoi4/svm_mnist_rbf.joblib",
    }

    # ğŸ”¹ Kiá»ƒm tra náº¿u cÃ³ mÃ´ hÃ¬nh train thÃªm trong session_stat
    trained_models = st.session_state.get("trained_models", {})

    # ğŸ”¹ Gá»™p danh sÃ¡ch mÃ´ hÃ¬nh
    all_models = {**default_models, **trained_models}

    # ğŸ“Œ Chá»n mÃ´ hÃ¬nh Ä‘á»ƒ dá»± Ä‘oÃ¡n
    model_option = st.selectbox("ğŸ” Chá»n mÃ´ hÃ¬nh Ä‘á»ƒ dá»± Ä‘oÃ¡n:", list(all_models.keys()))

    # ğŸ“Œ Táº£i mÃ´ hÃ¬nh Ä‘Ã£ chá»n
    def load_model(path):
        """Táº£i mÃ´ hÃ¬nh tá»« file `.joblib`"""
        return joblib.load(path)

    try:
        # Náº¿u mÃ´ hÃ¬nh cÃ³ sáºµn trong session_state thÃ¬ dÃ¹ng luÃ´n, náº¿u khÃ´ng thÃ¬ táº£i tá»« file
        model = trained_models.get(model_option, load_model(all_models[model_option]))
        st.success(f"âœ… ÄÃ£ táº£i mÃ´ hÃ¬nh: {model_option}")
    except FileNotFoundError:
        st.error(f"âš ï¸ KhÃ´ng tÃ¬m tháº¥y mÃ´ hÃ¬nh `{all_models[model_option]}`")
        st.stop()

    # âœï¸ Váº½ sá»‘ Ä‘á»ƒ dá»± Ä‘oÃ¡n
    canvas_result = st_canvas(
        fill_color="black",
        stroke_width=10,
        stroke_color="white",
        background_color="black",
        height=150,
        width=150,
        drawing_mode="freedraw",
        key="canvas"
    )

    if st.button("Dá»± Ä‘oÃ¡n sá»‘"):
        if canvas_result.image_data is not None:
            img = Image.fromarray((canvas_result.image_data[:, :, 0]).astype(np.uint8))
            img = img.resize((28, 28)).convert("L")
            img = ImageOps.invert(img)
            img = np.array(img, dtype=np.float32) / 255.0
            img = img.reshape(1, -1)

            # Hiá»ƒn thá»‹ áº£nh sau khi xá»­ lÃ½
            st.image(Image.fromarray((img.reshape(28, 28) * 255).astype(np.uint8)), caption="áº¢nh sau khi xá»­ lÃ½", width=100)

            # Dá»± Ä‘oÃ¡n vá»›i mÃ´ hÃ¬nh Ä‘Ã£ chá»n
            prediction = model.predict(img)
            st.subheader(f"ğŸ”¢ Dá»± Ä‘oÃ¡n: {prediction[0]}")
            
            
def Classification():
    digits = datasets.load_digits()
    X, y = digits.data, digits.target

    # Chia táº­p train/test
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    st.title("ğŸ–Šï¸ MNIST Classification App")

    ### **Pháº§n 1: Hiá»ƒn thá»‹ dá»¯ liá»‡u MNIST**
    st.header("ğŸ“Š Má»™t sá»‘ hÃ¬nh áº£nh trong táº­p MNIST")
    fig, axes = plt.subplots(2, 5, figsize=(10, 5))
    for i, ax in enumerate(axes.flatten()):
        ax.imshow(X[i].reshape(8, 8), cmap="gray")
        ax.set_title(f"Sá»‘ {y[i]}")
        ax.axis("off")
    st.pyplot(fig)

    ### **Pháº§n 2: TrÃ¬nh bÃ y lÃ½ thuyáº¿t vá» Decision Tree & SVM*
    
    # 1ï¸âƒ£ Pháº§n giá»›i thiá»‡u
    
    # === Sidebar Ä‘á»ƒ chá»n trang ===
    # === Táº¡o Tabs ===
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“˜ LÃ½ thuyáº¿t Decision Tree", "ğŸ“˜ LÃ½ thuyáº¿t SVM", "âš™ï¸ Huáº¥n luyá»‡n", "ğŸ”¢ Dá»± Ä‘oÃ¡n"])

    with tab1:
        ly_thuyet_Decision_tree()

    with tab2:
        ly_thuyet_SVM()

    with tab3:
        split_data()
        train()

    with tab4:
        du_doan()
        





            
if __name__ == "__main__":
    Classification()