import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
import mlflow
import mlflow.sklearn
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from streamlit_drawable_canvas import st_canvas
from PIL import Image, ImageOps

# Khá»Ÿi táº¡o MLflow
# mlflow.set_tracking_uri("sqlite:///mlruns.db")  # LÆ°u trá»¯ local
# mlflow.set_experiment("MNIST Classification")

# Load dá»¯ liá»‡u MNIST
digits = datasets.load_digits()
X, y = digits.data, digits.target

# Chia táº­p train/test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

def Classification():
    st.title("ğŸ–Šï¸ MNIST Classification App")

    ### **Pháº§n 1: Hiá»ƒn thá»‹ dá»¯ liá»‡u MNIST**
    st.header("ğŸ“Š Má»™t sá»‘ hÃ¬nh áº£nh trong táº­p MNIST")
    fig, axes = plt.subplots(2, 5, figsize=(10, 5))
    for i, ax in enumerate(axes.flatten()):
        ax.imshow(X[i].reshape(8, 8), cmap="gray")
        ax.set_title(f"Sá»‘ {y[i]}")
        ax.axis("off")
    st.pyplot(fig)

    ### **Pháº§n 2: TrÃ¬nh bÃ y lÃ½ thuyáº¿t vá» Decision Tree & SVM**
    st.header("ğŸ“– LÃ½ thuyáº¿t vá» mÃ´ hÃ¬nh")
    # 1ï¸âƒ£ Pháº§n giá»›i thiá»‡u
    st.header("ğŸ“– LÃ½ thuyáº¿t vá» Decision Tree")

    # 1ï¸âƒ£ Giá»›i thiá»‡u vá» Decision Tree
    st.subheader("1ï¸âƒ£ Giá»›i thiá»‡u vá» Decision Tree")
    st.write("""
    - **Decision Tree** hoáº¡t Ä‘á»™ng báº±ng cÃ¡ch chia nhá» dá»¯ liá»‡u theo Ä‘iá»u kiá»‡n Ä‘á»ƒ phÃ¢n loáº¡i chÃ­nh xÃ¡c.
    - Má»—i nhÃ¡nh trong cÃ¢y lÃ  má»™t cÃ¢u há»i "CÃ³/KhÃ´ng" dá»±a trÃªn Ä‘áº·c trÆ°ng dá»¯ liá»‡u.
    - MÃ´ hÃ¬nh nÃ y dá»… hiá»ƒu vÃ  trá»±c quan nhÆ°ng cÃ³ thá»ƒ bá»‹ **overfitting** náº¿u khÃ´ng giá»›i háº¡n Ä‘á»™ sÃ¢u.
    """)

    # Hiá»ƒn thá»‹ áº£nh minh há»a Decision Tree
    st.image("buoi4/img1.png", caption="VÃ­ dá»¥ vá» cÃ¡ch Decision Tree phÃ¢n chia dá»¯ liá»‡u", use_column_width=True)

    st.write("""
    ### ğŸ” CÃ¡ch Decision Tree hoáº¡t Ä‘á»™ng vá»›i MNIST:
    - Má»—i áº£nh trong MNIST cÃ³ kÃ­ch thÆ°á»›c **28Ã—28 pixels**, má»—i pixel cÃ³ thá»ƒ xem lÃ  má»™t **Ä‘áº·c trÆ°ng (feature)**.
    - MÃ´ hÃ¬nh sáº½ quyáº¿t Ä‘á»‹nh phÃ¢n tÃ¡ch dá»¯ liá»‡u báº±ng cÃ¡ch **chá»n nhá»¯ng pixels quan trá»ng nháº¥t** Ä‘á»ƒ táº¡o nhÃ¡nh.
    - VÃ­ dá»¥, Ä‘á»ƒ phÃ¢n biá»‡t chá»¯ sá»‘ **0** vÃ  **1**, Decision Tree cÃ³ thá»ƒ kiá»ƒm tra:
        - Pixel á»Ÿ giá»¯a cÃ³ sÃ¡ng khÃ´ng?
        - Pixel dá»c hai bÃªn cÃ³ sÃ¡ng khÃ´ng?
    - Dá»±a trÃªn cÃ¢u tráº£ lá»i, mÃ´ hÃ¬nh sáº½ tiáº¿p tá»¥c chia nhá» táº­p dá»¯ liá»‡u.
    """)

    # 2ï¸âƒ£ CÃ´ng thá»©c toÃ¡n há»c
    st.subheader("2ï¸âƒ£ CÃ¡c bÆ°á»›c tÃ­nh toÃ¡n trong Decision Tree")

    st.markdown(r"""
    ### ğŸ“Œ **CÃ´ng thá»©c chÃ­nh**
    - **Entropy (Äá»™ há»—n loáº¡n cá»§a dá»¯ liá»‡u)**:
    \[
    H(S) = - \sum_{i=1}^{c} p_i \log_2 p_i
    \]
    Trong Ä‘Ã³:
    - \( c \) lÃ  sá»‘ lÆ°á»£ng lá»›p.
    - \( p_i \) lÃ  xÃ¡c suáº¥t xuáº¥t hiá»‡n cá»§a lá»›p \( i \).

    - **Information Gain (Lá»£i Ã­ch thÃ´ng tin sau khi chia tÃ¡ch)**:
    \[
    IG = H(S) - \sum_{j=1}^{k} \frac{|S_j|}{|S|} H(S_j)
    \]

    - **Gini Impurity (ThÆ°á»›c Ä‘o thay tháº¿ Entropy)**:
    \[
    Gini(S) = 1 - \sum_{i=1}^{c} p_i^2
    \]

    ğŸ’¡ **Sau khi tÃ­nh toÃ¡n Entropy, mÃ´ hÃ¬nh chá»n Ä‘áº·c trÆ°ng tá»‘t nháº¥t lÃ m gá»‘c, rá»“i tÃ­nh Information Gain cá»§a cÃ¡c Ä‘áº·c trÆ°ng cÃ²n láº¡i Ä‘á»ƒ tÃ¬m nhÃ¡nh tiáº¿p theo.**
    """)




    st.subheader("2ï¸âƒ£ Support Vector Machine (SVM)")

    st.write("""
    - **Support Vector Machine (SVM)** lÃ  má»™t thuáº­t toÃ¡n há»c mÃ¡y máº¡nh máº½ Ä‘á»ƒ phÃ¢n loáº¡i dá»¯ liá»‡u.
    - **Má»¥c tiÃªu chÃ­nh**: TÃ¬m má»™t **siÃªu pháº³ng (hyperplane)** tá»‘i Æ°u Ä‘á»ƒ phÃ¢n tÃ¡ch cÃ¡c lá»›p dá»¯ liá»‡u.
    - **á»¨ng dá»¥ng**: Nháº­n diá»‡n khuÃ´n máº·t, phÃ¡t hiá»‡n thÆ° rÃ¡c, phÃ¢n loáº¡i vÄƒn báº£n, v.v.
    - **Æ¯u Ä‘iá»ƒm**:
        - Hiá»‡u quáº£ trÃªn dá»¯ liá»‡u cÃ³ Ä‘á»™ nhiá»…u tháº¥p.
        - Há»— trá»£ dá»¯ liá»‡u khÃ´ng tuyáº¿n tÃ­nh báº±ng **kernel trick**.
    - **NhÆ°á»£c Ä‘iá»ƒm**:
        - Cháº­m trÃªn táº­p dá»¯ liá»‡u lá»›n do tÃ­nh toÃ¡n phá»©c táº¡p.
        - Nháº¡y cáº£m vá»›i lá»±a chá»n tham sá»‘ (C, Kernel).
    """)

    # Hiá»ƒn thá»‹ hÃ¬nh áº£nh minh há»a SV
    #st.image("buoi4/svm_example.png", caption="SVM tÃ¬m siÃªu pháº³ng tá»‘i Æ°u Ä‘á»ƒ phÃ¢n tÃ¡ch dá»¯ liá»‡u", use_column_width=True)

    st.write("""
    ### ğŸ” **CÃ¡ch hoáº¡t Ä‘á»™ng cá»§a SVM**
    - Dá»¯ liá»‡u Ä‘Æ°á»£c biá»ƒu diá»…n trong khÃ´ng gian nhiá»u chiá»u.
    - MÃ´ hÃ¬nh tÃ¬m má»™t siÃªu pháº³ng Ä‘á»ƒ phÃ¢n tÃ¡ch dá»¯ liá»‡u sao cho khoáº£ng cÃ¡ch tá»« siÃªu pháº³ng Ä‘áº¿n cÃ¡c Ä‘iá»ƒm gáº§n nháº¥t (support vectors) lÃ  lá»›n nháº¥t.
    - Náº¿u dá»¯ liá»‡u **khÃ´ng thá»ƒ phÃ¢n tÃ¡ch tuyáº¿n tÃ­nh**, ta cÃ³ thá»ƒ:
        - **DÃ¹ng Kernel Trick** Ä‘á»ƒ Ã¡nh xáº¡ dá»¯ liá»‡u sang khÃ´ng gian cao hÆ¡n.
        - **ThÃªm soft margin** Ä‘á»ƒ cháº¥p nháº­n má»™t sá»‘ Ä‘iá»ƒm bá»‹ phÃ¢n loáº¡i sai.
    """)

    # ğŸ“Œ 2ï¸âƒ£ CÃ´ng thá»©c toÃ¡n há»c
    st.subheader("ğŸ“Œ CÃ´ng thá»©c toÃ¡n há»c")

    st.markdown(r"""
    - **HÃ m má»¥c tiÃªu cáº§n tá»‘i Æ°u**:
    \[
    \min_{w, b} \frac{1}{2} ||w||^2
    \]
    vá»›i rÃ ng buá»™c:
    \[
    y_i (w \cdot x_i + b) \geq 1, \forall i
    \]
    Trong Ä‘Ã³:
    - \( w \) lÃ  vector trá»ng sá»‘.
    - \( b \) lÃ  bias (Ä‘á»™ dá»‹ch cá»§a siÃªu pháº³ng).
    - \( x_i \) lÃ  Ä‘iá»ƒm dá»¯ liá»‡u.
    - \( y_i \) lÃ  nhÃ£n cá»§a Ä‘iá»ƒm dá»¯ liá»‡u (\(+1\) hoáº·c \(-1\)).

    - **Khoáº£ng cÃ¡ch tá»« má»™t Ä‘iá»ƒm Ä‘áº¿n siÃªu pháº³ng**:
    \[
    d = \frac{|w \cdot x + b|}{||w||}
    \]
    
    - **HÃ m máº¥t mÃ¡t vá»›i soft margin (SVM khÃ´ng tuyáº¿n tÃ­nh)**:
    \[
    \min_{w, b} \frac{1}{2} ||w||^2 + C \sum_{i=1}^{n} \xi_i
    \]
    vá»›i \( \xi_i \) lÃ  biáº¿n slack cho phÃ©p phÃ¢n loáº¡i sai má»™t sá»‘ Ä‘iá»ƒm.
    """)

    st.write("""
    ğŸ’¡ **Ã nghÄ©a cá»§a cÃ´ng thá»©c:**
    - SVM tá»‘i Æ°u hÃ³a khoáº£ng cÃ¡ch giá»¯a hai lá»›p dá»¯ liá»‡u (margin).
    - Náº¿u dá»¯ liá»‡u khÃ´ng tuyáº¿n tÃ­nh, kernel trick giÃºp Ã¡nh xáº¡ dá»¯ liá»‡u lÃªn khÃ´ng gian cao hÆ¡n.
    - \( C \) lÃ  há»‡ sá»‘ Ä‘iá»u chá»‰nh giá»¯a viá»‡c tá»‘i Æ°u margin vÃ  cháº¥p nháº­n lá»—i.
    """)

    # ğŸ“Œ 3ï¸âƒ£ VÃ­ dá»¥ tÃ­nh toÃ¡n khoáº£ng cÃ¡ch Ä‘áº¿n siÃªu pháº³ng
    st.subheader("ğŸ“Œ VÃ­ dá»¥ tÃ­nh toÃ¡n")

    # MÃ´ phá»ng dá»¯ liá»‡u Ä‘Æ¡n giáº£n
    w = np.array([2, -3])  # Trá»ng sá»‘ w
    b = 5  # Bias
    x_sample = np.array([1, 2])  # Má»™t Ä‘iá»ƒm dá»¯ liá»‡u

    # TÃ­nh khoáº£ng cÃ¡ch Ä‘áº¿n siÃªu pháº³ng
    distance = np.abs(np.dot(w, x_sample) + b) / np.linalg.norm(w)

    st.write(f"ğŸ“Œ **Khoáº£ng cÃ¡ch tá»« Ä‘iá»ƒm {x_sample} Ä‘áº¿n siÃªu pháº³ng**: {distance:.4f}")

    # ğŸ“Œ 4ï¸âƒ£ Minh há»a phÃ¢n tÃ¡ch dá»¯ liá»‡u báº±ng SVM
    st.subheader("ğŸ“Œ Minh há»a phÃ¢n tÃ¡ch dá»¯ liá»‡u")

    # Táº¡o dá»¯ liá»‡u mÃ´ phá»ng
    X, y = make_classification(n_samples=100, n_features=2, n_classes=2, n_clusters_per_class=1, n_redundant=0, random_state=42)
    svm_model = SVC(kernel="linear", C=1.0)
    svm_model.fit(X, y)

    # Váº½ siÃªu pháº³ng
    fig, ax = plt.subplots(figsize=(6, 4))

    # Váº½ dá»¯ liá»‡u
    ax.scatter(X[:, 0], X[:, 1], c=y, cmap="coolwarm", edgecolors="k")

    # Váº½ siÃªu pháº³ng
    xx = np.linspace(X[:, 0].min(), X[:, 0].max(), 50)
    yy = - (svm_model.coef_[0][0] * xx + svm_model.intercept_[0]) / svm_model.coef_[0][1]
    ax.plot(xx, yy, "k--", label="SiÃªu pháº³ng")

    # Váº½ support vectors
    ax.scatter(svm_model.support_vectors_[:, 0], svm_model.support_vectors_[:, 1], facecolors="none", edgecolors="k", s=100, label="Support Vectors")

    ax.set_title("Minh há»a SVM vá»›i dá»¯ liá»‡u Ä‘Æ¡n giáº£n")
    ax.legend()
    st.pyplot(fig)

    st.write("""
    ### ğŸ”¥ **TÃ³m táº¯t**
    - SVM tÃ¬m siÃªu pháº³ng tá»‘i Æ°u Ä‘á»ƒ phÃ¢n loáº¡i dá»¯ liá»‡u.
    - Náº¿u dá»¯ liá»‡u khÃ´ng tuyáº¿n tÃ­nh, cÃ³ thá»ƒ dÃ¹ng **kernel trick**.
    - Cáº§n chá»n tham sá»‘ **C, kernel** phÃ¹ há»£p Ä‘á»ƒ trÃ¡nh overfitting.

    ğŸš€ **Báº¡n cÃ³ muá»‘n thá»­ nghiá»‡m vá»›i dá»¯ liá»‡u thá»±c táº¿?**
    """)
    ### **Pháº§n 3: Chá»n mÃ´ hÃ¬nh & Train**
    st.header("âš™ï¸ Chá»n mÃ´ hÃ¬nh & Huáº¥n luyá»‡n")

    model_choice = st.selectbox("Chá»n mÃ´ hÃ¬nh:", ["Decision Tree", "SVM"])

    if model_choice == "Decision Tree":
        max_depth = st.slider("max_depth", 1, 20, 5)
        model = DecisionTreeClassifier(max_depth=max_depth)
    elif model_choice == "SVM":
        C = st.slider("C (Regularization)", 0.1, 10.0, 1.0)
        kernel = st.selectbox("Kernel", ["linear", "rbf", "poly", "sigmoid"])
        model = SVC(C=C, kernel=kernel)

    if st.button("Huáº¥n luyá»‡n mÃ´ hÃ¬nh"):
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        acc = accuracy_score(y_test, y_pred)
        st.success(f"âœ… Äá»™ chÃ­nh xÃ¡c: {acc:.4f}")

        # LÆ°u káº¿t quáº£ vÃ o MLflow
        with mlflow.start_run():
            mlflow.log_param("model", model_choice)
            if model_choice == "Decision Tree":
                mlflow.log_param("max_depth", max_depth)
            else:
                mlflow.log_param("C", C)
                mlflow.log_param("kernel", kernel)
            mlflow.log_metric("accuracy", acc)
            mlflow.sklearn.log_model(model, model_choice)

    ### **Pháº§n 4: Váº½ sá»‘ & Dá»± Ä‘oÃ¡n**
    st.header("âœï¸ Váº½ sá»‘ Ä‘á»ƒ dá»± Ä‘oÃ¡n")

    canvas_result = st_canvas(
        fill_color="black",
        stroke_width=10,
        stroke_color="white",
        background_color="black",
        height=150,
        width=150,
        drawing_mode="freedraw",
        key="canvas"
    )

    if st.button("Dá»± Ä‘oÃ¡n sá»‘"):
        if canvas_result.image_data is not None:
            img = Image.fromarray((canvas_result.image_data[:, :, 0]).astype(np.uint8))
            img = img.resize((8, 8)).convert("L")
            img = ImageOps.invert(img)
            img = np.array(img).reshape(1, -1)

            # Dá»± Ä‘oÃ¡n
            prediction = model.predict(img)
            st.subheader(f"ğŸ”¢ Dá»± Ä‘oÃ¡n: {prediction[0]}")
            
if __name__ == "__main__":
    Classification()