import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
import mlflow
import mlflow.sklearn
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from streamlit_drawable_canvas import st_canvas
from PIL import Image, ImageOps


# Kh·ªüi t·∫°o MLflow
# mlflow.set_tracking_uri("sqlite:///mlruns.db")  # L∆∞u tr·ªØ local
# mlflow.set_experiment("MNIST Classification")

# Load d·ªØ li·ªáu MNIST


def Classification():
    digits = datasets.load_digits()
    X, y = digits.data, digits.target

    # Chia t·∫≠p train/test
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    st.title("üñäÔ∏è MNIST Classification App")

    ### **Ph·∫ßn 1: Hi·ªÉn th·ªã d·ªØ li·ªáu MNIST**
    st.header("üìä M·ªôt s·ªë h√¨nh ·∫£nh trong t·∫≠p MNIST")
    fig, axes = plt.subplots(2, 5, figsize=(10, 5))
    for i, ax in enumerate(axes.flatten()):
        ax.imshow(X[i].reshape(8, 8), cmap="gray")
        ax.set_title(f"S·ªë {y[i]}")
        ax.axis("off")
    st.pyplot(fig)

    ### **Ph·∫ßn 2: Tr√¨nh b√†y l√Ω thuy·∫øt v·ªÅ Decision Tree & SVM**
    st.header("üìñ L√Ω thuy·∫øt v·ªÅ m√¥ h√¨nh")
    # 1Ô∏è‚É£ Ph·∫ßn gi·ªõi thi·ªáu
    st.header("üìñ L√Ω thuy·∫øt v·ªÅ Decision Tree")

    # 1Ô∏è‚É£ Gi·ªõi thi·ªáu v·ªÅ Decision Tree
    st.subheader("1Ô∏è‚É£ Gi·ªõi thi·ªáu v·ªÅ Decision Tree")
    st.write("""
    - **Decision Tree** ho·∫°t ƒë·ªông b·∫±ng c√°ch chia nh·ªè d·ªØ li·ªáu theo ƒëi·ªÅu ki·ªán ƒë·ªÉ ph√¢n lo·∫°i ch√≠nh x√°c.
    - M·ªói nh√°nh trong c√¢y l√† m·ªôt c√¢u h·ªèi "C√≥/Kh√¥ng" d·ª±a tr√™n ƒë·∫∑c tr∆∞ng d·ªØ li·ªáu.
    - M√¥ h√¨nh n√†y d·ªÖ hi·ªÉu v√† tr·ª±c quan nh∆∞ng c√≥ th·ªÉ b·ªã **overfitting** n·∫øu kh√¥ng gi·ªõi h·∫°n ƒë·ªô s√¢u.
    """)

    # Hi·ªÉn th·ªã ·∫£nh minh h·ªça Decision Tree
    st.image("buoi4/img1.png", caption="V√≠ d·ª• v·ªÅ c√°ch Decision Tree ph√¢n chia d·ªØ li·ªáu", use_column_width=True)

    st.write("""
    ### üîç C√°ch Decision Tree ho·∫°t ƒë·ªông v·ªõi MNIST:
    - M·ªói ·∫£nh trong MNIST c√≥ k√≠ch th∆∞·ªõc **28√ó28 pixels**, m·ªói pixel c√≥ th·ªÉ xem l√† m·ªôt **ƒë·∫∑c tr∆∞ng (feature)**.
    - M√¥ h√¨nh s·∫Ω quy·∫øt ƒë·ªãnh ph√¢n t√°ch d·ªØ li·ªáu b·∫±ng c√°ch **ch·ªçn nh·ªØng pixels quan tr·ªçng nh·∫•t** ƒë·ªÉ t·∫°o nh√°nh.
    - V√≠ d·ª•, ƒë·ªÉ ph√¢n bi·ªát ch·ªØ s·ªë **0** v√† **1**, Decision Tree c√≥ th·ªÉ ki·ªÉm tra:
        - Pixel ·ªü gi·ªØa c√≥ s√°ng kh√¥ng?
        - Pixel d·ªçc hai b√™n c√≥ s√°ng kh√¥ng?
    - D·ª±a tr√™n c√¢u tr·∫£ l·ªùi, m√¥ h√¨nh s·∫Ω ti·∫øp t·ª•c chia nh·ªè t·∫≠p d·ªØ li·ªáu.
    """)

    # 2Ô∏è‚É£ C√¥ng th·ª©c to√°n h·ªçc
    st.subheader("2Ô∏è‚É£ C√°c b∆∞·ªõc t√≠nh to√°n trong Decision Tree")

    st.markdown(r"""
    ### üìå **C√¥ng th·ª©c ch√≠nh**
    - **Entropy (ƒê·ªô h·ªón lo·∫°n c·ªßa d·ªØ li·ªáu)**:
    \[
    H(S) = - \sum_{i=1}^{c} p_i \log_2 p_i
    \]
    Trong ƒë√≥:
    - \( c \) l√† s·ªë l∆∞·ª£ng l·ªõp.
    - \( p_i \) l√† x√°c su·∫•t xu·∫•t hi·ªán c·ªßa l·ªõp \( i \).

    - **Information Gain (L·ª£i √≠ch th√¥ng tin sau khi chia t√°ch)**:
    \[
    IG = H(S) - \sum_{j=1}^{k} \frac{|S_j|}{|S|} H(S_j)
    \]

   

    üí° **Sau khi t√≠nh to√°n Entropy, m√¥ h√¨nh ch·ªçn ƒë·∫∑c tr∆∞ng t·ªët nh·∫•t l√†m g·ªëc, r·ªìi t√≠nh Information Gain c·ªßa c√°c ƒë·∫∑c tr∆∞ng c√≤n l·∫°i ƒë·ªÉ t√¨m nh√°nh ti·∫øp theo.**
    """)




    st.subheader("2Ô∏è‚É£ Support Vector Machine (SVM)")

    st.write("""
    - **Support Vector Machine (SVM)** l√† m·ªôt thu·∫≠t to√°n h·ªçc m√°y m·∫°nh m·∫Ω ƒë·ªÉ ph√¢n lo·∫°i d·ªØ li·ªáu.
    - **M·ª•c ti√™u ch√≠nh**: T√¨m m·ªôt **si√™u ph·∫≥ng (hyperplane)** t·ªëi ∆∞u ƒë·ªÉ ph√¢n t√°ch c√°c l·ªõp d·ªØ li·ªáu.
    - **·ª®ng d·ª•ng**: Nh·∫≠n di·ªán khu√¥n m·∫∑t, ph√°t hi·ªán th∆∞ r√°c, ph√¢n lo·∫°i vƒÉn b·∫£n, v.v.
    - **∆Øu ƒëi·ªÉm**:
        - Hi·ªáu qu·∫£ tr√™n d·ªØ li·ªáu c√≥ ƒë·ªô nhi·ªÖu th·∫•p.
        - H·ªó tr·ª£ d·ªØ li·ªáu kh√¥ng tuy·∫øn t√≠nh b·∫±ng **kernel trick**.
    - **Nh∆∞·ª£c ƒëi·ªÉm**:
        - Ch·∫≠m tr√™n t·∫≠p d·ªØ li·ªáu l·ªõn do t√≠nh to√°n ph·ª©c t·∫°p.
        - Nh·∫°y c·∫£m v·ªõi l·ª±a ch·ªçn tham s·ªë (C, Kernel).
    """)

    # Hi·ªÉn th·ªã h√¨nh ·∫£nh minh h·ªça SV
    st.image("buoi4/img2.png", caption="SVM t√¨m si√™u ph·∫≥ng t·ªëi ∆∞u ƒë·ªÉ ph√¢n t√°ch d·ªØ li·ªáu", use_column_width=True)

    st.write("""
    ### üîç **C√°ch ho·∫°t ƒë·ªông c·ªßa SVM**
    - D·ªØ li·ªáu ƒë∆∞·ª£c bi·ªÉu di·ªÖn trong kh√¥ng gian nhi·ªÅu chi·ªÅu.
    - M√¥ h√¨nh t√¨m m·ªôt si√™u ph·∫≥ng ƒë·ªÉ ph√¢n t√°ch d·ªØ li·ªáu sao cho kho·∫£ng c√°ch t·ª´ si√™u ph·∫≥ng ƒë·∫øn c√°c ƒëi·ªÉm g·∫ßn nh·∫•t (support vectors) l√† l·ªõn nh·∫•t.
    - N·∫øu d·ªØ li·ªáu **kh√¥ng th·ªÉ ph√¢n t√°ch tuy·∫øn t√≠nh**, ta c√≥ th·ªÉ:
        - **D√πng Kernel Trick** ƒë·ªÉ √°nh x·∫° d·ªØ li·ªáu sang kh√¥ng gian cao h∆°n.
        - **Th√™m soft margin** ƒë·ªÉ ch·∫•p nh·∫≠n m·ªôt s·ªë ƒëi·ªÉm b·ªã ph√¢n lo·∫°i sai.
    """)

    # üìå 2Ô∏è‚É£ C√¥ng th·ª©c to√°n h·ªçc
    st.subheader("üìå C√¥ng th·ª©c to√°n h·ªçc")

    st.markdown(r"""
    - **H√†m m·ª•c ti√™u c·∫ßn t·ªëi ∆∞u**:  
    $$\min_{w, b} \frac{1}{2} ||w||^2$$  
    ‚Üí M√¥ h√¨nh c·ªë g·∫Øng t√¨m **si√™u ph·∫≥ng ph√¢n c√°ch** sao cho **vector tr·ªçng s·ªë \( w \) c√≥ ƒë·ªô l·ªõn nh·ªè nh·∫•t**, gi√∫p tƒÉng ƒë·ªô t·ªïng qu√°t.  

    - **R√†ng bu·ªôc**:  
    $$y_i (w \cdot x_i + b) \geq 1, \forall i$$  
    ‚Üí M·ªçi ƒëi·ªÉm d·ªØ li·ªáu **ph·∫£i n·∫±m ƒë√∫ng ph√≠a** c·ªßa si√™u ph·∫≥ng, ƒë·∫£m b·∫£o ph√¢n lo·∫°i ch√≠nh x√°c.  

    - **Kho·∫£ng c√°ch t·ª´ m·ªôt ƒëi·ªÉm ƒë·∫øn si√™u ph·∫≥ng**:  
    $$d = \frac{|w \cdot x + b|}{||w||}$$  
    ‚Üí ƒêo **kho·∫£ng c√°ch vu√¥ng g√≥c** t·ª´ m·ªôt ƒëi·ªÉm ƒë·∫øn si√™u ph·∫≥ng, kho·∫£ng c√°ch c√†ng l·ªõn th√¨ m√¥ h√¨nh c√†ng ƒë√°ng tin c·∫≠y.  

    - **H√†m m·∫•t m√°t v·ªõi soft margin (SVM kh√¥ng tuy·∫øn t√≠nh)**:  
    $$\min_{w, b} \frac{1}{2} ||w||^2 + C \sum_{i=1}^{n} \xi_i$$  
    ‚Üí N·∫øu d·ªØ li·ªáu **kh√¥ng th·ªÉ ph√¢n t√°ch ho√†n h·∫£o**, cho ph√©p m·ªôt s·ªë ƒëi·ªÉm b·ªã ph√¢n lo·∫°i sai v·ªõi **bi·∫øn slack \( \xi_i \)**.  
    - **\( C \) l·ªõn** ‚Üí c·ªë g·∫Øng ph√¢n lo·∫°i ch√≠nh x√°c, d·ªÖ overfitting.  
    - **\( C \) nh·ªè** ‚Üí ch·∫•p nh·∫≠n m·ªôt s·ªë l·ªói, m√¥ h√¨nh t·ªïng qu√°t t·ªët h∆°n.  
    """)

    st.write("""
    üí° **√ù nghƒ©a c·ªßa c√¥ng th·ª©c:**
    - SVM t·ªëi ∆∞u h√≥a kho·∫£ng c√°ch gi·ªØa hai l·ªõp d·ªØ li·ªáu (margin).
    - N·∫øu d·ªØ li·ªáu kh√¥ng tuy·∫øn t√≠nh, kernel trick gi√∫p √°nh x·∫° d·ªØ li·ªáu l√™n kh√¥ng gian cao h∆°n.
    - \( C \) l√† h·ªá s·ªë ƒëi·ªÅu ch·ªânh gi·ªØa vi·ªác t·ªëi ∆∞u margin v√† ch·∫•p nh·∫≠n l·ªói.
    """)

    # üìå 3Ô∏è‚É£ V√≠ d·ª• t√≠nh to√°n kho·∫£ng c√°ch ƒë·∫øn si√™u ph·∫≥ng
    
    st.write("""
    ### üî• **T√≥m t·∫Øt**
    - SVM t√¨m si√™u ph·∫≥ng t·ªëi ∆∞u ƒë·ªÉ ph√¢n lo·∫°i d·ªØ li·ªáu.
    - N·∫øu d·ªØ li·ªáu kh√¥ng tuy·∫øn t√≠nh, c√≥ th·ªÉ d√πng **kernel trick**.
    - C·∫ßn ch·ªçn tham s·ªë **C, kernel** ph√π h·ª£p ƒë·ªÉ tr√°nh overfitting.

    üöÄ **B·∫°n c√≥ mu·ªën th·ª≠ nghi·ªám v·ªõi d·ªØ li·ªáu th·ª±c t·∫ø?**
    """)
    ### **Ph·∫ßn 3: Ch·ªçn m√¥ h√¨nh & Train**
    st.header("‚öôÔ∏è Ch·ªçn m√¥ h√¨nh & Hu·∫•n luy·ªán")

    model_choice = st.selectbox("Ch·ªçn m√¥ h√¨nh:", ["Decision Tree", "SVM"])

    if model_choice == "Decision Tree":
        max_depth = st.slider("max_depth", 1, 20, 5)
        model = DecisionTreeClassifier(max_depth=max_depth)
    elif model_choice == "SVM":
        C = st.slider("C (Regularization)", 0.1, 10.0, 1.0)
        kernel = st.selectbox("Kernel", ["linear", "rbf", "poly", "sigmoid"])
        model = SVC(C=C, kernel=kernel)

    if st.button("Hu·∫•n luy·ªán m√¥ h√¨nh"):
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        acc = accuracy_score(y_test, y_pred)
        st.success(f"‚úÖ ƒê·ªô ch√≠nh x√°c: {acc:.4f}")

        # L∆∞u k·∫øt qu·∫£ v√†o MLflow
        with mlflow.start_run():
            mlflow.log_param("model", model_choice)
            if model_choice == "Decision Tree":
                mlflow.log_param("max_depth", max_depth)
            else:
                mlflow.log_param("C", C)
                mlflow.log_param("kernel", kernel)
            mlflow.log_metric("accuracy", acc)
            mlflow.sklearn.log_model(model, model_choice)

    ### **Ph·∫ßn 4: V·∫Ω s·ªë & D·ª± ƒëo√°n**
    st.header("‚úçÔ∏è V·∫Ω s·ªë ƒë·ªÉ d·ª± ƒëo√°n")

    canvas_result = st_canvas(
        fill_color="black",
        stroke_width=10,
        stroke_color="white",
        background_color="black",
        height=150,
        width=150,
        drawing_mode="freedraw",
        key="canvas"
    )

    if st.button("D·ª± ƒëo√°n s·ªë"):
        if canvas_result.image_data is not None:
            img = Image.fromarray((canvas_result.image_data[:, :, 0]).astype(np.uint8))
            img = img.resize((8, 8)).convert("L")
            img = ImageOps.invert(img)
            img = np.array(img).reshape(1, -1)

            # D·ª± ƒëo√°n
            prediction = model.predict(img)
            st.subheader(f"üî¢ D·ª± ƒëo√°n: {prediction[0]}")
            
if __name__ == "__main__":
    Classification()