import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
import mlflow
import mlflow.sklearn
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from streamlit_drawable_canvas import st_canvas
from PIL import Image, ImageOps

# Kh·ªüi t·∫°o MLflow
# mlflow.set_tracking_uri("sqlite:///mlruns.db")  # L∆∞u tr·ªØ local
# mlflow.set_experiment("MNIST Classification")

# Load d·ªØ li·ªáu MNIST
digits = datasets.load_digits()
X, y = digits.data, digits.target

# Chia t·∫≠p train/test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

def Classification():
    st.title("üñäÔ∏è MNIST Classification App")

    ### **Ph·∫ßn 1: Hi·ªÉn th·ªã d·ªØ li·ªáu MNIST**
    st.header("üìä M·ªôt s·ªë h√¨nh ·∫£nh trong t·∫≠p MNIST")
    fig, axes = plt.subplots(2, 5, figsize=(10, 5))
    for i, ax in enumerate(axes.flatten()):
        ax.imshow(X[i].reshape(8, 8), cmap="gray")
        ax.set_title(f"S·ªë {y[i]}")
        ax.axis("off")
    st.pyplot(fig)

    ### **Ph·∫ßn 2: Tr√¨nh b√†y l√Ω thuy·∫øt v·ªÅ Decision Tree & SVM**
    st.header("üìñ L√Ω thuy·∫øt v·ªÅ m√¥ h√¨nh")
    # 1Ô∏è‚É£ Ph·∫ßn gi·ªõi thi·ªáu
    st.header("üìñ L√Ω thuy·∫øt v·ªÅ Decision Tree")

    # 1Ô∏è‚É£ Gi·ªõi thi·ªáu v·ªÅ Decision Tree
    st.subheader("1Ô∏è‚É£ Gi·ªõi thi·ªáu v·ªÅ Decision Tree")
    st.write("""
    - **Decision Tree** ho·∫°t ƒë·ªông b·∫±ng c√°ch chia nh·ªè d·ªØ li·ªáu theo ƒëi·ªÅu ki·ªán ƒë·ªÉ ph√¢n lo·∫°i ch√≠nh x√°c.
    - M·ªói nh√°nh trong c√¢y l√† m·ªôt c√¢u h·ªèi "C√≥/Kh√¥ng" d·ª±a tr√™n ƒë·∫∑c tr∆∞ng d·ªØ li·ªáu.
    - M√¥ h√¨nh n√†y d·ªÖ hi·ªÉu v√† tr·ª±c quan nh∆∞ng c√≥ th·ªÉ b·ªã **overfitting** n·∫øu kh√¥ng gi·ªõi h·∫°n ƒë·ªô s√¢u.
    """)

    # Hi·ªÉn th·ªã ·∫£nh minh h·ªça Decision Tree
    st.image("buoi4/img1.png", caption="V√≠ d·ª• v·ªÅ c√°ch Decision Tree ph√¢n chia d·ªØ li·ªáu", use_column_width=True)

    st.write("""
    ### üîç C√°ch Decision Tree ho·∫°t ƒë·ªông v·ªõi MNIST:
    - M·ªói ·∫£nh trong MNIST c√≥ k√≠ch th∆∞·ªõc **28√ó28 pixels**, m·ªói pixel c√≥ th·ªÉ xem l√† m·ªôt **ƒë·∫∑c tr∆∞ng (feature)**.
    - M√¥ h√¨nh s·∫Ω quy·∫øt ƒë·ªãnh ph√¢n t√°ch d·ªØ li·ªáu b·∫±ng c√°ch **ch·ªçn nh·ªØng pixels quan tr·ªçng nh·∫•t** ƒë·ªÉ t·∫°o nh√°nh.
    - V√≠ d·ª•, ƒë·ªÉ ph√¢n bi·ªát ch·ªØ s·ªë **0** v√† **1**, Decision Tree c√≥ th·ªÉ ki·ªÉm tra:
        - Pixel ·ªü gi·ªØa c√≥ s√°ng kh√¥ng?
        - Pixel d·ªçc hai b√™n c√≥ s√°ng kh√¥ng?
    - D·ª±a tr√™n c√¢u tr·∫£ l·ªùi, m√¥ h√¨nh s·∫Ω ti·∫øp t·ª•c chia nh·ªè t·∫≠p d·ªØ li·ªáu.
    """)

    # 2Ô∏è‚É£ C√¥ng th·ª©c to√°n h·ªçc
    st.subheader("2Ô∏è‚É£ C√°c b∆∞·ªõc t√≠nh to√°n trong Decision Tree")

    st.markdown(r"""
    ### üìå **C√¥ng th·ª©c ch√≠nh**
    - **Entropy (ƒê·ªô h·ªón lo·∫°n c·ªßa d·ªØ li·ªáu)**:
    \[
    H(S) = - \sum_{i=1}^{c} p_i \log_2 p_i
    \]
    Trong ƒë√≥:
    - \( c \) l√† s·ªë l∆∞·ª£ng l·ªõp.
    - \( p_i \) l√† x√°c su·∫•t xu·∫•t hi·ªán c·ªßa l·ªõp \( i \).

    - **Information Gain (L·ª£i √≠ch th√¥ng tin sau khi chia t√°ch)**:
    \[
    IG = H(S) - \sum_{j=1}^{k} \frac{|S_j|}{|S|} H(S_j)
    \]

    - **Gini Impurity (Th∆∞·ªõc ƒëo thay th·∫ø Entropy)**:
    \[
    Gini(S) = 1 - \sum_{i=1}^{c} p_i^2
    \]

    üí° **Sau khi t√≠nh to√°n Entropy, m√¥ h√¨nh ch·ªçn ƒë·∫∑c tr∆∞ng t·ªët nh·∫•t l√†m g·ªëc, r·ªìi t√≠nh Information Gain c·ªßa c√°c ƒë·∫∑c tr∆∞ng c√≤n l·∫°i ƒë·ªÉ t√¨m nh√°nh ti·∫øp theo.**
    """)




    st.subheader("2Ô∏è‚É£ Support Vector Machine (SVM)")

    st.write("""
    - **Support Vector Machine (SVM)** l√† m·ªôt thu·∫≠t to√°n h·ªçc m√°y m·∫°nh m·∫Ω ƒë·ªÉ ph√¢n lo·∫°i d·ªØ li·ªáu.
    - **M·ª•c ti√™u ch√≠nh**: T√¨m m·ªôt **si√™u ph·∫≥ng (hyperplane)** t·ªëi ∆∞u ƒë·ªÉ ph√¢n t√°ch c√°c l·ªõp d·ªØ li·ªáu.
    - **·ª®ng d·ª•ng**: Nh·∫≠n di·ªán khu√¥n m·∫∑t, ph√°t hi·ªán th∆∞ r√°c, ph√¢n lo·∫°i vƒÉn b·∫£n, v.v.
    - **∆Øu ƒëi·ªÉm**:
        - Hi·ªáu qu·∫£ tr√™n d·ªØ li·ªáu c√≥ ƒë·ªô nhi·ªÖu th·∫•p.
        - H·ªó tr·ª£ d·ªØ li·ªáu kh√¥ng tuy·∫øn t√≠nh b·∫±ng **kernel trick**.
    - **Nh∆∞·ª£c ƒëi·ªÉm**:
        - Ch·∫≠m tr√™n t·∫≠p d·ªØ li·ªáu l·ªõn do t√≠nh to√°n ph·ª©c t·∫°p.
        - Nh·∫°y c·∫£m v·ªõi l·ª±a ch·ªçn tham s·ªë (C, Kernel).
    """)

    # Hi·ªÉn th·ªã h√¨nh ·∫£nh minh h·ªça SV
    #st.image("buoi4/svm_example.png", caption="SVM t√¨m si√™u ph·∫≥ng t·ªëi ∆∞u ƒë·ªÉ ph√¢n t√°ch d·ªØ li·ªáu", use_column_width=True)

    st.write("""
    ### üîç **C√°ch ho·∫°t ƒë·ªông c·ªßa SVM**
    - D·ªØ li·ªáu ƒë∆∞·ª£c bi·ªÉu di·ªÖn trong kh√¥ng gian nhi·ªÅu chi·ªÅu.
    - M√¥ h√¨nh t√¨m m·ªôt si√™u ph·∫≥ng ƒë·ªÉ ph√¢n t√°ch d·ªØ li·ªáu sao cho kho·∫£ng c√°ch t·ª´ si√™u ph·∫≥ng ƒë·∫øn c√°c ƒëi·ªÉm g·∫ßn nh·∫•t (support vectors) l√† l·ªõn nh·∫•t.
    - N·∫øu d·ªØ li·ªáu **kh√¥ng th·ªÉ ph√¢n t√°ch tuy·∫øn t√≠nh**, ta c√≥ th·ªÉ:
        - **D√πng Kernel Trick** ƒë·ªÉ √°nh x·∫° d·ªØ li·ªáu sang kh√¥ng gian cao h∆°n.
        - **Th√™m soft margin** ƒë·ªÉ ch·∫•p nh·∫≠n m·ªôt s·ªë ƒëi·ªÉm b·ªã ph√¢n lo·∫°i sai.
    """)

    # üìå 2Ô∏è‚É£ C√¥ng th·ª©c to√°n h·ªçc
    st.subheader("üìå C√¥ng th·ª©c to√°n h·ªçc")

    st.markdown(r"""
    - **H√†m m·ª•c ti√™u c·∫ßn t·ªëi ∆∞u**:
    \[
    \min_{w, b} \frac{1}{2} ||w||^2
    \]
    v·ªõi r√†ng bu·ªôc:
    \[
    y_i (w \cdot x_i + b) \geq 1, \forall i
    \]
    Trong ƒë√≥:
    - \( w \) l√† vector tr·ªçng s·ªë.
    - \( b \) l√† bias (ƒë·ªô d·ªãch c·ªßa si√™u ph·∫≥ng).
    - \( x_i \) l√† ƒëi·ªÉm d·ªØ li·ªáu.
    - \( y_i \) l√† nh√£n c·ªßa ƒëi·ªÉm d·ªØ li·ªáu (\(+1\) ho·∫∑c \(-1\)).

    - **Kho·∫£ng c√°ch t·ª´ m·ªôt ƒëi·ªÉm ƒë·∫øn si√™u ph·∫≥ng**:
    \[
    d = \frac{|w \cdot x + b|}{||w||}
    \]
    
    - **H√†m m·∫•t m√°t v·ªõi soft margin (SVM kh√¥ng tuy·∫øn t√≠nh)**:
    \[
    \min_{w, b} \frac{1}{2} ||w||^2 + C \sum_{i=1}^{n} \xi_i
    \]
    v·ªõi \( \xi_i \) l√† bi·∫øn slack cho ph√©p ph√¢n lo·∫°i sai m·ªôt s·ªë ƒëi·ªÉm.
    """)

    st.write("""
    üí° **√ù nghƒ©a c·ªßa c√¥ng th·ª©c:**
    - SVM t·ªëi ∆∞u h√≥a kho·∫£ng c√°ch gi·ªØa hai l·ªõp d·ªØ li·ªáu (margin).
    - N·∫øu d·ªØ li·ªáu kh√¥ng tuy·∫øn t√≠nh, kernel trick gi√∫p √°nh x·∫° d·ªØ li·ªáu l√™n kh√¥ng gian cao h∆°n.
    - \( C \) l√† h·ªá s·ªë ƒëi·ªÅu ch·ªânh gi·ªØa vi·ªác t·ªëi ∆∞u margin v√† ch·∫•p nh·∫≠n l·ªói.
    """)

    # üìå 3Ô∏è‚É£ V√≠ d·ª• t√≠nh to√°n kho·∫£ng c√°ch ƒë·∫øn si√™u ph·∫≥ng
    st.subheader("üìå V√≠ d·ª• t√≠nh to√°n")

    # M√¥ ph·ªèng d·ªØ li·ªáu ƒë∆°n gi·∫£n
    w = np.array([2, -3])  # Tr·ªçng s·ªë w
    b = 5  # Bias
    x_sample = np.array([1, 2])  # M·ªôt ƒëi·ªÉm d·ªØ li·ªáu

    # T√≠nh kho·∫£ng c√°ch ƒë·∫øn si√™u ph·∫≥ng
    distance = np.abs(np.dot(w, x_sample) + b) / np.linalg.norm(w)

    st.write(f"üìå **Kho·∫£ng c√°ch t·ª´ ƒëi·ªÉm {x_sample} ƒë·∫øn si√™u ph·∫≥ng**: {distance:.4f}")

    # üìå 4Ô∏è‚É£ Minh h·ªça ph√¢n t√°ch d·ªØ li·ªáu b·∫±ng SVM
    st.subheader("üìå Minh h·ªça ph√¢n t√°ch d·ªØ li·ªáu")

    # T·∫°o d·ªØ li·ªáu m√¥ ph·ªèng
    X, y = make_classification(n_samples=100, n_features=2, n_classes=2, n_clusters_per_class=1, n_redundant=0, random_state=42)
    svm_model = SVC(kernel="linear", C=1.0)
    svm_model.fit(X, y)

    # V·∫Ω si√™u ph·∫≥ng
    fig, ax = plt.subplots(figsize=(6, 4))

    # V·∫Ω d·ªØ li·ªáu
    ax.scatter(X[:, 0], X[:, 1], c=y, cmap="coolwarm", edgecolors="k")

    # V·∫Ω si√™u ph·∫≥ng
    xx = np.linspace(X[:, 0].min(), X[:, 0].max(), 50)
    yy = - (svm_model.coef_[0][0] * xx + svm_model.intercept_[0]) / svm_model.coef_[0][1]
    ax.plot(xx, yy, "k--", label="Si√™u ph·∫≥ng")

    # V·∫Ω support vectors
    ax.scatter(svm_model.support_vectors_[:, 0], svm_model.support_vectors_[:, 1], facecolors="none", edgecolors="k", s=100, label="Support Vectors")

    ax.set_title("Minh h·ªça SVM v·ªõi d·ªØ li·ªáu ƒë∆°n gi·∫£n")
    ax.legend()
    st.pyplot(fig)

    st.write("""
    ### üî• **T√≥m t·∫Øt**
    - SVM t√¨m si√™u ph·∫≥ng t·ªëi ∆∞u ƒë·ªÉ ph√¢n lo·∫°i d·ªØ li·ªáu.
    - N·∫øu d·ªØ li·ªáu kh√¥ng tuy·∫øn t√≠nh, c√≥ th·ªÉ d√πng **kernel trick**.
    - C·∫ßn ch·ªçn tham s·ªë **C, kernel** ph√π h·ª£p ƒë·ªÉ tr√°nh overfitting.

    üöÄ **B·∫°n c√≥ mu·ªën th·ª≠ nghi·ªám v·ªõi d·ªØ li·ªáu th·ª±c t·∫ø?**
    """)
    ### **Ph·∫ßn 3: Ch·ªçn m√¥ h√¨nh & Train**
    st.header("‚öôÔ∏è Ch·ªçn m√¥ h√¨nh & Hu·∫•n luy·ªán")

    model_choice = st.selectbox("Ch·ªçn m√¥ h√¨nh:", ["Decision Tree", "SVM"])

    if model_choice == "Decision Tree":
        max_depth = st.slider("max_depth", 1, 20, 5)
        model = DecisionTreeClassifier(max_depth=max_depth)
    elif model_choice == "SVM":
        C = st.slider("C (Regularization)", 0.1, 10.0, 1.0)
        kernel = st.selectbox("Kernel", ["linear", "rbf", "poly", "sigmoid"])
        model = SVC(C=C, kernel=kernel)

    if st.button("Hu·∫•n luy·ªán m√¥ h√¨nh"):
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        acc = accuracy_score(y_test, y_pred)
        st.success(f"‚úÖ ƒê·ªô ch√≠nh x√°c: {acc:.4f}")

        # L∆∞u k·∫øt qu·∫£ v√†o MLflow
        with mlflow.start_run():
            mlflow.log_param("model", model_choice)
            if model_choice == "Decision Tree":
                mlflow.log_param("max_depth", max_depth)
            else:
                mlflow.log_param("C", C)
                mlflow.log_param("kernel", kernel)
            mlflow.log_metric("accuracy", acc)
            mlflow.sklearn.log_model(model, model_choice)

    ### **Ph·∫ßn 4: V·∫Ω s·ªë & D·ª± ƒëo√°n**
    st.header("‚úçÔ∏è V·∫Ω s·ªë ƒë·ªÉ d·ª± ƒëo√°n")

    canvas_result = st_canvas(
        fill_color="black",
        stroke_width=10,
        stroke_color="white",
        background_color="black",
        height=150,
        width=150,
        drawing_mode="freedraw",
        key="canvas"
    )

    if st.button("D·ª± ƒëo√°n s·ªë"):
        if canvas_result.image_data is not None:
            img = Image.fromarray((canvas_result.image_data[:, :, 0]).astype(np.uint8))
            img = img.resize((8, 8)).convert("L")
            img = ImageOps.invert(img)
            img = np.array(img).reshape(1, -1)

            # D·ª± ƒëo√°n
            prediction = model.predict(img)
            st.subheader(f"üî¢ D·ª± ƒëo√°n: {prediction[0]}")
            
if __name__ == "__main__":
    Classification()