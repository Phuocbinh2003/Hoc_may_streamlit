import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from scipy.stats import zscore
# Ti√™u ƒë·ªÅ
def bt_buoi3():
    uploaded_file = "buoi2/data.txt"
    try:
        df = pd.read_csv(uploaded_file, delimiter=",")
    except FileNotFoundError:
        st.error("‚ùå Kh√¥ng t√¨m th·∫•y t·ªáp d·ªØ li·ªáu. Vui l√≤ng ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n.")
        st.stop()
    st.title("üîç Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu")
    
    st.subheader("üìå 10 d√≤ng ƒë·∫ßu c·ªßa d·ªØ li·ªáu g·ªëc")
    st.write(df.head(10))
    
    st.subheader("üö® Ki·ªÉm tra l·ªói d·ªØ li·ªáu")

                # Ki·ªÉm tra gi√° tr·ªã thi·∫øu
    missing_values = df.isnull().sum()

                # Ki·ªÉm tra d·ªØ li·ªáu tr√πng l·∫∑p
    duplicate_count = df.duplicated().sum()

                
                
                # Ki·ªÉm tra gi√° tr·ªã qu√° l·ªõn (outlier) b·∫±ng Z-score
    outlier_count = {
        col: (abs(zscore(df[col], nan_policy='omit')) > 3).sum()
        for col in df.select_dtypes(include=['number']).columns
    }

                # T·∫°o b√°o c√°o l·ªói
    error_report = pd.DataFrame({
        'C·ªôt': df.columns,
        'Gi√° tr·ªã thi·∫øu': missing_values,
        'Outlier': [outlier_count.get(col, 0) for col in df.columns]
    })

                # Hi·ªÉn th·ªã b√°o c√°o l·ªó
    st.table(error_report)

                # Hi·ªÉn th·ªã s·ªë l∆∞·ª£ng d·ªØ li·ªáu tr√πng l·∫∑p
    st.write(f"üîÅ **S·ªë l∆∞·ª£ng d√≤ng b·ªã tr√πng l·∫∑p:** {duplicate_count}")         
    
    st.title("üîç Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu")

    # Lo·∫°i b·ªè c√°c c·ªôt kh√¥ng c·∫ßn thi·∫øt
    st.subheader("1Ô∏è‚É£ Lo·∫°i b·ªè c√°c c·ªôt kh√¥ng quan tr·ªçng")
    st.write("""
    M·ªôt s·ªë c·ªôt trong d·ªØ li·ªáu c√≥ th·ªÉ kh√¥ng ƒë√≥ng g√≥p nhi·ªÅu v√†o k·∫øt qu·∫£ d·ª± ƒëo√°n ho·∫∑c ch·ª©a qu√° nhi·ªÅu gi√° tr·ªã thi·∫øu. Vi·ªác lo·∫°i b·ªè c√°c c·ªôt n√†y gi√∫p gi·∫£m ƒë·ªô ph·ª©c t·∫°p c·ªßa m√¥ h√¨nh v√† c·∫£i thi·ªán hi·ªáu su·∫•t.
    """)

    # X·ª≠ l√Ω gi√° tr·ªã thi·∫øu
    st.subheader("2Ô∏è‚É£ X·ª≠ l√Ω gi√° tr·ªã thi·∫øu")
    st.write("""
    D·ªØ li·ªáu th·ª±c t·∫ø th∆∞·ªùng ch·ª©a c√°c gi√° tr·ªã b·ªã thi·∫øu. Ta c·∫ßn l·ª±a ch·ªçn ph∆∞∆°ng ph√°p th√≠ch h·ª£p nh∆∞ ƒëi·ªÅn gi√° tr·ªã trung b√¨nh, lo·∫°i b·ªè h√†ng ho·∫∑c s·ª≠ d·ª•ng m√¥ h√¨nh d·ª± ƒëo√°n ƒë·ªÉ x·ª≠ l√Ω ch√∫ng nh·∫±m tr√°nh ·∫£nh h∆∞·ªüng ƒë·∫øn m√¥ h√¨nh.
    """)

    # Chuy·ªÉn ƒë·ªïi ki·ªÉu d·ªØ li·ªáu
    st.subheader("3Ô∏è‚É£ Chuy·ªÉn ƒë·ªïi ki·ªÉu d·ªØ li·ªáu")
    st.write("""
    M·ªôt s·ªë c·ªôt trong d·ªØ li·ªáu c√≥ th·ªÉ ch·ª©a gi√° tr·ªã d·∫°ng ch·ªØ (danh m·ª•c). ƒê·ªÉ m√¥ h√¨nh c√≥ th·ªÉ x·ª≠ l√Ω, ta c·∫ßn chuy·ªÉn ƒë·ªïi ch√∫ng th√†nh d·∫°ng s·ªë b·∫±ng c√°c ph∆∞∆°ng ph√°p nh∆∞ one-hot encoding ho·∫∑c label encoding.
    """)

    # Chu·∫©n h√≥a d·ªØ li·ªáu s·ªë
    st.subheader("4Ô∏è‚É£ Chu·∫©n h√≥a d·ªØ li·ªáu s·ªë")
    st.write("""
    C√°c gi√° tr·ªã s·ªë trong t·∫≠p d·ªØ li·ªáu c√≥ th·ªÉ c√≥ ph·∫°m vi r·∫•t kh√°c nhau, ƒëi·ªÅu n√†y c√≥ th·ªÉ ·∫£nh h∆∞·ªüng ƒë·∫øn ƒë·ªô h·ªôi t·ª• c·ªßa m√¥ h√¨nh. Ta c·∫ßn chu·∫©n h√≥a d·ªØ li·ªáu ƒë·ªÉ ƒë·∫£m b·∫£o t·∫•t c·∫£ c√°c ƒë·∫∑c tr∆∞ng c√≥ c√πng tr·ªçng s·ªë khi hu·∫•n luy·ªán m√¥ h√¨nh.
    """)

    # Chia d·ªØ li·ªáu th√†nh t·∫≠p Train, Validation, v√† Test
    st.subheader("5Ô∏è‚É£ Chia d·ªØ li·ªáu th√†nh t·∫≠p Train, Validation, v√† Test")
    st.write("""
    ƒê·ªÉ ƒë·∫£m b·∫£o m√¥ h√¨nh ho·∫°t ƒë·ªông t·ªët tr√™n d·ªØ li·ªáu th·ª±c t·∫ø, ta chia t·∫≠p d·ªØ li·ªáu th√†nh ba ph·∫ßn:
    - **Train**: D√πng ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh.
    - **Validation**: D√πng ƒë·ªÉ ƒëi·ªÅu ch·ªânh tham s·ªë m√¥ h√¨nh nh·∫±m t·ªëi ∆∞u h√≥a hi·ªáu su·∫•t.
    - **Test**: D√πng ƒë·ªÉ ƒë√°nh gi√° hi·ªáu su·∫•t cu·ªëi c√πng c·ªßa m√¥ h√¨nh tr√™n d·ªØ li·ªáu ch∆∞a t·ª´ng th·∫•y.
    """)
    
    
    
    st.title("L·ª±a ch·ªçn thu·∫≠t to√°n h·ªçc m√°y: Multiple vs. Polynomial Regression")

    # Gi·ªõi thi·ªáu
    st.write("## 1. Multiple Linear Regression")

    st.latex(r"""
    y = w_0 + w_1x_1 + w_2x_2 + \dots + w_nx_n
    """)

    st.write("Multiple Linear Regression l√† m√¥ h√¨nh tuy·∫øn t√≠nh s·ª≠ d·ª•ng nhi·ªÅu bi·∫øn ƒë·ªôc l·∫≠p ƒë·ªÉ d·ª± ƒëo√°n bi·∫øn ph·ª• thu·ªôc.")

    # Gi·ªõi thi·ªáu Polynomial Regression
    st.write("## 2. Polynomial Regression")

    st.latex(r"""
    y = w_0 + w_1x + w_2x^2 + w_3x^3 + \dots + w_nx^n
    """)

    st.write("Polynomial Regression m·ªü r·ªông m√¥ h√¨nh tuy·∫øn t√≠nh b·∫±ng c√°ch th√™m c√°c b·∫≠c cao h∆°n c·ªßa bi·∫øn ƒë·∫ßu v√†o.")

    # V·∫Ω bi·ªÉu ƒë·ªì so s√°nh
    st.write("## 3. Minh h·ªça tr·ª±c quan")

    # T·∫°o d·ªØ li·ªáu m·∫´u
    np.random.seed(0)
    x = np.sort(5 * np.random.rand(20, 1), axis=0)
    y = 2 * x**2 - 3 * x + np.random.randn(20, 1) * 2

    # H·ªìi quy tuy·∫øn t√≠nh
    lin_reg = LinearRegression()
    lin_reg.fit(x, y)
    y_pred_linear = lin_reg.predict(x)

    # H·ªìi quy b·∫≠c hai
    poly_features = PolynomialFeatures(degree=2)
    x_poly = poly_features.fit_transform(x)
    poly_reg = LinearRegression()
    poly_reg.fit(x_poly, y)
    y_pred_poly = poly_reg.predict(x_poly)

    # V·∫Ω bi·ªÉu ƒë·ªì
    fig, ax = plt.subplots(figsize=(6, 4))
    ax.scatter(x, y, color='blue', label='D·ªØ li·ªáu th·ª±c t·∫ø')
    ax.plot(x, y_pred_linear, color='red', label='Multiple Linear Regression')
    ax.plot(x, y_pred_poly, color='green', label='Polynomial Regression (b·∫≠c 2)')
    ax.set_xlabel("X")
    ax.set_ylabel("Y")
    ax.legend()
    st.pyplot(fig)
if __name__ == "__main__":
    bt_buoi3()