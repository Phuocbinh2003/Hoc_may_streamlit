import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from scipy.stats import zscore
# Ti√™u ƒë·ªÅ
def bt_buoi3():
    uploaded_file = "buoi2/data.txt"
    try:
        df = pd.read_csv(uploaded_file, delimiter=",")
    except FileNotFoundError:
        st.error("‚ùå Kh√¥ng t√¨m th·∫•y t·ªáp d·ªØ li·ªáu. Vui l√≤ng ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n.")
        st.stop()
    st.title("üîç Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu")
    
    st.subheader("üìå 10 d√≤ng ƒë·∫ßu c·ªßa d·ªØ li·ªáu g·ªëc")
    st.write(df.head(10))
    
    st.subheader("üö® Ki·ªÉm tra l·ªói d·ªØ li·ªáu")

                # Ki·ªÉm tra gi√° tr·ªã thi·∫øu
    missing_values = df.isnull().sum()

                # Ki·ªÉm tra d·ªØ li·ªáu tr√πng l·∫∑p
    duplicate_count = df.duplicated().sum()

                
                
                # Ki·ªÉm tra gi√° tr·ªã qu√° l·ªõn (outlier) b·∫±ng Z-score
    outlier_count = {
        col: (abs(zscore(df[col], nan_policy='omit')) > 3).sum()
        for col in df.select_dtypes(include=['number']).columns
    }

                # T·∫°o b√°o c√°o l·ªói
    error_report = pd.DataFrame({
        'C·ªôt': df.columns,
        'Gi√° tr·ªã thi·∫øu': missing_values,
        'Outlier': [outlier_count.get(col, 0) for col in df.columns]
    })

                # Hi·ªÉn th·ªã b√°o c√°o l·ªó
    st.table(error_report)

                # Hi·ªÉn th·ªã s·ªë l∆∞·ª£ng d·ªØ li·ªáu tr√πng l·∫∑p
    st.write(f"üîÅ **S·ªë l∆∞·ª£ng d√≤ng b·ªã tr√πng l·∫∑p:** {duplicate_count}")         
    
    st.title("üîç Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu")

    # Lo·∫°i b·ªè c√°c c·ªôt kh√¥ng c·∫ßn thi·∫øt
    st.subheader("1Ô∏è‚É£ Lo·∫°i b·ªè c√°c c·ªôt kh√¥ng quan tr·ªçng")
    st.write("""
    M·ªôt s·ªë c·ªôt trong d·ªØ li·ªáu c√≥ th·ªÉ kh√¥ng ƒë√≥ng g√≥p nhi·ªÅu v√†o k·∫øt qu·∫£ d·ª± ƒëo√°n ho·∫∑c ch·ª©a qu√° nhi·ªÅu gi√° tr·ªã thi·∫øu. Vi·ªác lo·∫°i b·ªè c√°c c·ªôt n√†y gi√∫p gi·∫£m ƒë·ªô ph·ª©c t·∫°p c·ªßa m√¥ h√¨nh v√† c·∫£i thi·ªán hi·ªáu su·∫•t.
    """)

    # X·ª≠ l√Ω gi√° tr·ªã thi·∫øu
    st.subheader("2Ô∏è‚É£ X·ª≠ l√Ω gi√° tr·ªã thi·∫øu")
    st.write("""
    D·ªØ li·ªáu th·ª±c t·∫ø th∆∞·ªùng ch·ª©a c√°c gi√° tr·ªã b·ªã thi·∫øu. Ta c·∫ßn l·ª±a ch·ªçn ph∆∞∆°ng ph√°p th√≠ch h·ª£p nh∆∞ ƒëi·ªÅn gi√° tr·ªã trung b√¨nh, lo·∫°i b·ªè h√†ng ho·∫∑c s·ª≠ d·ª•ng m√¥ h√¨nh d·ª± ƒëo√°n ƒë·ªÉ x·ª≠ l√Ω ch√∫ng nh·∫±m tr√°nh ·∫£nh h∆∞·ªüng ƒë·∫øn m√¥ h√¨nh.
    """)

    # Chuy·ªÉn ƒë·ªïi ki·ªÉu d·ªØ li·ªáu
    st.subheader("3Ô∏è‚É£ Chuy·ªÉn ƒë·ªïi ki·ªÉu d·ªØ li·ªáu")
    st.write("""
    M·ªôt s·ªë c·ªôt trong d·ªØ li·ªáu c√≥ th·ªÉ ch·ª©a gi√° tr·ªã d·∫°ng ch·ªØ (danh m·ª•c). ƒê·ªÉ m√¥ h√¨nh c√≥ th·ªÉ x·ª≠ l√Ω, ta c·∫ßn chuy·ªÉn ƒë·ªïi ch√∫ng th√†nh d·∫°ng s·ªë b·∫±ng c√°c ph∆∞∆°ng ph√°p nh∆∞ one-hot encoding ho·∫∑c label encoding.
    """)

    # Chu·∫©n h√≥a d·ªØ li·ªáu s·ªë
    st.subheader("4Ô∏è‚É£ Chu·∫©n h√≥a d·ªØ li·ªáu s·ªë")
    st.write("""
    C√°c gi√° tr·ªã s·ªë trong t·∫≠p d·ªØ li·ªáu c√≥ th·ªÉ c√≥ ph·∫°m vi r·∫•t kh√°c nhau, ƒëi·ªÅu n√†y c√≥ th·ªÉ ·∫£nh h∆∞·ªüng ƒë·∫øn ƒë·ªô h·ªôi t·ª• c·ªßa m√¥ h√¨nh. Ta c·∫ßn chu·∫©n h√≥a d·ªØ li·ªáu ƒë·ªÉ ƒë·∫£m b·∫£o t·∫•t c·∫£ c√°c ƒë·∫∑c tr∆∞ng c√≥ c√πng tr·ªçng s·ªë khi hu·∫•n luy·ªán m√¥ h√¨nh.
    """)

    # Chia d·ªØ li·ªáu th√†nh t·∫≠p Train, Validation, v√† Test
    st.subheader("5Ô∏è‚É£ Chia d·ªØ li·ªáu th√†nh t·∫≠p Train, Validation, v√† Test")
    st.write("""
    ƒê·ªÉ ƒë·∫£m b·∫£o m√¥ h√¨nh ho·∫°t ƒë·ªông t·ªët tr√™n d·ªØ li·ªáu th·ª±c t·∫ø, ta chia t·∫≠p d·ªØ li·ªáu th√†nh ba ph·∫ßn:
    - **Train**: D√πng ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh.
    - **Validation**: D√πng ƒë·ªÉ ƒëi·ªÅu ch·ªânh tham s·ªë m√¥ h√¨nh nh·∫±m t·ªëi ∆∞u h√≥a hi·ªáu su·∫•t.
    - **Test**: D√πng ƒë·ªÉ ƒë√°nh gi√° hi·ªáu su·∫•t cu·ªëi c√πng c·ªßa m√¥ h√¨nh tr√™n d·ªØ li·ªáu ch∆∞a t·ª´ng th·∫•y.
    """)
    
    
    
    st.title("L·ª±a ch·ªçn thu·∫≠t to√°n h·ªçc m√°y: Multiple vs. Polynomial Regression")

    # Gi·ªõi thi·ªáu
    st.write("## 1. Multiple Linear Regression")
    st.write("""
    H·ªìi quy tuy·∫øn t√≠nh b·ªôi l√† m·ªôt thu·∫≠t to√°n h·ªçc m√°y c√≥ gi√°m s√°t, m√¥ t·∫£ m·ªëi quan h·ªá gi·ªØa m·ªôt bi·∫øn ph·ª• thu·ªôc (output) v√† nhi·ªÅu bi·∫øn ƒë·ªôc l·∫≠p (input) th√¥ng qua m·ªôt h√†m tuy·∫øn t√≠nh.
    V√≠ d·ª• d·ª± ƒëo√°n gi√° nh√† d·ª±a tr√™n di·ªán t√≠ch, s·ªë ph√≤ng, v·ªã tr√≠, ... 
    
    C√¥ng th·ª©c t·ªïng qu√°t c·ªßa m√¥ h√¨nh h·ªìi quy tuy·∫øn t√≠nh b·ªôi:
    """)
    st.image("buoi3/img1.png", caption="Multiple Linear Regression ƒë∆°n", use_container_width =True)
    st.latex(r"""
    y = w_0 + w_1x_1 + w_2x_2 + \dots + w_nx_n
    """)

    
   
    st.write("""
    ### H√†m m·∫•t m√°t (Loss Function) c·ªßa Linear Regression
    H√†m m·∫•t m√°t ph·ªï bi·∫øn nh·∫•t l√† **Mean Squared Error (MSE)**:
    """)
    st.latex(r"""
    MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
    """)

    st.write("""
    Trong ƒë√≥:
    - \( n \): S·ªë l∆∞·ª£ng ƒëi·ªÉm d·ªØ li·ªáu.
    - \( y_i \): Gi√° tr·ªã th·ª±c t·∫ø c·ªßa bi·∫øn ph·ª• thu·ªôc.
    - \( \hat{y}_i \): Gi√° tr·ªã d·ª± ƒëo√°n t·ª´ m√¥ h√¨nh.

    M·ª•c ti√™u c·ªßa h·ªìi quy tuy·∫øn t√≠nh b·ªôi l√† t√¨m c√°c h·ªá s·ªë tr·ªçng s·ªë \( w_0, w_1, w_2, ..., w_n \) sao cho gi√° tr·ªã MSE nh·ªè nh·∫•t.

    ### Thu·∫≠t to√°n Gradient Descent
    1. Kh·ªüi t·∫°o c√°c tr·ªçng s·ªë \( w_0, w_1, w_2, ..., w_n \) v·ªõi gi√° tr·ªã b·∫•t k·ª≥.
    2. T√≠nh gradient c·ªßa MSE ƒë·ªëi v·ªõi t·ª´ng tr·ªçng s·ªë.
    3. C·∫≠p nh·∫≠t tr·ªçng s·ªë theo quy t·∫Øc c·ªßa thu·∫≠t to√°n Gradient Descent.

    ### ƒê√°nh gi√° m√¥ h√¨nh h·ªìi quy tuy·∫øn t√≠nh b·ªôi
    - **H·ªá s·ªë t∆∞∆°ng quan (R)**: ƒê√°nh gi√° m·ª©c ƒë·ªô t∆∞∆°ng quan gi·ªØa gi√° tr·ªã th·ª±c t·∫ø v√† gi√° tr·ªã d·ª± ƒëo√°n.
    - **H·ªá s·ªë x√°c ƒë·ªãnh (R¬≤)**: ƒêo l∆∞·ªùng ph·∫ßn trƒÉm bi·∫øn ƒë·ªông c·ªßa bi·∫øn ph·ª• thu·ªôc c√≥ th·ªÉ gi·∫£i th√≠ch b·ªüi c√°c bi·∫øn ƒë·ªôc l·∫≠p:
    """)
    st.latex(r"""
    R^2 = 1 - \frac{\sum (y_i - \hat{y}_i)^2}{\sum (y_i - \bar{y})^2}
    """)

    st.write("""
    - **Adjusted R¬≤**: ƒêi·ªÅu ch·ªânh cho s·ªë l∆∞·ª£ng bi·∫øn ƒë·ªôc l·∫≠p, gi√∫p tr√°nh overfitting:
    """)
    st.latex(r"""
    R^2_{adj} = 1 - \left( \frac{(1 - R^2)(n - 1)}{n - k - 1} \right)
    """)

    st.write("""
    Trong ƒë√≥:
    - \( n \): S·ªë l∆∞·ª£ng quan s√°t.
    - \( k \): S·ªë l∆∞·ª£ng bi·∫øn ƒë·ªôc l·∫≠p.
    - \( \bar{y} \): Gi√° tr·ªã trung b√¨nh c·ªßa bi·∫øn ph·ª• thu·ªôc.

    - **Sai s·ªë chu·∫©n (SE)**: ƒê√°nh gi√° m·ª©c ƒë·ªô ph√¢n t√°n c·ªßa sai s·ªë d·ª± ƒëo√°n quanh gi√° tr·ªã th·ª±c t·∫ø:
    """)
    st.latex(r"""
    SE = \sqrt{\frac{\sum (y_i - \hat{y}_i)^2}{n - k - 1}}
    """)

    st.write("""
    C√°c ch·ªâ s·ªë n√†y gi√∫p ƒë√°nh gi√° ƒë·ªô ch√≠nh x√°c v√† kh·∫£ nƒÉng kh√°i qu√°t h√≥a c·ªßa m√¥ h√¨nh h·ªìi quy tuy·∫øn t√≠nh b·ªôi.
    """)

    # Gi·ªõi thi·ªáu Polynomial Regression
    st.write("## 2. Polynomial Regression")

    st.latex(r"""
    y = w_0 + w_1x + w_2x^2 + w_3x^3 + \dots + w_nx^n
    """)

    st.write("Polynomial Regression m·ªü r·ªông m√¥ h√¨nh tuy·∫øn t√≠nh b·∫±ng c√°ch th√™m c√°c b·∫≠c cao h∆°n c·ªßa bi·∫øn ƒë·∫ßu v√†o.")

    # V·∫Ω bi·ªÉu ƒë·ªì so s√°nh
    st.write("## 3. Minh h·ªça tr·ª±c quan")

    # T·∫°o d·ªØ li·ªáu m·∫´u
    np.random.seed(0)
    x = np.sort(5 * np.random.rand(20, 1), axis=0)
    y = 2 * x**2 - 3 * x + np.random.randn(20, 1) * 2

    # H·ªìi quy tuy·∫øn t√≠nh
    lin_reg = LinearRegression()
    lin_reg.fit(x, y)
    y_pred_linear = lin_reg.predict(x)

    # H·ªìi quy b·∫≠c hai
    poly_features = PolynomialFeatures(degree=2)
    x_poly = poly_features.fit_transform(x)
    poly_reg = LinearRegression()
    poly_reg.fit(x_poly, y)
    y_pred_poly = poly_reg.predict(x_poly)

    # V·∫Ω bi·ªÉu ƒë·ªì
    fig, ax = plt.subplots(figsize=(6, 4))
    ax.scatter(x, y, color='blue', label='D·ªØ li·ªáu th·ª±c t·∫ø')
    ax.plot(x, y_pred_linear, color='red', label='Multiple Linear Regression')
    ax.plot(x, y_pred_poly, color='green', label='Polynomial Regression (b·∫≠c 2)')
    ax.set_xlabel("X")
    ax.set_ylabel("Y")
    ax.legend()
    st.pyplot(fig)
if __name__ == "__main__":
    bt_buoi3()