import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
import mlflow
import os
import time
from datetime import datetime
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import Callback
import plotly.express as px

# ======================================
# PHáº¦N 1: LÃ THUYáº¾T NEURAL NETWORK
# ======================================
def explain_nn():
    st.markdown("""
    ## ğŸ§  Neural Network CÆ¡ Báº£n

    **Neural Network (Máº¡ng nÆ¡-ron nhÃ¢n táº¡o - ANN)** lÃ  má»™t mÃ´ hÃ¬nh tÃ­nh toÃ¡n láº¥y cáº£m há»©ng tá»« cáº¥u trÃºc vÃ  hoáº¡t Ä‘á»™ng cá»§a nÃ£o bá»™ con ngÆ°á»i. Máº¡ng bao gá»“m nhiá»u nÆ¡-ron nhÃ¢n táº¡o káº¿t ná»‘i vá»›i nhau thÃ nh cÃ¡c lá»›p (layers), giÃºp mÃ´ hÃ¬nh há»c vÃ  nháº­n diá»‡n cÃ¡c máº«u trong dá»¯ liá»‡u.

    ### ğŸ”° Kiáº¿n trÃºc cÆ¡ báº£n:
    """)
    
    st.markdown("""
    ### ğŸ“Œ Cáº¥u trÃºc cá»§a má»™t máº¡ng nÆ¡-ron nhÃ¢n táº¡o gá»“m ba loáº¡i lá»›p chÃ­nh:
    1. **Input Layer**: Lá»›p tiáº¿p nháº­n dá»¯ liá»‡u Ä‘áº§u vÃ o.
    2. **Hidden Layers**: Xá»­ lÃ½ thÃ´ng tin thÃ´ng qua cÃ¡c trá»ng sá»‘ (weights) vÃ  hÃ m kÃ­ch hoáº¡t.
    3. **Output Layer**: Lá»›p Ä‘Æ°a ra káº¿t quáº£ dá»± Ä‘oÃ¡n.
    """)
    
    st.image("buoi7/img1.webp", caption="Cáº¥u trÃºc máº¡ng nÆ¡-ron(medium.com)", use_container_width="auto")
    
   

    st.markdown("""
    ## ğŸ“Œ CÃ´ng thá»©c toÃ¡n há»c trong Neural Network:
    Má»—i nÆ¡-ron trong má»™t lá»›p nháº­n tÃ­n hiá»‡u tá»« cÃ¡c nÆ¡-ron lá»›p trÆ°á»›c, nhÃ¢n vá»›i trá»ng sá»‘ (**weights**), cá»™ng vá»›i **bias**, rá»“i Ä‘Æ°a vÃ o má»™t **hÃ m kÃ­ch hoáº¡t** Ä‘á»ƒ quyáº¿t Ä‘á»‹nh tÃ­n hiá»‡u truyá»n Ä‘i.
    """)

    st.markdown("### ğŸ¯ CÃ´ng thá»©c tÃ­nh giÃ¡ trá»‹ Ä‘áº§u ra cá»§a má»™t nÆ¡-ron:")
    st.latex(r" z = \sum_{i=1}^{n} w_i x_i + b ")

    st.markdown(r"""
    Trong Ä‘Ã³:
    - $$ x_i $$ lÃ  Ä‘áº§u vÃ o (**input features**).
    - $$ w_i $$ lÃ  **trá»ng sá»‘** (**weights**) káº¿t ná»‘i vá»›i nÆ¡-ron Ä‘Ã³.
    - $$ b $$ lÃ  **bias** (há»‡ sá»‘ dá»‹ch chuyá»ƒn).
    - $$ z $$ lÃ  tá»•ng cÃ³ trá»ng sá»‘ (**weighted sum**).

    Sau khi tÃ­nh toÃ¡n $$ z $$, nÃ³ sáº½ Ä‘i qua má»™t **hÃ m kÃ­ch hoáº¡t** $$ \sigma(z) $$ Ä‘á»ƒ táº¡o ra giÃ¡ trá»‹ Ä‘áº§u ra.
    """)

    # st.markdown("### ğŸ¯ CÃ´ng thá»©c tÃ­nh Ä‘áº§u ra sau khi qua hÃ m kÃ­ch hoáº¡t:")
    # st.latex(r" a = \sigma(z) ")


    
    st.markdown("""
    ### ğŸ¯ HÃ m KÃ­ch Hoáº¡t (Activation Functions)
    HÃ m kÃ­ch hoáº¡t giÃºp máº¡ng há»c Ä‘Æ°á»£c cÃ¡c tÃ­nh phi tuyáº¿n tÃ­nh, nhá» Ä‘Ã³ cÃ³ thá»ƒ mÃ´ hÃ¬nh hÃ³a cÃ¡c má»‘i quan há»‡ phá»©c táº¡p.
    """)
    
    st.image("buoi7/img2.png", caption="Má»™t sá»‘ hÃ m kÃ­ch hoáº¡t cÆ¡ báº£n", use_container_width="auto")
    
    st.markdown("- **Sigmoid:** Chuyá»ƒn Ä‘á»•i giÃ¡ trá»‹ Ä‘áº§u vÃ o thÃ nh khoáº£ng tá»« 0 Ä‘áº¿n 1, phÃ¹ há»£p cho bÃ i toÃ¡n phÃ¢n loáº¡i nhá»‹ phÃ¢n.")
    st.latex(r"\sigma(z) = \frac{1}{1 + e^{-z}}")

    st.markdown("- **Tanh (Hyperbolic Tangent):** Äáº§u ra náº±m trong khoáº£ng tá»« -1 Ä‘áº¿n 1, giÃºp xá»­ lÃ½ dá»¯ liá»‡u cÃ³ cáº£ giÃ¡ trá»‹ dÆ°Æ¡ng vÃ  Ã¢m.")
    st.latex(r"\tanh(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}}")

    st.markdown("- **ReLU (Rectified Linear Unit):** Náº¿u Ä‘áº§u vÃ o Ã¢m thÃ¬ báº±ng 0, cÃ²n náº¿u dÆ°Æ¡ng thÃ¬ giá»¯ nguyÃªn giÃ¡ trá»‹.")
    st.latex(r"ReLU(z) = \max(0, z)")
    
   

    st.markdown("### ğŸ”„ QuÃ¡ trÃ¬nh huáº¥n luyá»‡n Neural Network")
    st.markdown("Máº¡ng nÆ¡-ron há»c báº±ng cÃ¡ch cáº­p nháº­t cÃ¡c trá»ng sá»‘ thÃ´ng qua hai giai Ä‘oáº¡n chÃ­nh:")

    st.markdown("#### 1ï¸âƒ£ Lan truyá»n thuáº­n (Forward Propagation)")
    st.markdown("- Input Ä‘i qua tá»«ng lá»›p nÆ¡-ron, tÃ­nh toÃ¡n Ä‘áº§u ra:")
    st.latex(r"a^{(l)} = \sigma(W^{(l)} a^{(l-1)} + b^{(l)})")

    st.markdown("Trong Ä‘Ã³:")
    st.markdown(r"- $$ a^{(l)} $$: Äáº§u ra cá»§a lá»›p thá»© $$l $$.")
    st.markdown(r"- $$ W^{(l)} $$: Ma tráº­n trá»ng sá»‘ giá»¯a lá»›p $$l-1 $$ vÃ  lá»›p $$ l $$.")
    st.markdown(r"- $$ a^{(l-1)} $$: Äáº§u ra cá»§a lá»›p trÆ°á»›c Ä‘Ã³ (hoáº·c lÃ  Ä‘áº§u vÃ o náº¿u $$ l = 1 $$).")
    st.markdown(r"- $$b^{(l)} $$: Bias cá»§a lá»›p $$ l $$.")
    st.markdown(r"- $$ \sigma(z) $$: HÃ m kÃ­ch hoáº¡t (ReLU, Sigmoid, Tanh,...).")

    st.markdown("#### 2ï¸âƒ£ TÃ­nh toÃ¡n loss")
    st.markdown("- HÃ m máº¥t mÃ¡t Ä‘o lÆ°á»ng sai sá»‘ giá»¯a dá»± Ä‘oÃ¡n vÃ  thá»±c táº¿.")
    st.markdown("- VÃ­ dá»¥: Mean Squared Error (MSE) cho bÃ i toÃ¡n há»“i quy:")
    st.latex(r"L = \frac{1}{N} \sum (y_{true} - y_{pred})^2")

    st.markdown("- Cross-Entropy Loss cho bÃ i toÃ¡n phÃ¢n loáº¡i:")
    st.latex(r"L = - \sum y_{true} \log(y_{pred})")

    st.markdown("Trong Ä‘Ã³:")
    st.markdown(r"- $$ L $$: GiÃ¡ trá»‹ hÃ m máº¥t mÃ¡t.")
    st.markdown(r"- $$ N $$: Sá»‘ lÆ°á»£ng máº«u trong táº­p dá»¯ liá»‡u.")
    st.markdown(r"- $$y_{true} $$: NhÃ£n thá»±c táº¿ cá»§a dá»¯ liá»‡u.")
    st.markdown(r"- $$y_{pred} $$: Dá»± Ä‘oÃ¡n cá»§a mÃ´ hÃ¬nh.")

    st.markdown("#### 3ï¸âƒ£ Lan truyá»n ngÆ°á»£c (Backpropagation)")
    st.markdown("- TÃ­nh Ä‘áº¡o hÃ m cá»§a hÃ m máº¥t mÃ¡t theo trá»ng sá»‘.")
    st.markdown("- Sá»­ dá»¥ng thuáº­t toÃ¡n tá»‘i Æ°u Ä‘á»ƒ cáº­p nháº­t trá»ng sá»‘.")

    st.markdown("Lan truyá»n ngÆ°á»£c dá»±a trÃªn cÃ´ng thá»©c:")
    st.latex(r"\frac{\partial L}{\partial W^{(l)}} = \frac{\partial L}{\partial a^{(l)}} \cdot \frac{\partial a^{(l)}}{\partial z^{(l)}} \cdot \frac{\partial z^{(l)}}{\partial W^{(l)}}")

    st.markdown("Trong Ä‘Ã³:")
    st.markdown(r"- $$\frac{\partial L}{\partial W^{(l)}} $$: Äáº¡o hÃ m cá»§a loss theo trá»ng sá»‘ $$ W^{(l)} $$.")
    st.markdown(r"- $$ \frac{\partial L}{\partial a^{(l)}} $$: Äáº¡o hÃ m cá»§a loss theo Ä‘áº§u ra cá»§a lá»›p \( l \).")
    st.markdown(r"- $$ \frac{\partial a^{(l)}}{\partial z^{(l)}} $$: Äáº¡o hÃ m cá»§a hÃ m kÃ­ch hoáº¡t.")
    st.markdown(r"- $$ \frac{\partial z^{(l)}}{\partial W^{(l)}} $$: Äáº¡o hÃ m cá»§a Ä‘áº§u vÃ o trÆ°á»›c lá»›p kÃ­ch hoáº¡t theo trá»ng sá»‘.")

    st.markdown("#### 4ï¸âƒ£ Tá»‘i Æ°u hÃ³a")
    st.markdown("- **Gradient Descent:** Cáº­p nháº­t trá»ng sá»‘ báº±ng cÃ¡ch Ä‘i theo hÆ°á»›ng giáº£m cá»§a gradient.")
    st.latex(r"W^{(l)} = W^{(l)} - \alpha \frac{\partial L}{\partial W^{(l)}}")
    st.markdown("- **Momentum:** ThÃªm Ä‘á»™ng lÆ°á»£ng giÃºp tá»‘i Æ°u nhanh hÆ¡n.")
    st.latex(r"v_t = \beta v_{t-1} + (1 - \beta) \frac{\partial L}{\partial W^{(l)}}")
    st.latex(r"W^{(l)} = W^{(l)} - \alpha v_t")
    st.markdown("- **Adam (Adaptive Moment Estimation):** Káº¿t há»£p Momentum vÃ  RMSprop Ä‘á»ƒ Ä‘áº¡t hiá»‡u suáº¥t tá»‘i Æ°u.")
    st.latex(r"m_t = \beta_1 m_{t-1} + (1 - \beta_1) \frac{\partial L}{\partial W^{(l)}}")
    st.latex(r"v_t = \beta_2 v_{t-1} + (1 - \beta_2) \left(\frac{\partial L}{\partial W^{(l)}}\right)^2")
    st.latex(r"\hat{m_t} = \frac{m_t}{1 - \beta_1^t}, \quad \hat{v_t} = \frac{v_t}{1 - \beta_2^t}")
    st.latex(r"W^{(l)} = W^{(l)} - \alpha \frac{\hat{m_t}}{\sqrt{\hat{v_t}} + \epsilon}")

    st.markdown("Trong Ä‘Ã³:")
    st.markdown(r"- $$ \alpha $$: Tá»‘c Ä‘á»™ há»c (learning rate).")
    st.markdown(r"- $$ v_t $$: GiÃ¡ trá»‹ Ä‘á»™ng lÆ°á»£ng táº¡i thá»i Ä‘iá»ƒm $$ t $$.")
    st.markdown(r"- $$ \beta, \beta_1, \beta_2 $$: Há»‡ sá»‘ Momentum hoáº·c Adam.")
    st.markdown(r"- $$ m_t $$, $$ v_t $$: Trung bÃ¬nh trá»ng sá»‘ vÃ  phÆ°Æ¡ng sai cá»§a gradient.")
    st.markdown(r"- $$ \epsilon $$: Sá»‘ ráº¥t nhá» Ä‘á»ƒ trÃ¡nh chia cho 0.")

    st.markdown("""
    ### ğŸ” Káº¿t Luáº­n
    Neural Network lÃ  má»™t mÃ´ hÃ¬nh máº¡nh máº½ trong Machine Learning vÃ  Deep Learning, cÃ³ thá»ƒ há»c Ä‘Æ°á»£c cÃ¡c Ä‘áº·c trÆ°ng phá»©c táº¡p tá»« dá»¯ liá»‡u. Hiá»ƒu rÃµ cÃ¡ch hoáº¡t Ä‘á»™ng giÃºp ta tá»‘i Æ°u hÃ³a mÃ´ hÃ¬nh Ä‘á»ƒ Ä‘áº¡t hiá»‡u suáº¥t cao hÆ¡n.
    """)
    
    
def data():
    st.header("MNIST Dataset")
    st.write("""
      **MNIST** lÃ  má»™t trong nhá»¯ng bá»™ dá»¯ liá»‡u ná»•i tiáº¿ng vÃ  phá»• biáº¿n nháº¥t trong cá»™ng Ä‘á»“ng há»c mÃ¡y, 
      Ä‘áº·c biá»‡t lÃ  trong cÃ¡c nghiÃªn cá»©u vá» nháº­n diá»‡n máº«u vÃ  phÃ¢n loáº¡i hÃ¬nh áº£nh.
  
      - Bá»™ dá»¯ liá»‡u bao gá»“m tá»•ng cá»™ng **70.000 áº£nh chá»¯ sá»‘ viáº¿t tay** tá»« **0** Ä‘áº¿n **9**, 
        má»—i áº£nh cÃ³ kÃ­ch thÆ°á»›c **28 x 28 pixel**.
      - Chia thÃ nh:
        - **Training set**: 60.000 áº£nh Ä‘á»ƒ huáº¥n luyá»‡n.
        - **Test set**: 10.000 áº£nh Ä‘á»ƒ kiá»ƒm tra.
      - Má»—i hÃ¬nh áº£nh lÃ  má»™t chá»¯ sá»‘ viáº¿t tay, Ä‘Æ°á»£c chuáº©n hÃ³a vÃ  chuyá»ƒn thÃ nh dáº¡ng grayscale (Ä‘en tráº¯ng).
  
      Dá»¯ liá»‡u nÃ y Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i Ä‘á»ƒ xÃ¢y dá»±ng cÃ¡c mÃ´ hÃ¬nh nháº­n diá»‡n chá»¯ sá»‘.
      """)

    st.subheader("Má»™t sá»‘ hÃ¬nh áº£nh tá»« MNIST Dataset")
    st.image("buoi4/img3.png", caption="Má»™t sá»‘ hÃ¬nh áº£nh tá»« MNIST Dataset", use_container_width ="auto")

    st.subheader("á»¨ng dá»¥ng thá»±c táº¿ cá»§a MNIST")
    st.write("""
      Bá»™ dá»¯ liá»‡u MNIST Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng trong nhiá»u á»©ng dá»¥ng nháº­n dáº¡ng chá»¯ sá»‘ viáº¿t tay, cháº³ng háº¡n nhÆ°:
      - Nháº­n diá»‡n sá»‘ trÃªn cÃ¡c hoÃ¡ Ä‘Æ¡n thanh toÃ¡n, biÃªn lai cá»­a hÃ ng.
      - Xá»­ lÃ½ chá»¯ sá»‘ trÃªn cÃ¡c bÆ°u kiá»‡n gá»­i qua bÆ°u Ä‘iá»‡n.
      - á»¨ng dá»¥ng trong cÃ¡c há»‡ thá»‘ng nháº­n diá»‡n tÃ i liá»‡u tá»± Ä‘á»™ng.
    """)

    st.subheader("VÃ­ dá»¥ vá» cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y vá»›i MNIST")
    st.write("""
      CÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y phá»• biáº¿n Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i bá»™ dá»¯ liá»‡u MNIST bao gá»“m:
      - **Logistic Regression**
      - **Decision Trees**
      - **K-Nearest Neighbors (KNN)**
      - **Support Vector Machines (SVM)**
      - **Convolutional Neural Networks (CNNs)**
    """)

    st.subheader("ğŸ“Š Minh há»a dá»¯ liá»‡u MNIST")

    # Äá»c vÃ  hiá»ƒn thá»‹ áº£nh GIF minh há»a
    gif_path = "buoi7/g1.gif"  # Thay báº±ng Ä‘Æ°á»ng dáº«n thá»±c táº¿
    st.image(gif_path, caption="HÃ¬nh áº£nh minh há»a dá»¯ liá»‡u MNIST", use_container_width="auto")

    # MÃ´ táº£ vá» dá»¯ liá»‡u MNIST
    st.write("""
    Dá»¯ liá»‡u MNIST bao gá»“m cÃ¡c hÃ¬nh áº£nh chá»¯ sá»‘ viáº¿t tay cÃ³ kÃ­ch thÆ°á»›c **28x28 pixels**.  
    Má»—i áº£nh lÃ  má»™t **ma tráº­n 28x28**, vá»›i má»—i pixel cÃ³ giÃ¡ trá»‹ tá»« **0 Ä‘áº¿n 255**.  
    Khi Ä‘Æ°a vÃ o mÃ´ hÃ¬nh, áº£nh sáº½ Ä‘Æ°á»£c biáº¿n Ä‘á»•i thÃ nh **784 features (28x28)** Ä‘á»ƒ lÃ m Ä‘áº§u vÃ o cho máº¡ng nÆ¡-ron.  
    MÃ´ hÃ¬nh sá»­ dá»¥ng cÃ¡c lá»›p áº©n Ä‘á»ƒ há»c vÃ  dá»± Ä‘oÃ¡n chÃ­nh xÃ¡c chá»¯ sá»‘ tá»« hÃ¬nh áº£nh.
    """)

    
    



# ======================================

# def input_mlflow():
#     DAGSHUB_MLFLOW_URI = "https://dagshub.com/Phuocbinh2003/Hoc_may_python.mlflow"
#     mlflow.set_tracking_uri(DAGSHUB_MLFLOW_URI)
#     st.session_state['mlflow_url'] = DAGSHUB_MLFLOW_URI
#     os.environ["MLFLOW_TRACKING_USERNAME"] = "Phuocbinh2003"
#     os.environ["MLFLOW_TRACKING_PASSWORD"] = "c1495823c8f9156923b06f15899e989db7e62052"
#     mlflow.set_experiment("NN")

import streamlit as st
import numpy as np
import time
import mlflow
import mlflow.keras
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.model_selection import train_test_split, StratifiedKFold
from mlflow.models.signature import infer_signature

# Load dá»¯ liá»‡u MNIST
def load_mnist_data():
    X = np.load("buoi4/X.npy")
    y = np.load("buoi4/y.npy")
    return X, y

def split_data():
    st.title("ğŸ“Œ Chia dá»¯ liá»‡u Train/Test")
    
    # Äá»c dá»¯ liá»‡u
    X, y = load_mnist_data()
    total_samples = X.shape[0] 
    
    # Thanh kÃ©o chá»n sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ train
    num_samples = st.slider("ğŸ“Œ Chá»n sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ huáº¥n luyá»‡n:", 1000, total_samples, 10000)
    num_samples =num_samples -10
    # Thanh kÃ©o chá»n tá»· lá»‡ Train/Test
    test_size = st.slider("ğŸ“Œ Chá»n % dá»¯ liá»‡u Test", 10, 50, 20)
    train_size = 100 - test_size
    val_size = st.slider("ğŸ“Œ Chá»n % dá»¯ liá»‡u Validation (trong Train)", 0, 50, 15)
    
    st.write(f"ğŸ“Œ **Tá»· lá»‡ phÃ¢n chia:** Test={test_size}%, Validation={val_size}%, Train={train_size - val_size}%")
    
    if st.button("âœ… XÃ¡c nháº­n & LÆ°u"):
        X_selected, _, y_selected, _ = train_test_split(X, y, train_size=num_samples, stratify=y, random_state=42)
        X_train_full, X_test, y_train_full, y_test = train_test_split(X_selected, y_selected, test_size=test_size/100, stratify=y_selected, random_state=42)
        X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=val_size / (100 - test_size), stratify=y_train_full, random_state=42)
        
        # LÆ°u vÃ o session_state
        st.session_state.update({
            "X_train": X_train, "X_val": X_val, "X_test": X_test,
            "y_train": y_train, "y_val": y_val, "y_test": y_test
        })
        
        summary_df = pd.DataFrame({"Táº­p dá»¯ liá»‡u": ["Train", "Validation", "Test"], "Sá»‘ lÆ°á»£ng máº«u": [X_train.shape[0], X_val.shape[0], X_test.shape[0]]})
        st.success("âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia thÃ nh cÃ´ng!")
        st.table(summary_df)

def thi_nghiem():
   
    
    if "X_train" not in st.session_state:
        st.error("âš ï¸ ChÆ°a cÃ³ dá»¯ liá»‡u! HÃ£y chia dá»¯ liá»‡u trÆ°á»›c.")
        return
    
    X_train, X_val, X_test = [st.session_state[k].reshape(-1, 28 * 28) / 255.0 for k in ["X_train", "X_val", "X_test"]]
    y_train, y_val, y_test = [st.session_state[k] for k in ["y_train", "y_val", "y_test"]]
    
    k_folds = st.slider("Sá»‘ fold cho Cross-Validation:", 3, 10, 5)
    num_layers = st.slider("Sá»‘ lá»›p áº©n:", 1, 5, 2)
    num_neurons = st.slider("Sá»‘ neuron má»—i lá»›p:", 32, 512, 128, 32)
    activation = st.selectbox("HÃ m kÃ­ch hoáº¡t:", ["relu", "sigmoid", "tanh"])
    optimizer = st.selectbox("Optimizer:", ["adam", "sgd", "rmsprop"])
    epochs = st.slider("ğŸ•° Sá»‘ epochs:", min_value=1, max_value=50, value=20, step=1)
    learning_rate = st.slider("âš¡ Tá»‘c Ä‘á»™ há»c (Learning Rate):", min_value=1e-5, max_value=1e-1, value=1e-3, step=1e-5, format="%.5f")

    loss_fn = "sparse_categorical_crossentropy"
    run_name = st.text_input("ğŸ”¹ Nháº­p tÃªn Run:", "Default_Run")
    st.session_state['run_name'] = run_name
    
    if st.button("ğŸš€ Huáº¥n luyá»‡n mÃ´ hÃ¬nh"):
        with st.spinner("Äang huáº¥n luyá»‡n..."):
            mlflow.start_run(run_name=run_name)
            mlflow.log_params({
                "num_layers": num_layers,
                "num_neurons": num_neurons,
                "activation": activation,
                "optimizer": optimizer,
                "learning_rate": learning_rate,
                "k_folds": k_folds,
                "epochs": epochs
            })

            kf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)
            accuracies, losses = [], []

            # Thanh tiáº¿n trÃ¬nh tá»•ng quÃ¡t cho toÃ n bá»™ quÃ¡ trÃ¬nh huáº¥n luyá»‡n
            training_progress = st.progress(0)
            training_status = st.empty()

            for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train)):
                X_k_train, X_k_val = X_train[train_idx], X_train[val_idx]
                y_k_train, y_k_val = y_train[train_idx], y_train[val_idx]

                model = keras.Sequential([
                    layers.Input(shape=(X_k_train.shape[1],))
                ] + [
                    layers.Dense(num_neurons, activation=activation) for _ in range(num_layers)
                ] + [
                    layers.Dense(10, activation="softmax")
                ])

                # Chá»n optimizer vá»›i learning rate
                if optimizer == "adam":
                    opt = keras.optimizers.Adam(learning_rate=learning_rate)
                elif optimizer == "sgd":
                    opt = keras.optimizers.SGD(learning_rate=learning_rate)
                else:
                    opt = keras.optimizers.RMSprop(learning_rate=learning_rate)

                model.compile(optimizer=opt, loss=loss_fn, metrics=["accuracy"])

                start_time = time.time()
                history = model.fit(X_k_train, y_k_train, epochs=epochs, validation_data=(X_k_val, y_k_val), verbose=0)

                elapsed_time = time.time() - start_time
                accuracies.append(history.history["val_accuracy"][-1])
                losses.append(history.history["val_loss"][-1])

                # Cáº­p nháº­t thanh tiáº¿n trÃ¬nh chÃ­nh (theo fold)
                st.write(fold_idx ,k_folds)
                
                progress_percent = int((fold_idx + 1 / k_folds))
                training_progress.progress(progress_percent)
                
                            

                
                training_status.text(f"â³ Äang huáº¥n luyá»‡n... {progress_percent*100}%")

            avg_val_accuracy = np.mean(accuracies)
            avg_val_loss = np.mean(losses)

            mlflow.log_metrics({
                "avg_val_accuracy": avg_val_accuracy,
                "avg_val_loss": avg_val_loss,
                "elapsed_time": elapsed_time
            })

            test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)
            mlflow.log_metrics({"test_accuracy": test_accuracy, "test_loss": test_loss})

            mlflow.end_run()
            st.session_state["trained_model"] = model

            # HoÃ n thÃ nh tiáº¿n trÃ¬nh
            training_progress.progress(1.0)
            training_status.text("âœ… Huáº¥n luyá»‡n hoÃ n táº¥t!")

            st.success(f"âœ… Huáº¥n luyá»‡n hoÃ n táº¥t!")
            st.write(f"ğŸ“Š **Äá»™ chÃ­nh xÃ¡c trung bÃ¬nh trÃªn táº­p validation:** {avg_val_accuracy:.4f}")
            st.write(f"ğŸ“Š **Äá»™ chÃ­nh xÃ¡c trÃªn táº­p test:** {test_accuracy:.4f}")
            st.success(f"âœ… ÄÃ£ log dá»¯ liá»‡u cho **{st.session_state['run_name']}** trong MLflow (Neural_Network)! ğŸš€")
            st.markdown(f"ğŸ”— [Truy cáº­p MLflow UI]({st.session_state['mlflow_url']})")


                
            
            

import streamlit as st
import numpy as np
import joblib
import random
import pandas as pd
import time
from PIL import Image
from streamlit_drawable_canvas import st_canvas
from tensorflow.keras.models import load_model

def preprocess_canvas_image(canvas_result):
    """Chuyá»ƒn Ä‘á»•i áº£nh tá»« canvas sang Ä‘á»‹nh dáº¡ng phÃ¹ há»£p Ä‘á»ƒ dá»± Ä‘oÃ¡n."""
    if canvas_result.image_data is None:
        return None
    img = canvas_result.image_data[:, :, :3]  # Chá»‰ láº¥y 3 kÃªnh RGB
    img = Image.fromarray(img).convert("L").resize((28, 28))  # Chuyá»ƒn sang grayscale, resize vá» 28x28
    img = np.array(img) / 255.0  # Chuáº©n hÃ³a vá» [0,1]
    img = img.reshape(1, -1)  # ÄÆ°a vá» dáº¡ng vector giá»‘ng nhÆ° trong `thi_nghiem()`
    return img

def du_doan():
    st.header("âœï¸ Váº½ sá»‘ Ä‘á»ƒ dá»± Ä‘oÃ¡n")

    # ğŸ“¥ Load mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n
    if "trained_model" in st.session_state:
        model = st.session_state["trained_model"]
        st.success("âœ… ÄÃ£ sá»­ dá»¥ng mÃ´ hÃ¬nh vá»«a huáº¥n luyá»‡n!")
    else:
        st.error("âš ï¸ ChÆ°a cÃ³ mÃ´ hÃ¬nh! HÃ£y huáº¥n luyá»‡n trÆ°á»›c.")


    # ğŸ†• Cáº­p nháº­t key cho canvas khi nháº¥n "Táº£i láº¡i"
    if "key_value" not in st.session_state:
        st.session_state.key_value = str(random.randint(0, 1000000))  

    if st.button("ğŸ”„ Táº£i láº¡i náº¿u khÃ´ng tháº¥y canvas"):
        st.session_state.key_value = str(random.randint(0, 1000000))  

    # âœï¸ Váº½ sá»‘
    canvas_result = st_canvas(
        fill_color="black",
        stroke_width=10,
        stroke_color="white",
        background_color="black",
        height=150,
        width=150,
        drawing_mode="freedraw",
        key=st.session_state.key_value,
        update_streamlit=True
    )

    if st.button("Dá»± Ä‘oÃ¡n sá»‘"):
        img = preprocess_canvas_image(canvas_result)

        if img is not None:
            st.image(Image.fromarray((img.reshape(28, 28) * 255).astype(np.uint8)), caption="áº¢nh sau xá»­ lÃ½", width=100)

            # Dá»± Ä‘oÃ¡n sá»‘
            prediction = model.predict(img)
            predicted_number = np.argmax(prediction, axis=1)[0]
            max_confidence = np.max(prediction)

            st.subheader(f"ğŸ”¢ Dá»± Ä‘oÃ¡n: {predicted_number}")
            st.write(f"ğŸ“Š Má»©c Ä‘á»™ tin cáº­y: {max_confidence:.2%}")

            # Hiá»ƒn thá»‹ báº£ng confidence score
            prob_df = pd.DataFrame(prediction.reshape(1, -1), columns=[str(i) for i in range(10)]).T
            prob_df.columns = ["Má»©c Ä‘á»™ tin cáº­y"]
            st.bar_chart(prob_df)

        else:
            st.error("âš ï¸ HÃ£y váº½ má»™t sá»‘ trÆ°á»›c khi báº¥m Dá»± Ä‘oÃ¡n!")

    
from datetime import datetime    
import streamlit as st
import mlflow
from datetime import datetime

def show_experiment_selector():
    st.title("ğŸ“Š MLflow")
    
    # Káº¿t ná»‘i vá»›i DAGsHub MLflow Tracking
    mlflow.set_tracking_uri("https://dagshub.com/Phuocbinh2003/Hoc_may_python.mlflow")
    
    # Láº¥y danh sÃ¡ch táº¥t cáº£ experiments
    experiment_name = "Neural_Network"
    experiments = mlflow.search_experiments()
    selected_experiment = next((exp for exp in experiments if exp.name == experiment_name), None)

    if not selected_experiment:
        st.error(f"âŒ Experiment '{experiment_name}' khÃ´ng tá»“n táº¡i!")
        return

    st.subheader(f"ğŸ“Œ Experiment: {experiment_name}")
    st.write(f"**Experiment ID:** {selected_experiment.experiment_id}")
    st.write(f"**Tráº¡ng thÃ¡i:** {'Active' if selected_experiment.lifecycle_stage == 'active' else 'Deleted'}")
    st.write(f"**Vá»‹ trÃ­ lÆ°u trá»¯:** {selected_experiment.artifact_location}")

    # Láº¥y danh sÃ¡ch runs trong experiment
    runs = mlflow.search_runs(experiment_ids=[selected_experiment.experiment_id])

    if runs.empty:
        st.warning("âš  KhÃ´ng cÃ³ runs nÃ o trong experiment nÃ y.")
        return

    st.write("### ğŸƒâ€â™‚ï¸ CÃ¡c Runs gáº§n Ä‘Ã¢y:")
    
    # Láº¥y danh sÃ¡ch run_name tá»« params
    run_info = []
    for _, run in runs.iterrows():
        run_id = run["run_id"]
        run_tags = mlflow.get_run(run_id).data.tags
        run_name = run_tags.get("mlflow.runName", f"Run {run_id[:8]}")  # Láº¥y tá»« tags
        run_info.append((run_name, run_id))
    
    # Táº¡o dictionary Ä‘á»ƒ map run_name -> run_id
    run_name_to_id = dict(run_info)
    run_names = list(run_name_to_id.keys())
    
    # Chá»n run theo run_name
    selected_run_name = st.selectbox("ğŸ” Chá»n má»™t run:", run_names)
    selected_run_id = run_name_to_id[selected_run_name]

    # Hiá»ƒn thá»‹ thÃ´ng tin chi tiáº¿t cá»§a run Ä‘Æ°á»£c chá»n
    selected_run = mlflow.get_run(selected_run_id)

    if selected_run:
        st.subheader(f"ğŸ“Œ ThÃ´ng tin Run: {selected_run_name}")
        st.write(f"**Run ID:** {selected_run_id}")
        st.write(f"**Tráº¡ng thÃ¡i:** {selected_run.info.status}")
        
        start_time_ms = selected_run.info.start_time  # Thá»i gian lÆ°u dÆ°á»›i dáº¡ng milliseconds
        if start_time_ms:
            start_time = datetime.fromtimestamp(start_time_ms / 1000).strftime("%Y-%m-%d %H:%M:%S")
        else:
            start_time = "KhÃ´ng cÃ³ thÃ´ng tin"
        
        st.write(f"**Thá»i gian cháº¡y:** {start_time}")

        # Hiá»ƒn thá»‹ thÃ´ng sá»‘ Ä‘Ã£ log
        params = selected_run.data.params
        metrics = selected_run.data.metrics

        if params:
            st.write("### âš™ï¸ Parameters:")
            st.json(params)

        if metrics:
            st.write("### ğŸ“Š Metrics:")
            st.json(metrics)

        # Kiá»ƒm tra vÃ  hiá»ƒn thá»‹ dataset artifact
        dataset_path = f"{selected_experiment.artifact_location}/{selected_run_id}/artifacts/dataset.npy"
        st.write("### ğŸ“‚ Dataset:")
        st.write(f"ğŸ“¥ [Táº£i dataset]({dataset_path})")
    else:
        st.warning("âš  KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin cho run nÃ y.")

        
        
        
          
import mlflow
import os
from mlflow.tracking import MlflowClient
def Neural_Network():
    #st.title("ğŸš€ MLflow DAGsHub Tracking vá»›i Streamlit")
    
    if "mlflow_initialized" not in st.session_state:   
        DAGSHUB_MLFLOW_URI = "https://dagshub.com/Phuocbinh2003/Hoc_may_python.mlflow"
        st.session_state['mlflow_url']=DAGSHUB_MLFLOW_URI
        mlflow.set_tracking_uri(DAGSHUB_MLFLOW_URI)

        os.environ["MLFLOW_TRACKING_USERNAME"] = "Phuocbinh2003"
        os.environ["MLFLOW_TRACKING_PASSWORD"] = "c1495823c8f9156923b06f15899e989db7e62052"
        st.session_state.mlflow_initialized = True
        mlflow.set_experiment("Neural_Network")   
        
    
    
    # Táº¡o cÃ¡c tab vá»›i tiÃªu Ä‘á» tÆ°Æ¡ng á»©ng
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ“˜ LÃ½ thuyáº¿t NEURAL NETWORK",
        "ğŸ“Š Máº«u dá»¯ liá»‡u",
        "ğŸ§  Huáº¥n luyá»‡n",
        "ğŸ–¥ï¸ DEMO",
        "ğŸ”¥ MLflow"
    ])

    # Ná»™i dung tá»«ng tab
    with tab1:
        explain_nn()

    with tab2:
        data()

    with tab3:
        st.title("ğŸ§  Huáº¥n luyá»‡n Neural Network trÃªn MNIST")
        split_data()
        thi_nghiem()

    with tab4:
        du_doan()

    with tab5:
        show_experiment_selector()



if __name__ == "__main__":
    Neural_Network()