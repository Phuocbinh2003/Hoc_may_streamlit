import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
import mlflow
import os
import time
from datetime import datetime
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import Callback
import plotly.express as px

# ======================================
# PH·∫¶N 1: L√ù THUY·∫æT NEURAL NETWORK
# ======================================
def explain_nn():
    st.markdown("""
    ## üß† Neural Network C∆° B·∫£n

    **Neural Network (M·∫°ng n∆°-ron nh√¢n t·∫°o - ANN)** l√† m·ªôt m√¥ h√¨nh t√≠nh to√°n l·∫•y c·∫£m h·ª©ng t·ª´ c·∫•u tr√∫c v√† ho·∫°t ƒë·ªông c·ªßa n√£o b·ªô con ng∆∞·ªùi. M·∫°ng bao g·ªìm nhi·ªÅu n∆°-ron nh√¢n t·∫°o k·∫øt n·ªëi v·ªõi nhau th√†nh c√°c l·ªõp (layers), gi√∫p m√¥ h√¨nh h·ªçc v√† nh·∫≠n di·ªán c√°c m·∫´u trong d·ªØ li·ªáu.

    ### üî∞ Ki·∫øn tr√∫c c∆° b·∫£n:
    """)
    
    st.markdown("""
    ### üìå C·∫•u tr√∫c c·ªßa m·ªôt m·∫°ng n∆°-ron nh√¢n t·∫°o g·ªìm ba lo·∫°i l·ªõp ch√≠nh:
    1. **Input Layer**: L·ªõp ti·∫øp nh·∫≠n d·ªØ li·ªáu ƒë·∫ßu v√†o.
    2. **Hidden Layers**: X·ª≠ l√Ω th√¥ng tin th√¥ng qua c√°c tr·ªçng s·ªë (weights) v√† h√†m k√≠ch ho·∫°t.
    3. **Output Layer**: L·ªõp ƒë∆∞a ra k·∫øt qu·∫£ d·ª± ƒëo√°n.
    """)
    
    st.image("buoi7/img1.webp", caption="C·∫•u tr√∫c m·∫°ng n∆°-ron(medium.com)", use_container_width="auto")
    
   

    st.markdown("""
    ## üìå C√¥ng th·ª©c to√°n h·ªçc trong Neural Network:
    M·ªói n∆°-ron trong m·ªôt l·ªõp nh·∫≠n t√≠n hi·ªáu t·ª´ c√°c n∆°-ron l·ªõp tr∆∞·ªõc, nh√¢n v·ªõi tr·ªçng s·ªë (**weights**), c·ªông v·ªõi **bias**, r·ªìi ƒë∆∞a v√†o m·ªôt **h√†m k√≠ch ho·∫°t** ƒë·ªÉ quy·∫øt ƒë·ªãnh t√≠n hi·ªáu truy·ªÅn ƒëi.
    """)

    st.markdown("### üéØ C√¥ng th·ª©c t√≠nh gi√° tr·ªã ƒë·∫ßu ra c·ªßa m·ªôt n∆°-ron:")
    st.latex(r" z = \sum_{i=1}^{n} w_i x_i + b ")

    st.markdown(r"""
    Trong ƒë√≥:
    - $$ x_i $$ l√† ƒë·∫ßu v√†o (**input features**).
    - $$ w_i $$ l√† **tr·ªçng s·ªë** (**weights**) k·∫øt n·ªëi v·ªõi n∆°-ron ƒë√≥.
    - $$ b $$ l√† **bias** (h·ªá s·ªë d·ªãch chuy·ªÉn).
    - $$ z $$ l√† t·ªïng c√≥ tr·ªçng s·ªë (**weighted sum**).

    Sau khi t√≠nh to√°n $$ z $$, n√≥ s·∫Ω ƒëi qua m·ªôt **h√†m k√≠ch ho·∫°t** $$ \sigma(z) $$ ƒë·ªÉ t·∫°o ra gi√° tr·ªã ƒë·∫ßu ra.
    """)

    # st.markdown("### üéØ C√¥ng th·ª©c t√≠nh ƒë·∫ßu ra sau khi qua h√†m k√≠ch ho·∫°t:")
    # st.latex(r" a = \sigma(z) ")


    
    st.markdown("""
    ### üéØ H√†m K√≠ch Ho·∫°t (Activation Functions)
    H√†m k√≠ch ho·∫°t gi√∫p m·∫°ng h·ªçc ƒë∆∞·ª£c c√°c t√≠nh phi tuy·∫øn t√≠nh, nh·ªù ƒë√≥ c√≥ th·ªÉ m√¥ h√¨nh h√≥a c√°c m·ªëi quan h·ªá ph·ª©c t·∫°p.
    """)
    
    st.image("buoi7/img2.png", caption="M·ªôt s·ªë h√†m k√≠ch ho·∫°t c∆° b·∫£n", use_container_width="auto")
    
    st.markdown("- **Sigmoid:** Chuy·ªÉn ƒë·ªïi gi√° tr·ªã ƒë·∫ßu v√†o th√†nh kho·∫£ng t·ª´ 0 ƒë·∫øn 1, ph√π h·ª£p cho b√†i to√°n ph√¢n lo·∫°i nh·ªã ph√¢n.")
    st.latex(r"\sigma(z) = \frac{1}{1 + e^{-z}}")

    st.markdown("- **Tanh (Hyperbolic Tangent):** ƒê·∫ßu ra n·∫±m trong kho·∫£ng t·ª´ -1 ƒë·∫øn 1, gi√∫p x·ª≠ l√Ω d·ªØ li·ªáu c√≥ c·∫£ gi√° tr·ªã d∆∞∆°ng v√† √¢m.")
    st.latex(r"\tanh(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}}")

    st.markdown("- **ReLU (Rectified Linear Unit):** N·∫øu ƒë·∫ßu v√†o √¢m th√¨ b·∫±ng 0, c√≤n n·∫øu d∆∞∆°ng th√¨ gi·ªØ nguy√™n gi√° tr·ªã.")
    st.latex(r"ReLU(z) = \max(0, z)")
    
   

    st.markdown("### üîÑ Qu√° tr√¨nh hu·∫•n luy·ªán Neural Network")
    st.markdown("M·∫°ng n∆°-ron h·ªçc b·∫±ng c√°ch c·∫≠p nh·∫≠t c√°c tr·ªçng s·ªë th√¥ng qua hai giai ƒëo·∫°n ch√≠nh:")

    st.markdown("#### 1Ô∏è‚É£ Lan truy·ªÅn thu·∫≠n (Forward Propagation)")
    st.markdown("- Input ƒëi qua t·ª´ng l·ªõp n∆°-ron, t√≠nh to√°n ƒë·∫ßu ra:")
    st.latex(r"a^{(l)} = \sigma(W^{(l)} a^{(l-1)} + b^{(l)})")

    st.markdown("Trong ƒë√≥:")
    st.markdown(r"- $$ a^{(l)} $$: ƒê·∫ßu ra c·ªßa l·ªõp th·ª© $$l $$.")
    st.markdown(r"- $$ W^{(l)} $$: Ma tr·∫≠n tr·ªçng s·ªë gi·ªØa l·ªõp $$l-1 $$ v√† l·ªõp $$ l $$.")
    st.markdown(r"- $$ a^{(l-1)} $$: ƒê·∫ßu ra c·ªßa l·ªõp tr∆∞·ªõc ƒë√≥ (ho·∫∑c l√† ƒë·∫ßu v√†o n·∫øu $$ l = 1 $$).")
    st.markdown(r"- $$b^{(l)} $$: Bias c·ªßa l·ªõp $$ l $$.")
    st.markdown(r"- $$ \sigma(z) $$: H√†m k√≠ch ho·∫°t (ReLU, Sigmoid, Tanh,...).")

    st.markdown("#### 2Ô∏è‚É£ T√≠nh to√°n loss")
    st.markdown("- H√†m m·∫•t m√°t ƒëo l∆∞·ªùng sai s·ªë gi·ªØa d·ª± ƒëo√°n v√† th·ª±c t·∫ø.")
    st.markdown("- V√≠ d·ª•: Mean Squared Error (MSE) cho b√†i to√°n h·ªìi quy:")
    st.latex(r"L = \frac{1}{N} \sum (y_{true} - y_{pred})^2")

    st.markdown("- Cross-Entropy Loss cho b√†i to√°n ph√¢n lo·∫°i:")
    st.latex(r"L = - \sum y_{true} \log(y_{pred})")

    st.markdown("Trong ƒë√≥:")
    st.markdown(r"- $$ L $$: Gi√° tr·ªã h√†m m·∫•t m√°t.")
    st.markdown(r"- $$ N $$: S·ªë l∆∞·ª£ng m·∫´u trong t·∫≠p d·ªØ li·ªáu.")
    st.markdown(r"- $$y_{true} $$: Nh√£n th·ª±c t·∫ø c·ªßa d·ªØ li·ªáu.")
    st.markdown(r"- $$y_{pred} $$: D·ª± ƒëo√°n c·ªßa m√¥ h√¨nh.")

    st.markdown("#### 3Ô∏è‚É£ Lan truy·ªÅn ng∆∞·ª£c (Backpropagation)")
    st.markdown("- T√≠nh ƒë·∫°o h√†m c·ªßa h√†m m·∫•t m√°t theo tr·ªçng s·ªë.")
    st.markdown("- S·ª≠ d·ª•ng thu·∫≠t to√°n t·ªëi ∆∞u ƒë·ªÉ c·∫≠p nh·∫≠t tr·ªçng s·ªë.")

    st.markdown("Lan truy·ªÅn ng∆∞·ª£c d·ª±a tr√™n c√¥ng th·ª©c:")
    st.latex(r"\frac{\partial L}{\partial W^{(l)}} = \frac{\partial L}{\partial a^{(l)}} \cdot \frac{\partial a^{(l)}}{\partial z^{(l)}} \cdot \frac{\partial z^{(l)}}{\partial W^{(l)}}")

    st.markdown("Trong ƒë√≥:")
    st.markdown(r"- $$\frac{\partial L}{\partial W^{(l)}} $$: ƒê·∫°o h√†m c·ªßa loss theo tr·ªçng s·ªë $$ W^{(l)} $$.")
    st.markdown(r"- $$ \frac{\partial L}{\partial a^{(l)}} $$: ƒê·∫°o h√†m c·ªßa loss theo ƒë·∫ßu ra c·ªßa l·ªõp \( l \).")
    st.markdown(r"- $$ \frac{\partial a^{(l)}}{\partial z^{(l)}} $$: ƒê·∫°o h√†m c·ªßa h√†m k√≠ch ho·∫°t.")
    st.markdown(r"- $$ \frac{\partial z^{(l)}}{\partial W^{(l)}} $$: ƒê·∫°o h√†m c·ªßa ƒë·∫ßu v√†o tr∆∞·ªõc l·ªõp k√≠ch ho·∫°t theo tr·ªçng s·ªë.")

    st.markdown("#### 4Ô∏è‚É£ T·ªëi ∆∞u h√≥a")
    st.markdown("- **Gradient Descent:** C·∫≠p nh·∫≠t tr·ªçng s·ªë b·∫±ng c√°ch ƒëi theo h∆∞·ªõng gi·∫£m c·ªßa gradient.")
    st.latex(r"W^{(l)} = W^{(l)} - \alpha \frac{\partial L}{\partial W^{(l)}}")
    st.markdown("- **Momentum:** Th√™m ƒë·ªông l∆∞·ª£ng gi√∫p t·ªëi ∆∞u nhanh h∆°n.")
    st.latex(r"v_t = \beta v_{t-1} + (1 - \beta) \frac{\partial L}{\partial W^{(l)}}")
    st.latex(r"W^{(l)} = W^{(l)} - \alpha v_t")
    st.markdown("- **Adam (Adaptive Moment Estimation):** K·∫øt h·ª£p Momentum v√† RMSprop ƒë·ªÉ ƒë·∫°t hi·ªáu su·∫•t t·ªëi ∆∞u.")
    st.latex(r"m_t = \beta_1 m_{t-1} + (1 - \beta_1) \frac{\partial L}{\partial W^{(l)}}")
    st.latex(r"v_t = \beta_2 v_{t-1} + (1 - \beta_2) \left(\frac{\partial L}{\partial W^{(l)}}\right)^2")
    st.latex(r"\hat{m_t} = \frac{m_t}{1 - \beta_1^t}, \quad \hat{v_t} = \frac{v_t}{1 - \beta_2^t}")
    st.latex(r"W^{(l)} = W^{(l)} - \alpha \frac{\hat{m_t}}{\sqrt{\hat{v_t}} + \epsilon}")

    st.markdown("Trong ƒë√≥:")
    st.markdown(r"- $$ \alpha $$: T·ªëc ƒë·ªô h·ªçc (learning rate).")
    st.markdown(r"- $$ v_t $$: Gi√° tr·ªã ƒë·ªông l∆∞·ª£ng t·∫°i th·ªùi ƒëi·ªÉm $$ t $$.")
    st.markdown(r"- $$ \beta, \beta_1, \beta_2 $$: H·ªá s·ªë Momentum ho·∫∑c Adam.")
    st.markdown(r"- $$ m_t $$, $$ v_t $$: Trung b√¨nh tr·ªçng s·ªë v√† ph∆∞∆°ng sai c·ªßa gradient.")
    st.markdown(r"- $$ \epsilon $$: S·ªë r·∫•t nh·ªè ƒë·ªÉ tr√°nh chia cho 0.")

    st.markdown("""
    ### üîç K·∫øt Lu·∫≠n
    Neural Network l√† m·ªôt m√¥ h√¨nh m·∫°nh m·∫Ω trong Machine Learning v√† Deep Learning, c√≥ th·ªÉ h·ªçc ƒë∆∞·ª£c c√°c ƒë·∫∑c tr∆∞ng ph·ª©c t·∫°p t·ª´ d·ªØ li·ªáu. Hi·ªÉu r√µ c√°ch ho·∫°t ƒë·ªông gi√∫p ta t·ªëi ∆∞u h√≥a m√¥ h√¨nh ƒë·ªÉ ƒë·∫°t hi·ªáu su·∫•t cao h∆°n.
    """)
    
    
def data():
    st.header("MNIST Dataset")
    st.write("""
      **MNIST** l√† m·ªôt trong nh·ªØng b·ªô d·ªØ li·ªáu n·ªïi ti·∫øng v√† ph·ªï bi·∫øn nh·∫•t trong c·ªông ƒë·ªìng h·ªçc m√°y, 
      ƒë·∫∑c bi·ªát l√† trong c√°c nghi√™n c·ª©u v·ªÅ nh·∫≠n di·ªán m·∫´u v√† ph√¢n lo·∫°i h√¨nh ·∫£nh.
  
      - B·ªô d·ªØ li·ªáu bao g·ªìm t·ªïng c·ªông **70.000 ·∫£nh ch·ªØ s·ªë vi·∫øt tay** t·ª´ **0** ƒë·∫øn **9**, 
        m·ªói ·∫£nh c√≥ k√≠ch th∆∞·ªõc **28 x 28 pixel**.
      - Chia th√†nh:
        - **Training set**: 60.000 ·∫£nh ƒë·ªÉ hu·∫•n luy·ªán.
        - **Test set**: 10.000 ·∫£nh ƒë·ªÉ ki·ªÉm tra.
      - M·ªói h√¨nh ·∫£nh l√† m·ªôt ch·ªØ s·ªë vi·∫øt tay, ƒë∆∞·ª£c chu·∫©n h√≥a v√† chuy·ªÉn th√†nh d·∫°ng grayscale (ƒëen tr·∫Øng).
  
      D·ªØ li·ªáu n√†y ƒë∆∞·ª£c s·ª≠ d·ª•ng r·ªông r√£i ƒë·ªÉ x√¢y d·ª±ng c√°c m√¥ h√¨nh nh·∫≠n di·ªán ch·ªØ s·ªë.
      """)

    st.subheader("M·ªôt s·ªë h√¨nh ·∫£nh t·ª´ MNIST Dataset")
    st.image("buoi4/img3.png", caption="M·ªôt s·ªë h√¨nh ·∫£nh t·ª´ MNIST Dataset", use_container_width ="auto")

    st.subheader("·ª®ng d·ª•ng th·ª±c t·∫ø c·ªßa MNIST")
    st.write("""
      B·ªô d·ªØ li·ªáu MNIST ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng trong nhi·ªÅu ·ª©ng d·ª•ng nh·∫≠n d·∫°ng ch·ªØ s·ªë vi·∫øt tay, ch·∫≥ng h·∫°n nh∆∞:
      - Nh·∫≠n di·ªán s·ªë tr√™n c√°c ho√° ƒë∆°n thanh to√°n, bi√™n lai c·ª≠a h√†ng.
      - X·ª≠ l√Ω ch·ªØ s·ªë tr√™n c√°c b∆∞u ki·ªán g·ª≠i qua b∆∞u ƒëi·ªán.
      - ·ª®ng d·ª•ng trong c√°c h·ªá th·ªëng nh·∫≠n di·ªán t√†i li·ªáu t·ª± ƒë·ªông.
    """)

    st.subheader("V√≠ d·ª• v·ªÅ c√°c m√¥ h√¨nh h·ªçc m√°y v·ªõi MNIST")
    st.write("""
      C√°c m√¥ h√¨nh h·ªçc m√°y ph·ªï bi·∫øn ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán v·ªõi b·ªô d·ªØ li·ªáu MNIST bao g·ªìm:
      - **Logistic Regression**
      - **Decision Trees**
      - **K-Nearest Neighbors (KNN)**
      - **Support Vector Machines (SVM)**
      - **Convolutional Neural Networks (CNNs)**
    """)

    st.subheader("üìä Minh h·ªça d·ªØ li·ªáu MNIST")

    # ƒê·ªçc v√† hi·ªÉn th·ªã ·∫£nh GIF minh h·ªça
    gif_path = "buoi7/g1.gif"  # Thay b·∫±ng ƒë∆∞·ªùng d·∫´n th·ª±c t·∫ø
    st.image(gif_path, caption="H√¨nh ·∫£nh minh h·ªça d·ªØ li·ªáu MNIST", use_container_width="auto")

    # M√¥ t·∫£ v·ªÅ d·ªØ li·ªáu MNIST
    st.write("""
    D·ªØ li·ªáu MNIST bao g·ªìm c√°c h√¨nh ·∫£nh ch·ªØ s·ªë vi·∫øt tay c√≥ k√≠ch th∆∞·ªõc **28x28 pixels**.  
    M·ªói ·∫£nh l√† m·ªôt **ma tr·∫≠n 28x28**, v·ªõi m·ªói pixel c√≥ gi√° tr·ªã t·ª´ **0 ƒë·∫øn 255**.  
    Khi ƒë∆∞a v√†o m√¥ h√¨nh, ·∫£nh s·∫Ω ƒë∆∞·ª£c bi·∫øn ƒë·ªïi th√†nh **784 features (28x28)** ƒë·ªÉ l√†m ƒë·∫ßu v√†o cho m·∫°ng n∆°-ron.  
    M√¥ h√¨nh s·ª≠ d·ª•ng c√°c l·ªõp ·∫©n ƒë·ªÉ h·ªçc v√† d·ª± ƒëo√°n ch√≠nh x√°c ch·ªØ s·ªë t·ª´ h√¨nh ·∫£nh.
    """)

    
    



# ======================================

# def input_mlflow():
#     DAGSHUB_MLFLOW_URI = "https://dagshub.com/Phuocbinh2003/Hoc_may_python.mlflow"
#     mlflow.set_tracking_uri(DAGSHUB_MLFLOW_URI)
#     st.session_state['mlflow_url'] = DAGSHUB_MLFLOW_URI
#     os.environ["MLFLOW_TRACKING_USERNAME"] = "Phuocbinh2003"
#     os.environ["MLFLOW_TRACKING_PASSWORD"] = "c1495823c8f9156923b06f15899e989db7e62052"
#     mlflow.set_experiment("NN")

import streamlit as st
import numpy as np
import time
import mlflow
import mlflow.keras
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.model_selection import train_test_split, StratifiedKFold
from mlflow.models.signature import infer_signature

# Load d·ªØ li·ªáu MNIST
def load_mnist_data():
    X = np.load("buoi4/X.npy")
    y = np.load("buoi4/y.npy")
    return X, y

def split_data():
    st.title("üìå Chia d·ªØ li·ªáu Train/Test")
    
    # ƒê·ªçc d·ªØ li·ªáu
    X, y = load_mnist_data()
    total_samples = X.shape[0] 
    
    # Thanh k√©o ch·ªçn s·ªë l∆∞·ª£ng ·∫£nh ƒë·ªÉ train
    num_samples = st.slider("üìå Ch·ªçn s·ªë l∆∞·ª£ng ·∫£nh ƒë·ªÉ hu·∫•n luy·ªán:", 1000, total_samples, 10000)
    num_samples =num_samples -10
    # Thanh k√©o ch·ªçn t·ª∑ l·ªá Train/Test
    test_size = st.slider("üìå Ch·ªçn % d·ªØ li·ªáu Test", 10, 50, 20)
    train_size = 100 - test_size
    val_size = st.slider("üìå Ch·ªçn % d·ªØ li·ªáu Validation (trong Train)", 0, 50, 15)
    
    st.write(f"üìå **T·ª∑ l·ªá ph√¢n chia:** Test={test_size}%, Validation={val_size}%, Train={train_size - val_size}%")
    
    if st.button("‚úÖ X√°c nh·∫≠n & L∆∞u"):
        X_selected, _, y_selected, _ = train_test_split(X, y, train_size=num_samples, stratify=y, random_state=42)
        X_train_full, X_test, y_train_full, y_test = train_test_split(X_selected, y_selected, test_size=test_size/100, stratify=y_selected, random_state=42)
        X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=val_size / (100 - test_size), stratify=y_train_full, random_state=42)
        
        # L∆∞u v√†o session_state
        st.session_state.update({
            "X_train": X_train, "X_val": X_val, "X_test": X_test,
            "y_train": y_train, "y_val": y_val, "y_test": y_test
        })
        
        summary_df = pd.DataFrame({"T·∫≠p d·ªØ li·ªáu": ["Train", "Validation", "Test"], "S·ªë l∆∞·ª£ng m·∫´u": [X_train.shape[0], X_val.shape[0], X_test.shape[0]]})
        st.success("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chia th√†nh c√¥ng!")
        st.table(summary_df)

def thi_nghiem():
   
    
    if "X_train" not in st.session_state:
        st.error("‚ö†Ô∏è Ch∆∞a c√≥ d·ªØ li·ªáu! H√£y chia d·ªØ li·ªáu tr∆∞·ªõc.")
        return
    
    X_train, X_val, X_test = [st.session_state[k].reshape(-1, 28 * 28) / 255.0 for k in ["X_train", "X_val", "X_test"]]
    y_train, y_val, y_test = [st.session_state[k] for k in ["y_train", "y_val", "y_test"]]
    
    k_folds = st.slider("S·ªë fold cho Cross-Validation:", 3, 10, 5)
    num_layers = st.slider("S·ªë l·ªõp ·∫©n:", 1, 5, 2)
    num_neurons = st.slider("S·ªë neuron m·ªói l·ªõp:", 32, 512, 128, 32)
    activation = st.selectbox("H√†m k√≠ch ho·∫°t:", ["relu", "sigmoid", "tanh"])
    optimizer = st.selectbox("Optimizer:", ["adam", "sgd", "rmsprop"])
    epochs = st.slider("üï∞ S·ªë epochs:", min_value=1, max_value=50, value=20, step=1)
    learning_rate = st.slider("‚ö° T·ªëc ƒë·ªô h·ªçc (Learning Rate):", min_value=1e-5, max_value=1e-1, value=1e-3, step=1e-5, format="%.5f")

    loss_fn = "sparse_categorical_crossentropy"
    run_name = st.text_input("üîπ Nh·∫≠p t√™n Run:", "Default_Run")
    st.session_state['run_name'] = run_name
    
    if st.button("üöÄ Hu·∫•n luy·ªán m√¥ h√¨nh"):
        with st.spinner("ƒêang hu·∫•n luy·ªán..."):
            mlflow.start_run(run_name=run_name)
            mlflow.log_params({
                "num_layers": num_layers,
                "num_neurons": num_neurons,
                "activation": activation,
                "optimizer": optimizer,
                "learning_rate": learning_rate,
                "k_folds": k_folds,
                "epochs": epochs
            })

            kf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)
            accuracies, losses = [], []

            # Thanh ti·∫øn tr√¨nh t·ªïng qu√°t cho to√†n b·ªô qu√° tr√¨nh hu·∫•n luy·ªán
            training_progress = st.progress(0)
            training_status = st.empty()

            for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train)):
                X_k_train, X_k_val = X_train[train_idx], X_train[val_idx]
                y_k_train, y_k_val = y_train[train_idx], y_train[val_idx]

                model = keras.Sequential([
                    layers.Input(shape=(X_k_train.shape[1],))
                ] + [
                    layers.Dense(num_neurons, activation=activation) for _ in range(num_layers)
                ] + [
                    layers.Dense(10, activation="softmax")
                ])

                # Ch·ªçn optimizer v·ªõi learning rate
                if optimizer == "adam":
                    opt = keras.optimizers.Adam(learning_rate=learning_rate)
                elif optimizer == "sgd":
                    opt = keras.optimizers.SGD(learning_rate=learning_rate)
                else:
                    opt = keras.optimizers.RMSprop(learning_rate=learning_rate)

                model.compile(optimizer=opt, loss=loss_fn, metrics=["accuracy"])

                start_time = time.time()
                history = model.fit(X_k_train, y_k_train, epochs=epochs, validation_data=(X_k_val, y_k_val), verbose=0)

                elapsed_time = time.time() - start_time
                accuracies.append(history.history["val_accuracy"][-1])
                losses.append(history.history["val_loss"][-1])

                # C·∫≠p nh·∫≠t thanh ti·∫øn tr√¨nh ch√≠nh (theo fold)
                st.write(fold_idx ,k_folds)
                
                progress_percent = int((fold_idx + 1 / k_folds))
                training_progress.progress(progress_percent)
                
                            

                
                training_status.text(f"‚è≥ ƒêang hu·∫•n luy·ªán... {progress_percent*100}%")

            avg_val_accuracy = np.mean(accuracies)
            avg_val_loss = np.mean(losses)

            mlflow.log_metrics({
                "avg_val_accuracy": avg_val_accuracy,
                "avg_val_loss": avg_val_loss,
                "elapsed_time": elapsed_time
            })

            test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)
            mlflow.log_metrics({"test_accuracy": test_accuracy, "test_loss": test_loss})

            mlflow.end_run()
            st.session_state["trained_model"] = model

            # Ho√†n th√†nh ti·∫øn tr√¨nh
            training_progress.progress(1.0)
            training_status.text("‚úÖ Hu·∫•n luy·ªán ho√†n t·∫•t!")

            st.success(f"‚úÖ Hu·∫•n luy·ªán ho√†n t·∫•t!")
            st.write(f"üìä **ƒê·ªô ch√≠nh x√°c trung b√¨nh tr√™n t·∫≠p validation:** {avg_val_accuracy:.4f}")
            st.write(f"üìä **ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p test:** {test_accuracy:.4f}")
            st.success(f"‚úÖ ƒê√£ log d·ªØ li·ªáu cho **{st.session_state['run_name']}** trong MLflow (Neural_Network)! üöÄ")
            st.markdown(f"üîó [Truy c·∫≠p MLflow UI]({st.session_state['mlflow_url']})")


                
            
            

import streamlit as st
import numpy as np
import joblib
import random
import pandas as pd
import time
from PIL import Image
from streamlit_drawable_canvas import st_canvas
from tensorflow.keras.models import load_model

def preprocess_canvas_image(canvas_result):
    """Chuy·ªÉn ƒë·ªïi ·∫£nh t·ª´ canvas sang ƒë·ªãnh d·∫°ng ph√π h·ª£p ƒë·ªÉ d·ª± ƒëo√°n."""
    if canvas_result.image_data is None:
        return None
    img = canvas_result.image_data[:, :, :3]  # Ch·ªâ l·∫•y 3 k√™nh RGB
    img = Image.fromarray(img).convert("L").resize((28, 28))  # Chuy·ªÉn sang grayscale, resize v·ªÅ 28x28
    img = np.array(img) / 255.0  # Chu·∫©n h√≥a v·ªÅ [0,1]
    img = img.reshape(1, -1)  # ƒê∆∞a v·ªÅ d·∫°ng vector gi·ªëng nh∆∞ trong `thi_nghiem()`
    return img

def du_doan():
    st.header("‚úçÔ∏è V·∫Ω s·ªë ƒë·ªÉ d·ª± ƒëo√°n")

    # üì• Load m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán
    if "trained_model" in st.session_state:
        model = st.session_state["trained_model"]
        st.success("‚úÖ ƒê√£ s·ª≠ d·ª•ng m√¥ h√¨nh v·ª´a hu·∫•n luy·ªán!")
    else:
        st.error("‚ö†Ô∏è Ch∆∞a c√≥ m√¥ h√¨nh! H√£y hu·∫•n luy·ªán tr∆∞·ªõc.")


    # üÜï C·∫≠p nh·∫≠t key cho canvas khi nh·∫•n "T·∫£i l·∫°i"
    if "key_value" not in st.session_state:
        st.session_state.key_value = str(random.randint(0, 1000000))  

    if st.button("üîÑ T·∫£i l·∫°i n·∫øu kh√¥ng th·∫•y canvas"):
        st.session_state.key_value = str(random.randint(0, 1000000))  

    # ‚úçÔ∏è V·∫Ω s·ªë
    canvas_result = st_canvas(
        fill_color="black",
        stroke_width=10,
        stroke_color="white",
        background_color="black",
        height=150,
        width=150,
        drawing_mode="freedraw",
        key=st.session_state.key_value,
        update_streamlit=True
    )

    if st.button("D·ª± ƒëo√°n s·ªë"):
        img = preprocess_canvas_image(canvas_result)

        if img is not None:
            st.image(Image.fromarray((img.reshape(28, 28) * 255).astype(np.uint8)), caption="·∫¢nh sau x·ª≠ l√Ω", width=100)

            # D·ª± ƒëo√°n s·ªë
            prediction = model.predict(img)
            predicted_number = np.argmax(prediction, axis=1)[0]
            max_confidence = np.max(prediction)

            st.subheader(f"üî¢ D·ª± ƒëo√°n: {predicted_number}")
            st.write(f"üìä M·ª©c ƒë·ªô tin c·∫≠y: {max_confidence:.2%}")

            # Hi·ªÉn th·ªã b·∫£ng confidence score
            prob_df = pd.DataFrame(prediction.reshape(1, -1), columns=[str(i) for i in range(10)]).T
            prob_df.columns = ["M·ª©c ƒë·ªô tin c·∫≠y"]
            st.bar_chart(prob_df)

        else:
            st.error("‚ö†Ô∏è H√£y v·∫Ω m·ªôt s·ªë tr∆∞·ªõc khi b·∫•m D·ª± ƒëo√°n!")

    
from datetime import datetime    
import streamlit as st
import mlflow
from datetime import datetime

def show_experiment_selector():
    st.title("üìä MLflow")
    
    # K·∫øt n·ªëi v·ªõi DAGsHub MLflow Tracking
    mlflow.set_tracking_uri("https://dagshub.com/Phuocbinh2003/Hoc_may_python.mlflow")
    
    # L·∫•y danh s√°ch t·∫•t c·∫£ experiments
    experiment_name = "Neural_Network"
    experiments = mlflow.search_experiments()
    selected_experiment = next((exp for exp in experiments if exp.name == experiment_name), None)

    if not selected_experiment:
        st.error(f"‚ùå Experiment '{experiment_name}' kh√¥ng t·ªìn t·∫°i!")
        return

    st.subheader(f"üìå Experiment: {experiment_name}")
    st.write(f"**Experiment ID:** {selected_experiment.experiment_id}")
    st.write(f"**Tr·∫°ng th√°i:** {'Active' if selected_experiment.lifecycle_stage == 'active' else 'Deleted'}")
    st.write(f"**V·ªã tr√≠ l∆∞u tr·ªØ:** {selected_experiment.artifact_location}")

    # L·∫•y danh s√°ch runs trong experiment
    runs = mlflow.search_runs(experiment_ids=[selected_experiment.experiment_id])

    if runs.empty:
        st.warning("‚ö† Kh√¥ng c√≥ runs n√†o trong experiment n√†y.")
        return

    st.write("### üèÉ‚Äç‚ôÇÔ∏è C√°c Runs g·∫ßn ƒë√¢y:")
    
    # L·∫•y danh s√°ch run_name t·ª´ params
    run_info = []
    for _, run in runs.iterrows():
        run_id = run["run_id"]
        run_tags = mlflow.get_run(run_id).data.tags
        run_name = run_tags.get("mlflow.runName", f"Run {run_id[:8]}")  # L·∫•y t·ª´ tags
        run_info.append((run_name, run_id))
    
    # T·∫°o dictionary ƒë·ªÉ map run_name -> run_id
    run_name_to_id = dict(run_info)
    run_names = list(run_name_to_id.keys())
    
    # Ch·ªçn run theo run_name
    selected_run_name = st.selectbox("üîç Ch·ªçn m·ªôt run:", run_names)
    selected_run_id = run_name_to_id[selected_run_name]

    # Hi·ªÉn th·ªã th√¥ng tin chi ti·∫øt c·ªßa run ƒë∆∞·ª£c ch·ªçn
    selected_run = mlflow.get_run(selected_run_id)

    if selected_run:
        st.subheader(f"üìå Th√¥ng tin Run: {selected_run_name}")
        st.write(f"**Run ID:** {selected_run_id}")
        st.write(f"**Tr·∫°ng th√°i:** {selected_run.info.status}")
        
        start_time_ms = selected_run.info.start_time  # Th·ªùi gian l∆∞u d∆∞·ªõi d·∫°ng milliseconds
        if start_time_ms:
            start_time = datetime.fromtimestamp(start_time_ms / 1000).strftime("%Y-%m-%d %H:%M:%S")
        else:
            start_time = "Kh√¥ng c√≥ th√¥ng tin"
        
        st.write(f"**Th·ªùi gian ch·∫°y:** {start_time}")

        # Hi·ªÉn th·ªã th√¥ng s·ªë ƒë√£ log
        params = selected_run.data.params
        metrics = selected_run.data.metrics

        if params:
            st.write("### ‚öôÔ∏è Parameters:")
            st.json(params)

        if metrics:
            st.write("### üìä Metrics:")
            st.json(metrics)

        # Ki·ªÉm tra v√† hi·ªÉn th·ªã dataset artifact
        dataset_path = f"{selected_experiment.artifact_location}/{selected_run_id}/artifacts/dataset.npy"
        st.write("### üìÇ Dataset:")
        st.write(f"üì• [T·∫£i dataset]({dataset_path})")
    else:
        st.warning("‚ö† Kh√¥ng t√¨m th·∫•y th√¥ng tin cho run n√†y.")

        
        
        
          
import mlflow
import os
from mlflow.tracking import MlflowClient
def Neural_Network():
    #st.title("üöÄ MLflow DAGsHub Tracking v·ªõi Streamlit")
    
    if "mlflow_initialized" not in st.session_state:   
        DAGSHUB_MLFLOW_URI = "https://dagshub.com/Phuocbinh2003/Hoc_may_python.mlflow"
        st.session_state['mlflow_url']=DAGSHUB_MLFLOW_URI
        mlflow.set_tracking_uri(DAGSHUB_MLFLOW_URI)

        os.environ["MLFLOW_TRACKING_USERNAME"] = "Phuocbinh2003"
        os.environ["MLFLOW_TRACKING_PASSWORD"] = "c1495823c8f9156923b06f15899e989db7e62052"
        st.session_state.mlflow_initialized = True
        mlflow.set_experiment("Neural_Network")   
        
    
    
    # T·∫°o c√°c tab v·ªõi ti√™u ƒë·ªÅ t∆∞∆°ng ·ª©ng
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "üìò L√Ω thuy·∫øt NEURAL NETWORK",
        "üìä M·∫´u d·ªØ li·ªáu",
        "üß† Hu·∫•n luy·ªán",
        "üñ•Ô∏è DEMO",
        "üî• MLflow"
    ])

    # N·ªôi dung t·ª´ng tab
    with tab1:
        explain_nn()

    with tab2:
        data()

    with tab3:
        st.title("üß† Hu·∫•n luy·ªán Neural Network tr√™n MNIST")
        split_data()
        thi_nghiem()

    with tab4:
        du_doan()

    with tab5:
        show_experiment_selector()



if __name__ == "__main__":
    Neural_Network()