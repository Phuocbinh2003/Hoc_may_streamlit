import streamlit as st
import pandas as pd
from sklearn.preprocessing import StandardScaler
from scipy.stats import zscore
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from scipy.stats import zscore
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.metrics import mean_squared_error
import mlflow
import io
from sklearn.model_selection import KFold

def drop(df):
    st.subheader("üóëÔ∏è X√≥a c·ªôt d·ªØ li·ªáu")
    
    if "df" not in st.session_state:
        st.session_state.df = df  # L∆∞u v√†o session_state n·∫øu ch∆∞a c√≥

    df = st.session_state.df
    columns_to_drop = st.multiselect("üìå Ch·ªçn c·ªôt mu·ªën x√≥a:", df.columns.tolist())

    if st.button("üöÄ X√≥a c·ªôt ƒë√£ ch·ªçn"):
        if columns_to_drop:
            df = df.drop(columns=columns_to_drop)  # T·∫°o b·∫£n sao thay v√¨ inplace=True
            st.session_state.df = df  # C·∫≠p nh·∫≠t session_state
            st.success(f"‚úÖ ƒê√£ x√≥a c·ªôt: {', '.join(columns_to_drop)}")
            st.dataframe(df.head())
        else:
            st.warning("‚ö†Ô∏è Vui l√≤ng ch·ªçn √≠t nh·∫•t m·ªôt c·ªôt ƒë·ªÉ x√≥a!")

    return df

def choose_label(df):
    st.subheader("üéØ Ch·ªçn c·ªôt d·ª± ƒëo√°n (label)")

    if "target_column" not in st.session_state:
        st.session_state.target_column = None
    
    selected_label = st.selectbox("üìå Ch·ªçn c·ªôt d·ª± ƒëo√°n", df.columns, 
                                  index=df.columns.get_loc(st.session_state.target_column) if st.session_state.target_column else 0)

    X, y = df.drop(columns=[selected_label]), df[selected_label]  # M·∫∑c ƒë·ªãnh
    
    if st.button("‚úÖ X√°c nh·∫≠n Label"):
        st.session_state.target_column = selected_label
        X, y = df.drop(columns=[selected_label]), df[selected_label]
        st.success(f"‚úÖ ƒê√£ ch·ªçn c·ªôt: **{selected_label}**")
    
    return X, y

def train_test_size(df):
    st.subheader("üìä Chia d·ªØ li·ªáu Train - Validation - Test")   
    
    if "df" not in st.session_state:
        st.error("‚ùå D·ªØ li·ªáu ch∆∞a ƒë∆∞·ª£c t·∫£i l√™n!")
        st.stop()
    df = st.session_state.df  # L·∫•y d·ªØ li·ªáu t·ª´ session_state
    
    X, y = choose_label(df)
   
    df = st.session_state.df
    test_size = st.slider("üìå Ch·ªçn % d·ªØ li·ªáu Test", 10, 50, 20)

    remaining_size = 100 - test_size
    val_size = st.slider("üìå Ch·ªçn % d·ªØ li·ªáu Validation (trong ph·∫ßn Train)", 0, 50, 15)

    st.write(f"üìå **T·ª∑ l·ªá ph√¢n chia:** Test={test_size}%, Validation={val_size}%, Train={remaining_size - val_size}%")
    if st.button("‚úÖ X√°c nh·∫≠n Chia"):
        
        # Ki·ªÉm tra y c√≥ nhi·ªÅu h∆°n 1 gi√° tr·ªã kh√¥ng tr∆∞·ªõc khi stratify
        stratify_option = y if y.nunique() > 1 else None

        # Chia d·ªØ li·ªáu th√†nh Test tr∆∞·ªõc
        X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=test_size/100, stratify=stratify_option, random_state=42)

        # Chia ti·∫øp ph·∫ßn c√≤n l·∫°i th√†nh Train v√† Validation
        X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=val_size / (100 - test_size), stratify=stratify_option, random_state=42)

        # L∆∞u v√†o session_state
        st.session_state.X_train = X_train
        st.session_state.X_test = X_test
        st.session_state.y_train = y_train
        st.session_state.y_test = y_test
        st.session_state.y = y

        # Hi·ªÉn th·ªã th√¥ng tin s·ªë l∆∞·ª£ng m·∫´u
        summary_df = pd.DataFrame({
            "T·∫≠p d·ªØ li·ªáu": ["Train", "Validation", "Test"],
            "S·ªë l∆∞·ª£ng m·∫´u": [X_train.shape[0], X_val.shape[0], X_test.shape[0]]
        })
        st.table(summary_df)

        st.success("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chia th√†nh c√¥ng!")
        st.dataframe(X_train.head())

    return X_train, X_val, X_test, y_train, y_val, y_test

def xu_ly_gia_tri_thieu(df):
    st.subheader("‚ö° X·ª≠ l√Ω gi√° tr·ªã thi·∫øu")

    if "df" not in st.session_state:
        st.session_state.df = df.copy()

    df = st.session_state.df

    # T√¨m c·ªôt c√≥ gi√° tr·ªã thi·∫øu
    missing_cols = df.columns[df.isnull().any()].tolist()
    if not missing_cols:
        st.success("‚úÖ D·ªØ li·ªáu kh√¥ng c√≥ gi√° tr·ªã thi·∫øu!")
        return df

    selected_col = st.selectbox("üìå Ch·ªçn c·ªôt ch·ª©a gi√° tr·ªã thi·∫øu:", missing_cols)
    method = st.radio("üîß Ch·ªçn ph∆∞∆°ng ph√°p x·ª≠ l√Ω:", ["Thay th·∫ø b·∫±ng Mean", "Thay th·∫ø b·∫±ng Median", "X√≥a gi√° tr·ªã thi·∫øu"])

    if st.button("üöÄ X·ª≠ l√Ω gi√° tr·ªã thi·∫øu"):
        if method == "Thay th·∫ø b·∫±ng Mean":
            df[selected_col] = df[selected_col].fillna(df[selected_col].mean())
        elif method == "Thay th·∫ø b·∫±ng Median":
            df[selected_col] = df[selected_col].fillna(df[selected_col].median())
        elif method == "X√≥a gi√° tr·ªã thi·∫øu":
            df = df.dropna(subset=[selected_col])

        st.session_state.df = df
        st.success(f"‚úÖ ƒê√£ x·ª≠ l√Ω gi√° tr·ªã thi·∫øu trong c·ªôt `{selected_col}`")

    st.dataframe(df.head())
    return df




def chuyen_doi_kieu_du_lieu(df):
    st.subheader("üîÑ Chuy·ªÉn ƒë·ªïi ki·ªÉu d·ªØ li·ªáu")

    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
    if not categorical_cols:
        st.success("‚úÖ Kh√¥ng c√≥ c·ªôt d·∫°ng chu·ªói c·∫ßn chuy·ªÉn ƒë·ªïi!")
        return df

    selected_col = st.selectbox("üìå Ch·ªçn c·ªôt ƒë·ªÉ chuy·ªÉn ƒë·ªïi:", categorical_cols)
    unique_values = df[selected_col].unique()
    
    mapping_dict = {}
    if len(unique_values) <10:
        for val in unique_values:
            new_val = st.text_input(f"üîÑ Nh·∫≠p gi√° tr·ªã thay th·∫ø cho `{val}`:", key=f"{selected_col}_{val}")
            mapping_dict[val] = new_val

        if st.button("üöÄ Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu"):
            df[selected_col] = df[selected_col].map(lambda x: mapping_dict.get(x, x))
            st.session_state.df = df
            st.success(f"‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi c·ªôt `{selected_col}`")
    
    st.dataframe(df.head())
    return df
def chuan_hoa_du_lieu(df):
    st.subheader("üìä Chu·∫©n h√≥a d·ªØ li·ªáu v·ªõi StandardScaler")

    # L·ªçc t·∫•t c·∫£ c√°c c·ªôt s·ªë
    numerical_cols = df.select_dtypes(include=['number']).columns.tolist()

    if not numerical_cols:
        st.success("‚úÖ Kh√¥ng c√≥ thu·ªôc t√≠nh d·∫°ng s·ªë c·∫ßn chu·∫©n h√≥a!")
        return df

    # Chu·∫©n h√≥a t·∫•t c·∫£ c√°c c·ªôt s·ªë
    scaler = StandardScaler()
    df[numerical_cols] = scaler.fit_transform(df[numerical_cols])
    
    # L∆∞u l·∫°i trong session_state ƒë·ªÉ tr√°nh m·∫•t d·ªØ li·ªáu khi t·∫£i l·∫°i trang
    st.session_state.df = df

    st.success(f"‚úÖ ƒê√£ chu·∫©n h√≥a t·∫•t c·∫£ c√°c c·ªôt s·ªë: {', '.join(numerical_cols)}")
    st.dataframe(df.head())

    return df

def hien_thi_ly_thuyet(df):
    st.subheader("üìå 10 d√≤ng ƒë·∫ßu c·ªßa d·ªØ li·ªáu g·ªëc")
    st.write(df.head(10))

                # Ki·ªÉm tra l·ªói d·ªØ li·ªáu
    st.subheader("üö® Ki·ªÉm tra l·ªói d·ªØ li·ªáu")

                # Ki·ªÉm tra gi√° tr·ªã thi·∫øu
    missing_values = df.isnull().sum()

                # Ki·ªÉm tra d·ªØ li·ªáu tr√πng l·∫∑p
    duplicate_count = df.duplicated().sum()

                
                
                # Ki·ªÉm tra gi√° tr·ªã qu√° l·ªõn (outlier) b·∫±ng Z-score
    outlier_count = {
        col: (abs(zscore(df[col], nan_policy='omit')) > 3).sum()
        for col in df.select_dtypes(include=['number']).columns
    }

                # T·∫°o b√°o c√°o l·ªói
    error_report = pd.DataFrame({
        'C·ªôt': df.columns,
        'Gi√° tr·ªã thi·∫øu': missing_values,
        'Outlier': [outlier_count.get(col, 0) for col in df.columns]
    })

                # Hi·ªÉn th·ªã b√°o c√°o l·ªói
    st.table(error_report)

                # Hi·ªÉn th·ªã s·ªë l∆∞·ª£ng d·ªØ li·ªáu tr√πng l·∫∑p
    st.write(f"üîÅ **S·ªë l∆∞·ª£ng d√≤ng b·ªã tr√πng l·∫∑p:** {duplicate_count}")            
   
    
    st.title("üîç Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu")

    # Hi·ªÉn th·ªã d·ªØ li·ªáu g·ªëc
    
    st.header("‚öôÔ∏è C√°c b∆∞·ªõc ch√≠nh trong ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu")
    st.subheader("1Ô∏è‚É£ Lo·∫°i b·ªè c√°c c·ªôt kh√¥ng c·∫ßn thi·∫øt")
    st.write("""
        M·ªôt s·ªë c·ªôt trong d·ªØ li·ªáu c√≥ th·ªÉ kh√¥ng ·∫£nh h∆∞·ªüng ƒë·∫øn k·∫øt qu·∫£ d·ª± ƒëo√°n ho·∫∑c ch·ª©a qu√° nhi·ªÅu gi√° tr·ªã thi·∫øu. Ch√∫ng ta s·∫Ω lo·∫°i b·ªè c√°c c·ªôt nh∆∞:
        - **Cabin**: C·ªôt n√†y c√≥ qu√° nhi·ªÅu gi√° tr·ªã b·ªã thi·∫øu 687/891 .
        - **Ticket**: M√£ v√© kh√¥ng mang nhi·ªÅu th√¥ng tin h·ªØu √≠ch v√† c√≥ 681/891 v√© kh√°c nhau.
        - **Name**:  Kh√¥ng c·∫ßn thi·∫øt cho b√†i to√°n d·ª± ƒëo√°n s·ªëng s√≥t.
        ```python
            columns_to_drop = ["Cabin", "Ticket", "Name"]  
            df.drop(columns=columns_to_drop, inplace=True)
        ```
        """)
    df1=drop(df)
    
    st.subheader("2Ô∏è‚É£ X·ª≠ l√Ω gi√° tr·ªã thi·∫øu")
    st.write("""
        D·ªØ li·ªáu th·ª±c t·∫ø th∆∞·ªùng c√≥ gi√° tr·ªã b·ªã thi·∫øu. Ta c·∫ßn x·ª≠ l√Ω nh∆∞ ƒëi·ªÅn v√†o nan b·∫±ng trung b√¨nh ho·∫∑c trung v·ªã c√≥ th·ªÉ x√≥a n·∫øu s·ªë d√≤ng d·ªØ li·ªáu thi·∫øu √≠t ,ƒë·ªÉ tr√°nh ·∫£nh h∆∞·ªüng ƒë·∫øn m√¥ h√¨nh.
        - **C·ªôt "Age"**: C√≥ th·ªÉ ƒëi·ªÅn trung b√¨nh ho·∫∑c trung v·ªã .
        - **C·ªôt "Fare"**: C√≥ th·ªÉ ƒëi·ªÅn gi√° tr·ªã trung b√¨nh ho·∫∑c trung v·ªã .
        - **C·ªôt "Embarked"**:   X√≥a c√°c d√≤ng b·ªã thi·∫øu v√¨ s·ªë l∆∞·ª£ng √≠t 2/891.
        ```python
        
            df["Age"].fillna(df["Age"].mean(), inplace=True)  # ƒêi·ªÅn gi√° tr·ªã trung b√¨nh cho "Age"
            df["Fare"].fillna(df["Fare"].median(), inplace=True)  # ƒêi·ªÅn gi√° tr·ªã trung v·ªã cho "Fare"
            df.dropna(subset=["Embarked"], inplace=True)  # X√≥a d√≤ng thi·∫øu "Embarked"

        ```
        """)
    df=xu_ly_gia_tri_thieu(df1)

    st.subheader("3Ô∏è‚É£ Chuy·ªÉn ƒë·ªïi ki·ªÉu d·ªØ li·ªáu")
    st.write("""
        Trong d·ªØ li·ªáu, c√≥ m·ªôt s·ªë c·ªôt ch·ª©a gi√° tr·ªã d·∫°ng ch·ªØ (category). Ta c·∫ßn chuy·ªÉn ƒë·ªïi th√†nh d·∫°ng s·ªë ƒë·ªÉ m√¥ h√¨nh c√≥ th·ªÉ x·ª≠ l√Ω.
        - **C·ªôt "Sex"**: Chuy·ªÉn th√†nh 1 (male), 0 (female).
        - **C·ªôt "Embarked"**:   Chuy·ªÉn th√†nh 1 (Q), 2 (S), 3 (C).
        ```python
            df["Sex"] = df["Sex"].map({"male": 1, "female": 0})  # M√£ h√≥a gi·ªõi t√≠nh
            df['Embarked'] = df['Embarked'].map({'Q': 0, 'S': 1, 'C': 2})

        ```
        """)

    df=chuyen_doi_kieu_du_lieu(df)

    st.subheader("4Ô∏è‚É£ Chu·∫©n h√≥a d·ªØ li·ªáu s·ªë")
    st.write("""
        C√°c gi√° tr·ªã s·ªë c√≥ th·ªÉ c√≥ kho·∫£ng gi√° tr·ªã kh√°c nhau, l√†m ·∫£nh h∆∞·ªüng ƒë·∫øn m√¥ h√¨nh. Ta s·∫Ω chu·∫©n h√≥a to√†n b·ªô v·ªÅ c√πng m·ªôt thang ƒëo b·∫±ng StandardScaler.
        
        ```python
            scaler = StandardScaler()
            df[["Age", "Fare",...]] = scaler.fit_transform(df[["Age", "Fare",...]])

        ```
        """)

    
    df=chuan_hoa_du_lieu(df)
    
    st.subheader("5Ô∏è‚É£ Chia d·ªØ li·ªáu th√†nh t·∫≠p Train, Validation, v√† Test")
    st.write("""
    ### üìå Chia t·∫≠p d·ªØ li·ªáu
    D·ªØ li·ªáu ƒë∆∞·ª£c chia th√†nh ba ph·∫ßn ƒë·ªÉ ƒë·∫£m b·∫£o m√¥ h√¨nh t·ªïng qu√°t t·ªët:
    - **70%**: ƒë·ªÉ train m√¥ h√¨nh.
    - **15%**: ƒë·ªÉ validation, d√πng ƒë·ªÉ ƒëi·ªÅu ch·ªânh tham s·ªë.
    - **15%**: ƒë·ªÉ test, ƒë√°nh gi√° hi·ªáu su·∫•t th·ª±c t·∫ø.

    ```python
    from sklearn.model_selection import train_test_split

    # Chia d·ªØ li·ªáu theo t·ª∑ l·ªá 85% (Train) - 15% (Test)
    X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.15, stratify=y, random_state=42)

    # Chia ti·∫øp 15% c·ªßa Train ƒë·ªÉ l√†m Validation (~12.75% c·ªßa to√†n b·ªô d·ªØ li·ªáu)
    val_size = 0.15 / 0.85  
    X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=val_size, stratify=y_train_full, random_state=42)
    ```
    """)
       
    X_train, X_val, X_test, y_train, y_val, y_test =train_test_size(df)
    
    return X_train, X_val, X_test, y_train, y_val, y_test


def train_multiple_linear_regression(X_train, y_train, learning_rate=0.001, n_iterations=200):
    """Hu·∫•n luy·ªán h·ªìi quy tuy·∫øn t√≠nh b·ªôi b·∫±ng Gradient Descent."""
    
    # Chuy·ªÉn ƒë·ªïi X_train, y_train sang NumPy array ƒë·ªÉ tr√°nh l·ªói
    X_train = X_train.to_numpy() if isinstance(X_train, pd.DataFrame) else X_train
    y_train = y_train.to_numpy().reshape(-1, 1) if isinstance(y_train, (pd.Series, pd.DataFrame)) else y_train.reshape(-1, 1)

    # Ki·ªÉm tra NaN ho·∫∑c Inf
    if np.isnan(X_train).any() or np.isnan(y_train).any():
        raise ValueError("D·ªØ li·ªáu ƒë·∫ßu v√†o ch·ª©a gi√° tr·ªã NaN!")
    if np.isinf(X_train).any() or np.isinf(y_train).any():
        raise ValueError("D·ªØ li·ªáu ƒë·∫ßu v√†o ch·ª©a gi√° tr·ªã v√¥ c√πng (Inf)!")

    # Chu·∫©n h√≥a d·ªØ li·ªáu ƒë·ªÉ tr√°nh tr√†n s·ªë
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)

    # L·∫•y s·ªë l∆∞·ª£ng m·∫´u (m) v√† s·ªë l∆∞·ª£ng ƒë·∫∑c tr∆∞ng (n)
    m, n = X_train.shape
    #st.write(f"S·ªë l∆∞·ª£ng m·∫´u (m): {m}, S·ªë l∆∞·ª£ng ƒë·∫∑c tr∆∞ng (n): {n}")

    # Th√™m c·ªôt bias (x0 = 1) v√†o X_train
    X_b = np.c_[np.ones((m, 1)), X_train]
    #st.write(f"K√≠ch th∆∞·ªõc ma tr·∫≠n X_b: {X_b.shape}")

    # Kh·ªüi t·∫°o tr·ªçng s·ªë ng·∫´u nhi√™n nh·ªè
    w = np.random.randn(X_b.shape[1], 1) * 0.01  
    #st.write(f"Tr·ªçng s·ªë ban ƒë·∫ßu: {w.flatten()}")

    # Gradient Descent
    for iteration in range(n_iterations):
        gradients = (2/m) * X_b.T.dot(X_b.dot(w) - y_train)

        # Ki·ªÉm tra xem gradients c√≥ NaN kh√¥ng
        # st.write(gradients)
        if np.isnan(gradients).any():
            raise ValueError("Gradient ch·ª©a gi√° tr·ªã NaN! H√£y ki·ªÉm tra l·∫°i d·ªØ li·ªáu ho·∫∑c learning rate.")

        w -= learning_rate * gradients

    #st.success("‚úÖ Hu·∫•n luy·ªán ho√†n t·∫•t!")
    #st.write(f"Tr·ªçng s·ªë cu·ªëi c√πng: {w.flatten()}")
    return w
def train_polynomial_regression(X_train, y_train, degree=2, learning_rate=0.001, n_iterations=500):
    """Hu·∫•n luy·ªán h·ªìi quy ƒëa th·ª©c **kh√¥ng c√≥ t∆∞∆°ng t√°c** b·∫±ng Gradient Descent."""

    # Chuy·ªÉn d·ªØ li·ªáu sang NumPy array n·∫øu l√† pandas DataFrame/Series
    X_train = X_train.to_numpy() if isinstance(X_train, pd.DataFrame) else X_train
    y_train = y_train.to_numpy().reshape(-1, 1) if isinstance(y_train, (pd.Series, pd.DataFrame)) else y_train.reshape(-1, 1)

    # T·∫°o ƒë·∫∑c tr∆∞ng ƒëa th·ª©c **ch·ªâ th√™m b·∫≠c cao, kh√¥ng c√≥ t∆∞∆°ng t√°c**
    X_poly = np.hstack([X_train] + [X_train**d for d in range(2, degree + 1)])
    # Chu·∫©n h√≥a d·ªØ li·ªáu ƒë·ªÉ tr√°nh tr√†n s·ªë
    scaler = StandardScaler()
    X_poly = scaler.fit_transform(X_poly)

    # L·∫•y s·ªë l∆∞·ª£ng m·∫´u (m) v√† s·ªë l∆∞·ª£ng ƒë·∫∑c tr∆∞ng (n)
    m, n = X_poly.shape
    print(f"S·ªë l∆∞·ª£ng m·∫´u (m): {m}, S·ªë l∆∞·ª£ng ƒë·∫∑c tr∆∞ng (n): {n}")

    # Th√™m c·ªôt bias (x0 = 1)
    X_b = np.c_[np.ones((m, 1)), X_poly]
    print(f"K√≠ch th∆∞·ªõc ma tr·∫≠n X_b: {X_b.shape}")

    # Kh·ªüi t·∫°o tr·ªçng s·ªë ng·∫´u nhi√™n nh·ªè
    w = np.random.randn(X_b.shape[1], 1) * 0.01  
    print(f"Tr·ªçng s·ªë ban ƒë·∫ßu: {w.flatten()}")

    # Gradient Descent
    for iteration in range(n_iterations):
        gradients = (2/m) * X_b.T.dot(X_b.dot(w) - y_train)

        # Ki·ªÉm tra n·∫øu gradient c√≥ gi√° tr·ªã NaN
        if np.isnan(gradients).any():
            raise ValueError("Gradient ch·ª©a gi√° tr·ªã NaN! H√£y ki·ªÉm tra l·∫°i d·ªØ li·ªáu ho·∫∑c learning rate.")

        w -= learning_rate * gradients

    print("‚úÖ Hu·∫•n luy·ªán ho√†n t·∫•t!")
    print(f"Tr·ªçng s·ªë cu·ªëi c√πng: {w.flatten()}")
    
    return w

def chon_mo_hinh(model_type, X_train, X_test, y_train, y_test, n_folds=5):
    """Ch·ªçn m√¥ h√¨nh h·ªìi quy tuy·∫øn t√≠nh b·ªôi ho·∫∑c h·ªìi quy ƒëa th·ª©c."""
    degree = 2
    fold_mse = []  # Danh s√°ch MSE c·ªßa t·ª´ng fold
    scaler = StandardScaler()  # Chu·∫©n h√≥a d·ªØ li·ªáu cho h·ªìi quy ƒëa th·ª©c n·∫øu c·∫ßn
    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)
    
    for fold, (train_idx, valid_idx) in enumerate(kf.split(X_train, y_train)):
        X_train_fold, X_valid = X_train.iloc[train_idx], X_train.iloc[valid_idx]
        y_train_fold, y_valid = y_train.iloc[train_idx], y_train.iloc[valid_idx]

        st.write("üöÄ Fold {fold + 1}: Train size = {len(X_train_fold)}, Validation size = {len(X_valid)}")

        if model_type == "linear":
            w= train_multiple_linear_regression(X_train_fold, y_train_fold)

            w = np.array(w).reshape(-1, 1)
            
            X_valid = X_valid.to_numpy()


            X_valid_b = np.c_[np.ones((len(X_valid), 1)), X_valid]  # Th√™m bias
            y_valid_pred = X_valid_b.dot(w)  # D·ª± ƒëo√°n
        elif model_type == "polynomial":
            
            X_train_fold = scaler.fit_transform(X_train_fold)
                
            w = train_polynomial_regression(X_train_fold, y_train_fold, degree)
            
            w = np.array(w).reshape(-1, 1)
            
            X_valid_scaled = scaler.transform(X_valid.to_numpy())
            X_valid_poly = np.hstack([X_valid_scaled] + [X_valid_scaled**d for d in range(2, degree + 1)])
            X_valid_b = np.c_[np.ones((len(X_valid_poly), 1)), X_valid_poly]
            
            y_valid_pred = X_valid_b.dot(w)  # D·ª± ƒëo√°n
        else:
            raise ValueError("‚ö†Ô∏è Ch·ªçn 'linear' ho·∫∑c 'polynomial'!")

        mse = mean_squared_error(y_valid, y_valid_pred)
        fold_mse.append(mse)

        print(f"üìå Fold {fold + 1} - MSE: {mse:.4f}")

    # üî• Hu·∫•n luy·ªán l·∫°i tr√™n to√†n b·ªô t·∫≠p train
    if model_type == "linear":
        final_w = train_multiple_linear_regression(X_train, y_train)
        X_test_b = np.c_[np.ones((len(X_test), 1)), X_test]
        y_test_pred = X_test_b.dot(final_w)
    else:
        X_train_scaled = scaler.fit_transform(X_train)
        final_w = train_polynomial_regression(X_train_scaled, y_train, degree)

        X_test_scaled = scaler.transform(X_test.to_numpy())
        X_test_poly = np.hstack([X_test_scaled] + [X_test_scaled**d for d in range(2, degree + 1)])
        X_test_b = np.c_[np.ones((len(X_test_poly), 1)), X_test_poly]

        y_test_pred = X_test_b.dot(final_w)

    # üìå ƒê√°nh gi√° tr√™n t·∫≠p test
    test_mse = mean_squared_error(y_test, y_test_pred)
    avg_mse = np.mean(fold_mse)  # Trung b√¨nh MSE qua c√°c folds

    st.success(f"MSE trung b√¨nh qua c√°c folds: {avg_mse:.4f}")
    st.success(f"MSE tr√™n t·∫≠p test: {test_mse:.4f}")

    return final_w, avg_mse, scaler




def main():
    uploaded_file = st.file_uploader("üìÇ Ch·ªçn file d·ªØ li·ªáu (.csv ho·∫∑c .txt)", type=["csv", "txt"])
    if uploaded_file is not None:  # Ki·ªÉm tra xem file ƒë√£ ƒë∆∞·ª£c t·∫£i l√™n ch∆∞
        try:
            df = pd.read_csv(uploaded_file, delimiter=",")
            
            X_train, X_val, X_test, y_train, y_val, y_test=hien_thi_ly_thuyet(df)
            
            
            model_type = st.radio("Ch·ªçn lo·∫°i m√¥ h√¨nh:", ["Multiple Linear Regression", "Polynomial Regression"])

            # Khi nh·∫•n n√∫t s·∫Ω hu·∫•n luy·ªán m√¥ h√¨nh
            if st.button("Hu·∫•n luy·ªán m√¥ h√¨nh"):
            
                model_type_value = "linear" if model_type == "Multiple Linear Regression" else "polynomial"

                # G·ªçi h√†m v·ªõi ƒë√∫ng th·ª© t·ª± tham s·ªë
                final_w, avg_mse, scaler = chon_mo_hinh(model_type_value, X_train, X_test, y_train, y_test)
            
            
            
            
        except Exception as e:
            st.error(f"‚ùå L·ªói khi ƒë·ªçc file: {e}")
    
        


        


            
  

if __name__ == "__main__":
    main()
