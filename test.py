import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
import mlflow
import os
import time
from datetime import datetime
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import Callback
import plotly.express as px

# ======================================
# PH·∫¶N 1: L√ù THUY·∫æT NEURAL NETWORK
# ======================================
def explain_nn():
    st.markdown("""
    ## üß† Neural Network C∆° B·∫£n

    **Neural Network (M·∫°ng n∆°-ron nh√¢n t·∫°o - ANN)** l√† m·ªôt m√¥ h√¨nh t√≠nh to√°n l·∫•y c·∫£m h·ª©ng t·ª´ c·∫•u tr√∫c v√† ho·∫°t ƒë·ªông c·ªßa n√£o b·ªô con ng∆∞·ªùi. M·∫°ng bao g·ªìm nhi·ªÅu n∆°-ron nh√¢n t·∫°o k·∫øt n·ªëi v·ªõi nhau th√†nh c√°c l·ªõp (layers), gi√∫p m√¥ h√¨nh h·ªçc v√† nh·∫≠n di·ªán c√°c m·∫´u trong d·ªØ li·ªáu.

    ### üî∞ Ki·∫øn tr√∫c c∆° b·∫£n:
    """)
    
    st.markdown("""
    ### üìå C·∫•u tr√∫c c·ªßa m·ªôt m·∫°ng n∆°-ron nh√¢n t·∫°o g·ªìm ba lo·∫°i l·ªõp ch√≠nh:
    1. **Input Layer**: L·ªõp ti·∫øp nh·∫≠n d·ªØ li·ªáu ƒë·∫ßu v√†o.
    2. **Hidden Layers**: X·ª≠ l√Ω th√¥ng tin th√¥ng qua c√°c tr·ªçng s·ªë (weights) v√† h√†m k√≠ch ho·∫°t.
    3. **Output Layer**: L·ªõp ƒë∆∞a ra k·∫øt qu·∫£ d·ª± ƒëo√°n.
    """)
    
    st.image("buoi7/img1.webp", caption="", use_container_width=True)
    
    st.markdown("""
    M·ªói n∆°-ron trong m·ªôt l·ªõp nh·∫≠n t√≠n hi·ªáu t·ª´ c√°c n∆°-ron l·ªõp tr∆∞·ªõc, nh√¢n v·ªõi tr·ªçng s·ªë (weights), c·ªông v·ªõi bias, r·ªìi ƒë∆∞a v√†o m·ªôt h√†m k√≠ch ho·∫°t ƒë·ªÉ quy·∫øt ƒë·ªãnh t√≠n hi·ªáu truy·ªÅn ƒëi.
    
    ### üìå C√¥ng th·ª©c to√°n h·ªçc trong Neural Network:
    V·ªõi m·ªôt n∆°-ron, gi√° tr·ªã ƒë·∫ßu ra ƒë∆∞·ª£c t√≠nh nh∆∞ sau:
    
    \[ z = \sum_{i=1}^{n} w_i x_i + b \]
    
    Trong ƒë√≥:
    - \( x_i \) l√† ƒë·∫ßu v√†o (input features)
    - \( w_i \) l√† tr·ªçng s·ªë (weights)
    - \( b \) l√† bias
    - \( z \) l√† t·ªïng c√≥ tr·ªçng s·ªë
    
    Sau ƒë√≥, gi√° tr·ªã \( z \) ƒëi qua h√†m k√≠ch ho·∫°t \( \sigma(z) \) ƒë·ªÉ t·∫°o ƒë·∫ßu ra:
    
    \[ a = \sigma(z) \]
    
    C√°c h√†m k√≠ch ho·∫°t ph·ªï bi·∫øn s·∫Ω ƒë∆∞·ª£c tr√¨nh b√†y trong ph·∫ßn ti·∫øp theo.
    """)
    
    st.markdown("""
    ### üéØ H√†m K√≠ch Ho·∫°t (Activation Functions)
    H√†m k√≠ch ho·∫°t gi√∫p m·∫°ng h·ªçc ƒë∆∞·ª£c c√°c t√≠nh phi tuy·∫øn t√≠nh, nh·ªù ƒë√≥ c√≥ th·ªÉ m√¥ h√¨nh h√≥a c√°c m·ªëi quan h·ªá ph·ª©c t·∫°p.
    """)
    
    st.image("buoi7/img2.png", caption="", use_container_width=True)
    
    st.markdown("""
    - **Sigmoid:** Chuy·ªÉn ƒë·ªïi gi√° tr·ªã ƒë·∫ßu v√†o th√†nh kho·∫£ng t·ª´ 0 ƒë·∫øn 1, ph√π h·ª£p cho b√†i to√°n ph√¢n lo·∫°i nh·ªã ph√¢n.
      \[ \sigma(z) = \frac{1}{1 + e^{-z}} \]
    
    - **Tanh (Hyperbolic Tangent):** ƒê·∫ßu ra n·∫±m trong kho·∫£ng t·ª´ -1 ƒë·∫øn 1, gi√∫p x·ª≠ l√Ω d·ªØ li·ªáu c√≥ c·∫£ gi√° tr·ªã d∆∞∆°ng v√† √¢m.
      \[ \tanh(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}} \]
    
    - **ReLU (Rectified Linear Unit):** N·∫øu ƒë·∫ßu v√†o √¢m th√¨ b·∫±ng 0, c√≤n n·∫øu d∆∞∆°ng th√¨ gi·ªØ nguy√™n gi√° tr·ªã.
      \[ ReLU(z) = \max(0, z) \]
    """)
    
    st.markdown("""
    ### üîÑ Qu√° tr√¨nh hu·∫•n luy·ªán Neural Network:
    M·∫°ng n∆°-ron h·ªçc b·∫±ng c√°ch c·∫≠p nh·∫≠t c√°c tr·ªçng s·ªë th√¥ng qua hai giai ƒëo·∫°n ch√≠nh:
    
    1. **Lan truy·ªÅn thu·∫≠n (Forward Propagation):**
       - Input ƒëi qua t·ª´ng l·ªõp n∆°-ron, t√≠nh to√°n ƒë·∫ßu ra:
         \[ a^{(l)} = \sigma(W^{(l)} a^{(l-1)} + b^{(l)}) \]
    
    2. **T√≠nh to√°n loss:**
       - H√†m m·∫•t m√°t ƒëo l∆∞·ªùng sai s·ªë gi·ªØa d·ª± ƒëo√°n v√† th·ª±c t·∫ø.
       - V√≠ d·ª•: Mean Squared Error (MSE) cho b√†i to√°n h·ªìi quy:
         \[ L = \frac{1}{N} \sum (y_{true} - y_{pred})^2 \]
       - Cross-Entropy Loss cho b√†i to√°n ph√¢n lo·∫°i:
         \[ L = - \sum y_{true} \log(y_{pred}) \]
    
    3. **Lan truy·ªÅn ng∆∞·ª£c (Backpropagation):**
       - T√≠nh ƒë·∫°o h√†m c·ªßa h√†m m·∫•t m√°t theo tr·ªçng s·ªë.
       - S·ª≠ d·ª•ng thu·∫≠t to√°n t·ªëi ∆∞u ƒë·ªÉ c·∫≠p nh·∫≠t tr·ªçng s·ªë.
    
    4. **T·ªëi ∆∞u h√≥a:**
       - **Gradient Descent:** C·∫≠p nh·∫≠t tr·ªçng s·ªë b·∫±ng c√°ch ƒëi theo h∆∞·ªõng gi·∫£m c·ªßa gradient.
       - **Momentum:** Th√™m ƒë·ªông l∆∞·ª£ng gi√∫p t·ªëi ∆∞u nhanh h∆°n.
       - **Adam (Adaptive Moment Estimation):** K·∫øt h·ª£p Momentum v√† RMSprop ƒë·ªÉ ƒë·∫°t hi·ªáu su·∫•t t·ªëi ∆∞u.
    
    ### üîç K·∫øt Lu·∫≠n
    Neural Network l√† m·ªôt m√¥ h√¨nh m·∫°nh m·∫Ω trong Machine Learning v√† Deep Learning, c√≥ th·ªÉ h·ªçc ƒë∆∞·ª£c c√°c ƒë·∫∑c tr∆∞ng ph·ª©c t·∫°p t·ª´ d·ªØ li·ªáu. Hi·ªÉu r√µ c√°ch ho·∫°t ƒë·ªông gi√∫p ta t·ªëi ∆∞u h√≥a m√¥ h√¨nh ƒë·ªÉ ƒë·∫°t hi·ªáu su·∫•t cao h∆°n.
    """)
    
    
    
    
    



# ======================================

def input_mlflow():
    DAGSHUB_MLFLOW_URI = "https://dagshub.com/Phuocbinh2003/Hoc_may_python.mlflow"
    mlflow.set_tracking_uri(DAGSHUB_MLFLOW_URI)
    st.session_state['mlflow_url'] = DAGSHUB_MLFLOW_URI
    os.environ["MLFLOW_TRACKING_USERNAME"] = "Phuocbinh2003"
    os.environ["MLFLOW_TRACKING_PASSWORD"] = "c1495823c8f9156923b06f15899e989db7e62052"
    mlflow.set_experiment("NN")

import streamlit as st
import numpy as np
import time
import mlflow
import mlflow.keras
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.model_selection import train_test_split, StratifiedKFold
from mlflow.models.signature import infer_signature


def thi_nghiem():
    st.title("üß† Hu·∫•n luy·ªán Neural Network tr√™n MNIST")

    # Load d·ªØ li·ªáu
    Xmt = np.load("buoi4/X.npy")
    ymt = np.load("buoi4/y.npy")
    X = Xmt.reshape(Xmt.shape[0], -1) / 255.0  # Chu·∫©n h√≥a d·ªØ li·ªáu v·ªÅ [0,1]
    y = ymt.reshape(-1)
  
    num_samples = st.slider("Ch·ªçn s·ªë l∆∞·ª£ng m·∫´u MNIST s·ª≠ d·ª•ng:", 1000, 60000, 5000, 1000)
    X, y = X[:num_samples], y[:num_samples]
    
    # Chia t·ª∑ l·ªá train/test
    train_size = st.slider("Ch·ªçn % t·∫≠p Train:", 50, 80, 70, 5) / 100
    test_size = 1 - train_size
    validation_size = st.slider("Ch·ªçn % t·∫≠p Validation:", 10, 30, 20, 5) / 100
    
    # Chia t·∫≠p d·ªØ li·ªáu
    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size, stratify=y, random_state=42)
    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=validation_size / (1 - test_size), stratify=y_train, random_state=42)
    k_folds = st.slider("S·ªë fold cho Cross-Validation:", 3, 10, 5)
    # C·∫•u h√¨nh m√¥ h√¨nh
    num_layers = st.slider("S·ªë l·ªõp ·∫©n:", 1, 5, 2)
    num_neurons = st.slider("S·ªë neuron m·ªói l·ªõp:", 32, 512, 128, 32)
    activation = st.selectbox("H√†m k√≠ch ho·∫°t:", ["relu", "sigmoid", "tanh"])
    optimizer = st.selectbox("Optimizer:", ["adam", "sgd", "rmsprop"])
    loss_fn = st.selectbox("H√†m m·∫•t m√°t:", ["sparse_categorical_crossentropy", "categorical_crossentropy"])
    
    
    run_name = st.text_input("üîπ Nh·∫≠p t√™n Run:", "Default_Run")
    st.session_state["run_name"] = run_name if run_name else "default_run"
    
    if st.button("üöÄ Hu·∫•n luy·ªán m√¥ h√¨nh"):
        with st.spinner("ƒêang hu·∫•n luy·ªán..."):
            mlflow.start_run(run_name=st.session_state["run_name"])
            mlflow.log_params({
                "num_layers": num_layers,
                "num_neurons": num_neurons,
                "activation": activation,
                "optimizer": optimizer,
                "loss_function": loss_fn,
                "train_size": train_size,
                "validation_size": validation_size,
                "test_size": test_size,
                "k_folds": k_folds
            })

            # K-Fold Cross-Validation
            kf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)
            accuracies, losses = [], []

            for train_idx, val_idx in kf.split(X_train, y_train):
                X_k_train, X_k_val = X_train[train_idx], X_train[val_idx]
                y_k_train, y_k_val = y_train[train_idx], y_train[val_idx]

                # X√¢y d·ª±ng m√¥ h√¨nh
                model = keras.Sequential([layers.Input(shape=(X_k_train.shape[1],))])
                for _ in range(num_layers):
                    model.add(layers.Dense(num_neurons, activation=activation))
                model.add(layers.Dense(10, activation="softmax"))

                model.compile(optimizer=optimizer, loss=loss_fn, metrics=["accuracy"])

                start_time = time.time()
                history = model.fit(X_k_train, y_k_train, epochs=20, validation_data=(X_k_val, y_k_val), verbose=0)
                elapsed_time = time.time() - start_time

                # L∆∞u k·∫øt qu·∫£ t·ª´ng fold
                accuracies.append(history.history["val_accuracy"][-1])
                losses.append(history.history["val_loss"][-1])

            # T√≠nh ƒë·ªô ch√≠nh x√°c trung b√¨nh
            avg_accuracy = np.mean(accuracies)
            avg_loss = np.mean(losses)

            mlflow.log_metric("avg_val_accuracy", avg_accuracy)
            mlflow.log_metric("avg_val_loss", avg_loss)
            mlflow.log_metric("elapsed_time", elapsed_time)

            st.session_state["trained_model"] = model

            # Log model v√†o MLflow
            example_input = np.random.rand(1, X_train.shape[1])
            example_output = model.predict(example_input)
            signature = infer_signature(example_input, example_output)

            mlflow.keras.log_model(model, "mnist_model", signature=signature, input_example=example_input)

            mlflow.end_run()
            st.success(f"‚úÖ ƒê√£ log d·ªØ li·ªáu cho **Train_{st.session_state['run_name']}**!")
            st.write(f"üìä ƒê·ªô ch√≠nh x√°c trung b√¨nh tr√™n validation: **{avg_accuracy:.4f}**")
            

import streamlit as st
import numpy as np
import joblib
import random
import pandas as pd
import time
from PIL import Image
from streamlit_drawable_canvas import st_canvas
from tensorflow.keras.models import load_model

def preprocess_canvas_image(canvas_result):
    """Chuy·ªÉn ƒë·ªïi ·∫£nh t·ª´ canvas sang ƒë·ªãnh d·∫°ng ph√π h·ª£p ƒë·ªÉ d·ª± ƒëo√°n."""
    if canvas_result.image_data is None:
        return None
    img = canvas_result.image_data[:, :, :3]  # Ch·ªâ l·∫•y 3 k√™nh RGB
    img = Image.fromarray(img).convert("L").resize((28, 28))  # Chuy·ªÉn sang grayscale, resize v·ªÅ 28x28
    img = np.array(img) / 255.0  # Chu·∫©n h√≥a v·ªÅ [0,1]
    img = img.reshape(1, -1)  # ƒê∆∞a v·ªÅ d·∫°ng vector gi·ªëng nh∆∞ trong `thi_nghiem()`
    return img

def du_doan():
    st.header("‚úçÔ∏è V·∫Ω s·ªë ƒë·ªÉ d·ª± ƒëo√°n")

    # üì• Load m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán
    if "trained_model" in st.session_state:
        model = st.session_state["trained_model"]
        st.success("‚úÖ ƒê√£ s·ª≠ d·ª•ng m√¥ h√¨nh v·ª´a hu·∫•n luy·ªán!")
    else:
        st.error("‚ö†Ô∏è Ch∆∞a c√≥ m√¥ h√¨nh! H√£y hu·∫•n luy·ªán tr∆∞·ªõc.")


    # üÜï C·∫≠p nh·∫≠t key cho canvas khi nh·∫•n "T·∫£i l·∫°i"
    if "key_value" not in st.session_state:
        st.session_state.key_value = str(random.randint(0, 1000000))  

    if st.button("üîÑ T·∫£i l·∫°i n·∫øu kh√¥ng th·∫•y canvas"):
        st.session_state.key_value = str(random.randint(0, 1000000))  

    # ‚úçÔ∏è V·∫Ω s·ªë
    canvas_result = st_canvas(
        fill_color="black",
        stroke_width=10,
        stroke_color="white",
        background_color="black",
        height=150,
        width=150,
        drawing_mode="freedraw",
        key=st.session_state.key_value,
        update_streamlit=True
    )

    if st.button("D·ª± ƒëo√°n s·ªë"):
        img = preprocess_canvas_image(canvas_result)

        if img is not None:
            st.image(Image.fromarray((img.reshape(28, 28) * 255).astype(np.uint8)), caption="·∫¢nh sau x·ª≠ l√Ω", width=100)

            # D·ª± ƒëo√°n s·ªë
            prediction = model.predict(img)
            predicted_number = np.argmax(prediction, axis=1)[0]
            max_confidence = np.max(prediction)

            st.subheader(f"üî¢ D·ª± ƒëo√°n: {predicted_number}")
            st.write(f"üìä M·ª©c ƒë·ªô tin c·∫≠y: {max_confidence:.2%}")

            # Hi·ªÉn th·ªã b·∫£ng confidence score
            prob_df = pd.DataFrame(prediction.reshape(1, -1), columns=[str(i) for i in range(10)]).T
            prob_df.columns = ["M·ª©c ƒë·ªô tin c·∫≠y"]
            st.bar_chart(prob_df)

        else:
            st.error("‚ö†Ô∏è H√£y v·∫Ω m·ªôt s·ªë tr∆∞·ªõc khi b·∫•m D·ª± ƒëo√°n!")

    
from datetime import datetime    
import streamlit as st
import mlflow
from datetime import datetime

def show_experiment_selector():
    st.title("üìä MLflow")
    
    # K·∫øt n·ªëi v·ªõi DAGsHub MLflow Tracking
    mlflow.set_tracking_uri("https://dagshub.com/Phuocbinh2003/Hoc_may_python.mlflow")
    
    # L·∫•y danh s√°ch t·∫•t c·∫£ experiments
    experiment_name = "NN"
    experiments = mlflow.search_experiments()
    selected_experiment = next((exp for exp in experiments if exp.name == experiment_name), None)

    if not selected_experiment:
        st.error(f"‚ùå Experiment '{experiment_name}' kh√¥ng t·ªìn t·∫°i!")
        return

    st.subheader(f"üìå Experiment: {experiment_name}")
    st.write(f"**Experiment ID:** {selected_experiment.experiment_id}")
    st.write(f"**Tr·∫°ng th√°i:** {'Active' if selected_experiment.lifecycle_stage == 'active' else 'Deleted'}")
    st.write(f"**V·ªã tr√≠ l∆∞u tr·ªØ:** {selected_experiment.artifact_location}")

    # L·∫•y danh s√°ch runs trong experiment
    runs = mlflow.search_runs(experiment_ids=[selected_experiment.experiment_id])

    if runs.empty:
        st.warning("‚ö† Kh√¥ng c√≥ runs n√†o trong experiment n√†y.")
        return

    st.write("### üèÉ‚Äç‚ôÇÔ∏è C√°c Runs g·∫ßn ƒë√¢y:")
    
    # L·∫•y danh s√°ch run_name t·ª´ params
    run_info = []
    for _, run in runs.iterrows():
        run_id = run["run_id"]
        run_params = mlflow.get_run(run_id).data.params
        run_name = run_params.get("run_name", f"Run {run_id[:8]}")
        run_info.append((run_name, run_id))
    
    # T·∫°o dictionary ƒë·ªÉ map run_name -> run_id
    run_name_to_id = dict(run_info)
    run_names = list(run_name_to_id.keys())
    
    # Ch·ªçn run theo run_name
    selected_run_name = st.selectbox("üîç Ch·ªçn m·ªôt run:", run_names)
    selected_run_id = run_name_to_id[selected_run_name]

    # Hi·ªÉn th·ªã th√¥ng tin chi ti·∫øt c·ªßa run ƒë∆∞·ª£c ch·ªçn
    selected_run = mlflow.get_run(selected_run_id)

    if selected_run:
        st.subheader(f"üìå Th√¥ng tin Run: {selected_run_name}")
        st.write(f"**Run ID:** {selected_run_id}")
        st.write(f"**Tr·∫°ng th√°i:** {selected_run.info.status}")
        
        start_time_ms = selected_run.info.start_time  # Th·ªùi gian l∆∞u d∆∞·ªõi d·∫°ng milliseconds
        if start_time_ms:
            start_time = datetime.fromtimestamp(start_time_ms / 1000).strftime("%Y-%m-%d %H:%M:%S")
        else:
            start_time = "Kh√¥ng c√≥ th√¥ng tin"
        
        st.write(f"**Th·ªùi gian ch·∫°y:** {start_time}")

        # Hi·ªÉn th·ªã th√¥ng s·ªë ƒë√£ log
        params = selected_run.data.params
        metrics = selected_run.data.metrics

        if params:
            st.write("### ‚öôÔ∏è Parameters:")
            st.json(params)

        if metrics:
            st.write("### üìä Metrics:")
            st.json(metrics)

        # Ki·ªÉm tra v√† hi·ªÉn th·ªã dataset artifact
        dataset_path = f"{selected_experiment.artifact_location}/{selected_run_id}/artifacts/dataset.npy"
        st.write("### üìÇ Dataset:")
        st.write(f"üì• [T·∫£i dataset]({dataset_path})")
    else:
        st.warning("‚ö† Kh√¥ng t√¨m th·∫•y th√¥ng tin cho run n√†y.")

        
        
        
          
import mlflow
import os
from mlflow.tracking import MlflowClient
def pca_tsne():
    #st.title("üöÄ MLflow DAGsHub Tracking v·ªõi Streamlit")
    
    
    
    tab1, tab2, tab3,tab4 = st.tabs(["üìò L√Ω thuy·∫øt TRAINING NEURAL NETWORK", "üìò TRAINING NEURAL NETWORK", "DEMO","üî• Mlflow"] )

    with tab1:
        explain_nn()

    with tab2:
        thi_nghiem()
    
    with tab3:
        du_doan()
    with tab4:
        show_experiment_selector()


if __name__ == "__main__":
    pca_tsne()