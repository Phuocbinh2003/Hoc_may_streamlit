import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay
import joblib  # L∆∞u m√¥ h√¨nh

def show_explanations():
    st.markdown("""
    ## üìö Gi·∫£i th√≠ch Quy tr√¨nh Ti·ªÅn x·ª≠ l√Ω
    1. **T·∫£i d·ªØ li·ªáu**: Nh·∫≠p t·∫≠p tin ·∫£nh (.npy) v√† nh√£n t∆∞∆°ng ·ª©ng  
    2. **Ki·ªÉm tra k√≠ch th∆∞·ªõc**: ƒê·∫£m b·∫£o s·ªë l∆∞·ª£ng ·∫£nh v√† nh√£n kh·ªõp nhau  
    3. **L√†m ph·∫≥ng ·∫£nh**: Chuy·ªÉn ·∫£nh 2D (28x28) th√†nh vector 1D (784 pixel)  
    4. **M√£ h√≥a nh√£n**: Chuy·ªÉn ƒë·ªïi nh√£n ch·ªØ c√°i th√†nh s·ªë nguy√™n  
    5. **Chu·∫©n h√≥a d·ªØ li·ªáu**: ƒê∆∞a gi√° tr·ªã pixel v·ªÅ kho·∫£ng [0,1]  
    """)

def display_sample_images(X, y, n_rows=3, n_cols=5):
    st.subheader("üñºÔ∏è Gallery ·∫¢nh M·∫´u")
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 8))
    for i in range(n_rows * n_cols):
        row = i // n_cols
        col = i % n_cols
        idx = np.random.randint(0, len(X))
        axes[row, col].imshow(X[idx].reshape(28, 28), cmap='gray')
        axes[row, col].set_title(f"Label: {y[idx]}", fontsize=8)
        axes[row, col].axis('off')
    plt.tight_layout()
    st.pyplot(fig)

def analyze_pixel_distribution(data):
    st.subheader("üìà Ph√¢n ph·ªëi Gi√° tr·ªã Pixel")
    plt.figure(figsize=(10, 4))

    plt.subplot(1, 2, 1)
    plt.hist(data.flatten(), bins=50, color='blue', alpha=0.7)
    plt.title('Ph√¢n ph·ªëi g·ªëc')
    plt.xlabel('Gi√° tr·ªã pixel')
    plt.ylabel('T·∫ßn su·∫•t')

    plt.subplot(1, 2, 2)
    scaler = MinMaxScaler()
    scaled_data = scaler.fit_transform(data)
    plt.hist(scaled_data.flatten(), bins=50, color='green', alpha=0.7)
    plt.title('Sau chu·∫©n h√≥a')
    plt.xlabel('Gi√° tr·ªã pixel (0-1)')

    plt.tight_layout()
    st.pyplot(plt)

def main():
    st.title("üî† Ti·ªÅn X·ª≠ l√Ω, Hu·∫•n luy·ªán & D·ª± ƒëo√°n ·∫£nh ch·ªØ c√°i")

    show_explanations()

    with st.expander("üì§ T·∫£i l√™n D·ªØ li·ªáu", expanded=True):
        col1, col2 = st.columns(2)
        with col1:
            X_file = st.file_uploader("Ch·ªçn file ·∫£nh (.npy)", type="npy")
        with col2:
            y_file = st.file_uploader("Ch·ªçn file nh√£n (.npy)", type="npy")

    if X_file and y_file:
        try:
            X = np.load(X_file)
            y = np.load(y_file).astype(str)

            if len(X) != len(y):
                st.error("‚ùå S·ªë l∆∞·ª£ng ·∫£nh v√† nh√£n kh√¥ng kh·ªõp!")
                return

            # Ti·ªÅn x·ª≠ l√Ω
            X_flat = X.reshape(X.shape[0], -1)
            le = LabelEncoder()
            y_encoded = le.fit_transform(y)
            scaler = MinMaxScaler()
            X_scaled = scaler.fit_transform(X_flat)

            df = pd.DataFrame(X_scaled, columns=[f"pixel_{i}" for i in range(X_scaled.shape[1])])
            df['label'] = y_encoded

            # Tabs
            tab1, tab2, tab3, tab4, tab5 = st.tabs([
                "üñºÔ∏è ·∫¢nh & Ph√¢n t√≠ch", "üìä D·ªØ li·ªáu", "üî§ Nh√£n", "ü§ñ Hu·∫•n luy·ªán", "üéØ D·ª± ƒëo√°n"
            ])

            with tab1:
                st.subheader("Th√¥ng tin Dataset")
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("T·ªïng s·ªë m·∫´u", len(X))
                with col2:
                    st.metric("K√≠ch th∆∞·ªõc ·∫£nh", f"{X.shape[1:] if X.ndim == 3 else X.shape[1]}")
                with col3:
                    st.metric("S·ªë l·ªõp", len(np.unique(y)))

                display_sample_images(X, y)
                analyze_pixel_distribution(X_flat)

            with tab2:
                st.dataframe(df.head(), use_container_width=True)

            with tab3:
                label_map = pd.DataFrame({
                    "K√Ω t·ª±": le.classes_,
                    "M√£ s·ªë": le.transform(le.classes_)
                })
                st.dataframe(label_map, hide_index=True)

            with tab4:
                st.subheader("ü§ñ Hu·∫•n luy·ªán m√¥ h√¨nh")

                algo = st.selectbox("Ch·ªçn thu·∫≠t to√°n", ["Logistic Regression", "KNN"])
                n_samples = st.slider("S·ªë l∆∞·ª£ng m·∫´u ƒë·ªÉ hu·∫•n luy·ªán", 100, len(X), 1000, step=100)
                test_size = st.slider("T·ª∑ l·ªá test", 0.1, 0.5, 0.2, 0.05)

                # Tr√≠ch m·∫´u
                X_sample = X_scaled[:n_samples]
                y_sample = y_encoded[:n_samples]

                X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=test_size, random_state=42)

                if algo == "Logistic Regression":
                    model = LogisticRegression(max_iter=1000)
                else:
                    k = st.slider("S·ªë l∆∞·ª£ng h√†ng x√≥m (k)", 1, 15, 3)
                    model = KNeighborsClassifier(n_neighbors=k)

                if st.button("üöÄ Hu·∫•n luy·ªán"):
                    model.fit(X_train, y_train)
                    y_pred = model.predict(X_test)
                    acc = accuracy_score(y_test, y_pred)

                    joblib.dump(model, "trained_model.pkl")
                    joblib.dump(le, "label_encoder.pkl")
                    st.success(f"üéØ ƒê·ªô ch√≠nh x√°c: {acc * 100:.2f}%")

                    fig, ax = plt.subplots(figsize=(8, 6))
                    cm = confusion_matrix(y_test, y_pred)
                    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)
                    disp.plot(ax=ax, cmap="Blues", xticks_rotation=45)
                    st.pyplot(fig)

            with tab5:
                st.subheader("üéØ D·ª± ƒëo√°n t·ª´ ·∫£nh")
                if not joblib.os.path.exists("trained_model.pkl"):
                    st.warning("‚ö†Ô∏è Vui l√≤ng hu·∫•n luy·ªán m√¥ h√¨nh tr∆∞·ªõc!")
                else:
                    model = joblib.load("trained_model.pkl")
                    le = joblib.load("label_encoder.pkl")

                    test_idx = st.slider("Ch·ªçn ch·ªâ s·ªë ·∫£nh test", 0, len(X_scaled) - 1, 0)
                    image = X_scaled[test_idx].reshape(1, -1)
                    true_label = y[test_idx]

                    pred_label = le.inverse_transform(model.predict(image))[0]

                    st.image(X[test_idx], width=150, caption="·∫¢nh c·∫ßn d·ª± ƒëo√°n")
                    st.write(f"üîç **D·ª± ƒëo√°n:** `{pred_label}`")
                    st.write(f"‚úÖ **Nh√£n th·∫≠t:** `{true_label}`")

            # T·∫£i xu·ªëng
            st.download_button(
                label="üì• T·∫£i xu·ªëng Dataset ƒë√£ x·ª≠ l√Ω",
                data=df.to_csv(index=False).encode(),
                file_name="processed_alphabet.csv",
                mime="text/csv"
            )

        except Exception as e:
            st.error(f"‚ö†Ô∏è L·ªói x·ª≠ l√Ω: {str(e)}")
    else:
        st.info("üëâ Vui l√≤ng t·∫£i l√™n c·∫£ file ·∫£nh v√† file nh√£n ƒë·ªÉ b·∫Øt ƒë·∫ßu")

if __name__ == "__main__":
    main()
