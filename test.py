import streamlit as st
import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler
from scipy.stats import zscore

# H√†m ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu t·ª´ file .npy
def tien_xu_ly_du_lieu_from_npy(X_file, y_file):
    # T·∫£i d·ªØ li·ªáu t·ª´ c√°c file .npy
    X = np.load(X_file, allow_pickle=True)
    y = np.load(y_file, allow_pickle=True)
    
    # Ki·ªÉm tra xem d·ªØ li·ªáu X c√≥ 3 chi·ªÅu kh√¥ng (ƒë·ªëi v·ªõi h√¨nh ·∫£nh)
    if X.ndim == 3:
        # L√†m ph·∫≥ng d·ªØ li·ªáu 3 chi·ªÅu (m·ªói h√¨nh ·∫£nh tr·ªü th√†nh m·ªôt vector)
        X = X.reshape(X.shape[0], -1)  # Chuy·ªÉn t·ª´ (10000, 28, 28) th√†nh (10000, 784)
    
    # Chuy·ªÉn d·ªØ li·ªáu NumPy th√†nh DataFrame ƒë·ªÉ d·ªÖ x·ª≠ l√Ω
    df = pd.DataFrame(X, columns=["Feature_" + str(i) for i in range(X.shape[1])])
    df['Target'] = y
    
    # Hi·ªÉn th·ªã th√¥ng tin d·ªØ li·ªáu g·ªëc
    st.write("üìä **D·ªØ li·ªáu g·ªëc**:")
    st.write(df.head(10))

    # Ki·ªÉm tra c√°c gi√° tr·ªã thi·∫øu
    missing_values = df.isnull().sum()
    st.write("üîç **Ki·ªÉm tra gi√° tr·ªã thi·∫øu**:")
    st.write(missing_values)

    # Ki·ªÉm tra d·ªØ li·ªáu tr√πng l·∫∑p
    duplicate_count = df.duplicated().sum()
    st.write(f"üîÅ **S·ªë l∆∞·ª£ng d√≤ng b·ªã tr√πng l·∫∑p**: {duplicate_count}")

    # Ki·ªÉm tra outliers (S·ª≠ d·ª•ng Z-score)
    outlier_count = {
        col: (abs(zscore(df[col], nan_policy='omit')) > 3).sum()
        for col in df.select_dtypes(include=['number']).columns
    }
    st.write("üö® **Outliers** (Z-score > 3):")
    st.write(outlier_count)

    # X·ª≠ l√Ω c√°c c·ªôt ki·ªÉu ch·ªØ (alphabet) b·∫±ng LabelEncoder
    label_encoder = LabelEncoder()
    for column in df.select_dtypes(include=['object']).columns:
        df[column] = label_encoder.fit_transform(df[column])

    # Ti·ªÅn x·ª≠ l√Ω c√°c gi√° tr·ªã thi·∫øu
    df['Target'] = df['Target'].fillna(df['Target'].mode()[0])  # ƒêi·ªÅn gi√° tr·ªã thi·∫øu b·∫±ng gi√° tr·ªã mode
    df.dropna(inplace=True)  # Lo·∫°i b·ªè c√°c d√≤ng ch·ª©a gi√° tr·ªã thi·∫øu n·∫øu c·∫ßn

    # Chu·∫©n h√≥a d·ªØ li·ªáu s·ªë
    scaler = StandardScaler()
    df[df.select_dtypes(include=[np.number]).columns] = scaler.fit_transform(df.select_dtypes(include=[np.number]))

    # Hi·ªÉn th·ªã d·ªØ li·ªáu sau khi ti·ªÅn x·ª≠ l√Ω
    st.write("‚úÖ **D·ªØ li·ªáu sau khi ti·ªÅn x·ª≠ l√Ω**:")
    st.write(df.head(10))

    return df

# H√†m ƒë·ªÉ hi·ªÉn th·ªã v√† ti·ªÅn x·ª≠ l√Ω
def show_preprocessing_tab():
    st.title("üîç Ti·ªÅn x·ª≠ l√Ω D·ªØ li·ªáu - Alphabet (t·ª´ .npy)")

    # Ch·ªçn t·ªáp .npy
    X_file = st.file_uploader("üìÇ T·∫£i l√™n t·ªáp d·ªØ li·ªáu X (.npy)", type=["npy"])
    y_file = st.file_uploader("üìÇ T·∫£i l√™n t·ªáp d·ªØ li·ªáu y (.npy)", type=["npy"])
    
    # N·∫øu ng∆∞·ªùi d√πng t·∫£i l√™n c·∫£ X v√† y, th·ª±c hi·ªán ti·ªÅn x·ª≠ l√Ω
    if X_file is not None and y_file is not None:
        # L∆∞u t·ªáp t·∫£i l√™n t·∫°m th·ªùi
        with open("/mnt/data/X_data.npy", "wb") as f:
            f.write(X_file.getbuffer())
        with open("/mnt/data/y_data.npy", "wb") as f:
            f.write(y_file.getbuffer())

        # G·ªçi h√†m ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu t·ª´ c√°c t·ªáp .npy
        df = tien_xu_ly_du_lieu_from_npy("/mnt/data/X_data.npy", "/mnt/data/y_data.npy")
    else:
        st.warning("‚ö†Ô∏è Vui l√≤ng t·∫£i l√™n c·∫£ hai t·ªáp d·ªØ li·ªáu X v√† y!")

# G·ªçi h√†m trong Streamlit
if __name__ == "__main__":
    show_preprocessing_tab()
