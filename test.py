import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
import plotly.express as px
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.datasets import fetch_openml

def explain_pca():
    st.markdown("## üß† Hi·ªÉu PCA m·ªôt c√°ch ƒë∆°n gi·∫£n")

    st.markdown("""
    **PCA (Ph√¢n t√≠ch th√†nh ph·∫ßn ch√≠nh)** l√† m·ªôt ph∆∞∆°ng ph√°p gi√∫p gi·∫£m s·ªë chi·ªÅu c·ªßa d·ªØ li·ªáu m√† v·∫´n gi·ªØ ƒë∆∞·ª£c th√¥ng tin quan tr·ªçng nh·∫•t.  
    H√£y t∆∞·ªüng t∆∞·ª£ng b·∫°n c√≥ m·ªôt t·∫≠p d·ªØ li·ªáu nhi·ªÅu chi·ªÅu (nhi·ªÅu c·ªôt), nh∆∞ng b·∫°n mu·ªën bi·ªÉu di·ªÖn n√≥ trong kh√¥ng gian 2D ho·∫∑c 3D ƒë·ªÉ d·ªÖ hi·ªÉu h∆°n. PCA gi√∫p b·∫°n l√†m ƒëi·ªÅu ƒë√≥!  

    ### üîπ **V√≠ d·ª• tr·ª±c quan**:
    H√£y t∆∞·ªüng t∆∞·ª£ng b·∫°n c√≥ m·ªôt t·∫≠p d·ªØ li·ªáu g·ªìm nhi·ªÅu ƒëi·ªÉm ph√¢n b·ªë theo m·ªôt ƒë∆∞·ªùng ch√©o trong kh√¥ng gian 2D:
    """)

   
    np.random.seed(42)
    x = np.random.rand(100) * 10  
    y = x * 0.8 + np.random.randn(100) * 2  
    X = np.column_stack((x, y))

    fig, ax = plt.subplots()
    ax.scatter(X[:, 0], X[:, 1], color="blue", alpha=0.5, label="D·ªØ li·ªáu ban ƒë·∫ßu")
    ax.set_xlabel("X1")
    ax.set_ylabel("X2")
    ax.legend()
    st.pyplot(fig)

    st.markdown(r"""
    ## üìå PCA - Gi·∫£i th√≠ch Tr·ª±c Quan  
    D·ªØ li·ªáu n√†y c√≥ s·ª± ph√¢n t√°n r√µ r√†ng theo m·ªôt h∆∞·ªõng ch√≠nh. PCA s·∫Ω t√¨m ra h∆∞·ªõng ƒë√≥ ƒë·ªÉ bi·ªÉu di·ªÖn d·ªØ li·ªáu m·ªôt c√°ch t·ªëi ∆∞u.

    ---

    ### üîπ **C√°c b∆∞·ªõc th·ª±c hi·ªán PCA d·ªÖ hi·ªÉu**

    1Ô∏è‚É£ **T√¨m ƒëi·ªÉm trung t√¢m (mean vector)**  
    - Tr∆∞·ªõc ti√™n, t√≠nh gi√° tr·ªã trung b√¨nh c·ªßa t·ª´ng ƒë·∫∑c tr∆∞ng (feature) trong t·∫≠p d·ªØ li·ªáu.  
    - Vector trung b√¨nh n√†y gi√∫p x√°c ƒë·ªãnh "trung t√¢m" c·ªßa d·ªØ li·ªáu.  
    $$ 
    \mu = \frac{1}{n} \sum_{i=1}^{n} x_i 
    $$  
    - Trong ƒë√≥:
        - \( n \) l√† s·ªë l∆∞·ª£ng m·∫´u d·ªØ li·ªáu.
        - \( x_i \) l√† t·ª´ng ƒëi·ªÉm d·ªØ li·ªáu.

    2Ô∏è‚É£ **D·ªãch chuy·ªÉn d·ªØ li·ªáu v·ªÅ g·ªëc t·ªça ƒë·ªô**  
    - ƒê·ªÉ ƒë·∫£m b·∫£o ph√¢n t√≠ch ch√≠nh x√°c h∆°n, ta d·ªãch chuy·ªÉn d·ªØ li·ªáu sao cho trung t√¢m c·ªßa n√≥ n·∫±m t·∫°i g·ªëc t·ªça ƒë·ªô b·∫±ng c√°ch tr·ª´ ƒëi vector trung b√¨nh:  
    $$ 
    X_{\text{norm}} = X - \mu
    $$  
    - Khi ƒë√≥, d·ªØ li·ªáu s·∫Ω c√≥ gi√° tr·ªã trung b√¨nh b·∫±ng 0.

    3Ô∏è‚É£ **T√≠nh ma tr·∫≠n hi·ªáp ph∆∞∆°ng sai**  
    - Ma tr·∫≠n hi·ªáp ph∆∞∆°ng sai gi√∫p ƒëo l∆∞·ªùng m·ª©c ƒë·ªô bi·∫øn thi√™n gi·ªØa c√°c ƒë·∫∑c tr∆∞ng:  
    $$ 
    C = \frac{1}{n} X_{\text{norm}}^T X_{\text{norm}}
    $$  
    - √ù nghƒ©a:
        - N·∫øu ph·∫ßn t·ª≠ \( C_{ij} \) c√≥ gi√° tr·ªã l·ªõn ‚Üí Hai ƒë·∫∑c tr∆∞ng \( i \) v√† \( j \) c√≥ m·ªëi t∆∞∆°ng quan m·∫°nh.
        - N·∫øu \( C_{ij} \) g·∫ßn 0 ‚Üí Hai ƒë·∫∑c tr∆∞ng kh√¥ng li√™n quan nhi·ªÅu.

    4Ô∏è‚É£ **T√¨m c√°c h∆∞·ªõng quan tr·ªçng nh·∫•t**  
    - T√≠nh tr·ªã ri√™ng (eigenvalues) v√† vector ri√™ng (eigenvectors) t·ª´ ma tr·∫≠n hi·ªáp ph∆∞∆°ng sai:  
    $$ 
    C v = \lambda v
    $$  
    - Trong ƒë√≥:
        - \( v \) l√† vector ri√™ng (eigenvector) - ƒë·∫°i di·ªán cho c√°c h∆∞·ªõng ch√≠nh c·ªßa d·ªØ li·ªáu.
        - \( \lambda \) l√† tr·ªã ri√™ng (eigenvalue) - th·ªÉ hi·ªán ƒë·ªô quan tr·ªçng c·ªßa t·ª´ng h∆∞·ªõng.
    - Vector ri√™ng c√≥ tr·ªã ri√™ng l·ªõn h∆°n s·∫Ω mang nhi·ªÅu th√¥ng tin quan tr·ªçng h∆°n.

    5Ô∏è‚É£ **Ch·ªçn s·ªë chi·ªÅu m·ªõi v√† t·∫°o kh√¥ng gian con**  
    - Ch·ªçn \( K \) vector ri√™ng t∆∞∆°ng ·ª©ng v·ªõi \( K \) tr·ªã ri√™ng l·ªõn nh·∫•t ƒë·ªÉ t·∫°o ma tr·∫≠n \( U_K \):  
    $$ 
    U_K = [v_1, v_2, ..., v_K]
    $$  
    - C√°c vector n√†y t·∫°o th√†nh h·ªá tr·ª±c giao v√† gi√∫p ta bi·ªÉu di·ªÖn d·ªØ li·ªáu t·ªëi ∆∞u trong kh√¥ng gian m·ªõi.

    6Ô∏è‚É£ **Chi·∫øu d·ªØ li·ªáu v√†o kh√¥ng gian m·ªõi**  
    - Bi·ªÉu di·ªÖn d·ªØ li·ªáu trong h·ªá tr·ª•c m·ªõi b·∫±ng c√°ch nh√¢n d·ªØ li·ªáu chu·∫©n h√≥a v·ªõi ma tr·∫≠n \( U_K \):  
    $$ 
    X_{\text{new}} = X_{\text{norm}} U_K
    $$  
    - D·ªØ li·ªáu m·ªõi \( X_{\text{new}} \) c√≥ s·ªë chi·ªÅu √≠t h∆°n nh∆∞ng v·∫´n gi·ªØ ƒë∆∞·ª£c nhi·ªÅu th√¥ng tin quan tr·ªçng.

    7Ô∏è‚É£ **D·ªØ li·ªáu m·ªõi ch√≠nh l√† t·ªça ƒë·ªô c·ªßa c√°c ƒëi·ªÉm trong kh√¥ng gian m·ªõi.**  
    - M·ªói ƒëi·ªÉm d·ªØ li·ªáu gi·ªù ƒë√¢y ƒë∆∞·ª£c bi·ªÉu di·ªÖn b·∫±ng c√°c th√†nh ph·∫ßn ch√≠nh thay v√¨ c√°c ƒë·∫∑c tr∆∞ng ban ƒë·∫ßu.

    ---

    ### üîπ **Tr·ª±c quan h√≥a qu√° tr√¨nh PCA**  
    D∆∞·ªõi ƒë√¢y l√† minh h·ªça c√°ch PCA t√¨m ra tr·ª•c quan tr·ªçng nh·∫•t c·ªßa d·ªØ li·ªáu:
    """)



    # PCA th·ªß c√¥ng
    X_centered = X - np.mean(X, axis=0)
    cov_matrix = np.cov(X_centered.T)
    eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)

    fig, ax = plt.subplots()
    ax.scatter(X[:, 0], X[:, 1], color="blue", alpha=0.5, label="D·ªØ li·ªáu ban ƒë·∫ßu")
    origin = np.mean(X, axis=0)

    for i in range(2):
        ax.arrow(origin[0], origin[1], 
                 eigenvectors[0, i] * 3, eigenvectors[1, i] * 3, 
                 head_width=0.3, head_length=0.3, color="red", label=f"Tr·ª•c {i+1}")

    ax.set_xlabel("X1")
    ax.set_ylabel("X2")
    ax.legend()
    st.pyplot(fig)

    st.markdown("""
    **üîπ K·∫øt qu·∫£:**  
    - Tr·ª•c ƒë·ªè l√† h∆∞·ªõng m√† PCA t√¨m ra.  
    - N·∫øu ch·ªçn 1 tr·ª•c ch√≠nh, ta c√≥ th·ªÉ chi·∫øu d·ªØ li·ªáu l√™n n√≥ ƒë·ªÉ gi·∫£m chi·ªÅu.  
      
    Nh·ªù ƒë√≥, ch√∫ng ta c√≥ th·ªÉ bi·ªÉu di·ªÖn d·ªØ li·ªáu m·ªôt c√°ch g·ªçn g√†ng h∆°n m√† kh√¥ng m·∫•t qu√° nhi·ªÅu th√¥ng tin!  
    """)


def explain_tsne():
    st.markdown(r"""
    ## üåå t-Distributed Stochastic Neighbor Embedding (t-SNE)
    t-SNE l√† m·ªôt ph∆∞∆°ng ph√°p gi·∫£m chi·ªÅu m·∫°nh m·∫Ω, gi√∫p hi·ªÉn th·ªã d·ªØ li·ªáu ƒëa chi·ªÅu tr√™n m·∫∑t ph·∫≥ng 2D ho·∫∑c kh√¥ng gian 3D b·∫±ng c√°ch b·∫£o to√†n m·ªëi quan h·ªá gi·ªØa c√°c ƒëi·ªÉm g·∫ßn nhau.

    ---
    
    ### üîπ **Nguy√™n l√Ω ho·∫°t ƒë·ªông c·ªßa t-SNE**
    
    1Ô∏è‚É£ **T√≠nh x√°c su·∫•t ƒëi·ªÉm g·∫ßn nhau trong kh√¥ng gian g·ªëc**  
       - V·ªõi m·ªói ƒëi·ªÉm \( x_i \), x√°c su·∫•t c√≥ ƒëi·ªÅu ki·ªán gi·ªØa \( x_i \) v√† \( x_j \) ƒë∆∞·ª£c t√≠nh d·ª±a tr√™n kho·∫£ng c√°ch Gaussian:  
       $$ 
       p_{j|i} = \frac{\exp(-\| x_i - x_j \|^2 / 2\sigma^2)}{\sum_{k \neq i} \exp(-\| x_i - x_k \|^2 / 2\sigma^2)} 
       $$  
       - Trong ƒë√≥:
         - \( \sigma \) l√† ƒë·ªô l·ªách chu·∫©n (bandwidth) c·ªßa Gaussian Kernel.
         - X√°c su·∫•t n√†y ph·∫£n √°nh m·ª©c ƒë·ªô g·∫ßn g≈©i c·ªßa c√°c ƒëi·ªÉm d·ªØ li·ªáu trong kh√¥ng gian ban ƒë·∫ßu.
      
    2Ô∏è‚É£ **T√≠nh x√°c su·∫•t trong kh√¥ng gian gi·∫£m chi·ªÅu (2D/3D)**  
       - Trong kh√¥ng gian gi·∫£m chi·ªÅu, t-SNE s·ª≠ d·ª•ng ph√¢n ph·ªëi t-Student v·ªõi m·ªôt m·ª©c ƒë·ªô t·ª± do ƒë·ªÉ gi·ªØ kho·∫£ng c√°ch gi·ªØa c√°c ƒëi·ªÉm:  
       $$ 
       q_{j|i} = \frac{(1 + \| y_i - y_j \|^2)^{-1}}{\sum_{k \neq i} (1 + \| y_i - y_k \|^2)^{-1}}
       $$  
       - √ù nghƒ©a:
         - Ph√¢n ph·ªëi t-Student gi√∫p gi·∫£m t√°c ƒë·ªông c·ªßa c√°c ƒëi·ªÉm xa nhau, t·∫°o ra c·ª•m d·ªØ li·ªáu r√µ h∆°n.
      
    3Ô∏è‚É£ **T·ªëi ∆∞u h√≥a kho·∫£ng c√°ch gi·ªØa \( p_{j|i} \) v√† \( q_{j|i} \)**  
       - t-SNE c·ªë g·∫Øng l√†m cho ph√¢n ph·ªëi x√°c su·∫•t trong kh√¥ng gian g·ªëc g·∫ßn b·∫±ng trong kh√¥ng gian m·ªõi b·∫±ng c√°ch t·ªëi thi·ªÉu h√≥a **h√†m m·∫•t m√°t Kullback-Leibler (KL divergence)**:  
       $$ 
       KL(P||Q) = \sum_{i \neq j} p_{ij} \log \frac{p_{ij}}{q_{ij}}
       $$  
       - √ù nghƒ©a:
         - N·∫øu \( P \) v√† \( Q \) gi·ªëng nhau, KL divergence s·∫Ω nh·ªè.
         - t-SNE c·∫≠p nh·∫≠t t·ªça ƒë·ªô \( y_i \) ƒë·ªÉ gi·∫£m KL divergence, gi√∫p b·∫£o to√†n c·∫•u tr√∫c d·ªØ li·ªáu.

    ---
    
    ### üìä **Tr·ª±c quan h√≥a qu√° tr√¨nh t-SNE**  
    D∆∞·ªõi ƒë√¢y l√† minh h·ªça c√°ch t-SNE bi·∫øn ƒë·ªïi d·ªØ li·ªáu t·ª´ kh√¥ng gian g·ªëc sang kh√¥ng gian gi·∫£m chi·ªÅu:  
    """)

    # Tr·ª±c quan h√≥a b·∫±ng bi·ªÉu ƒë·ªì matplotlib
    import streamlit as st
    import numpy as np
    import matplotlib.pyplot as plt
    from sklearn.manifold import TSNE

    # T·∫°o d·ªØ li·ªáu h√¨nh c·∫ßu (phi tuy·∫øn t√≠nh)
    np.random.seed(42)
    num_points = 500
    phi = np.random.uniform(0, np.pi, num_points)  # G√≥c azimuth
    theta = np.random.uniform(0, 2 * np.pi, num_points)  # G√≥c polar
    r = np.random.uniform(4, 6, num_points)  # B√°n k√≠nh

    # Chuy·ªÉn sang t·ªça ƒë·ªô Descartes (x, y, z)
    X = np.zeros((num_points, 3))
    X[:, 0] = r * np.sin(phi) * np.cos(theta)  # x
    X[:, 1] = r * np.sin(phi) * np.sin(theta)  # y
    X[:, 2] = r * np.cos(phi)  # z

    # Nh√£n d·ª±a tr√™n b√°n k√≠nh (ph√¢n c·ª•m ƒë∆°n gi·∫£n)
    labels = (r > 5).astype(int)

    # Gi·∫£m chi·ªÅu b·∫±ng t-SNE
    X_embedded = TSNE(n_components=2, perplexity=40, learning_rate=200, random_state=42).fit_transform(X)

    # Hi·ªÉn th·ªã k·∫øt qu·∫£ tr√™n Streamlit
    st.title("So s√°nh kh√¥ng gian g·ªëc v√† t-SNE")

    fig, ax = plt.subplots(1, 2, figsize=(12, 5))

    # Kh√¥ng gian g·ªëc (3D chi·∫øu l√™n 2D)
    ax[0].scatter(X[:, 0], X[:, 1], c=labels, cmap="coolwarm", alpha=0.6)
    ax[0].set_title("Kh√¥ng gian g·ªëc")
    ax[0].set_xlabel("$x_1$")
    ax[0].set_ylabel("$x_2$")

    # Kh√¥ng gian sau khi gi·∫£m chi·ªÅu b·∫±ng t-SNE
    ax[1].scatter(X_embedded[:, 0], X_embedded[:, 1], c=labels, cmap="coolwarm", alpha=0.6)
    ax[1].set_title("Kh√¥ng gian sau khi gi·∫£m chi·ªÅu (t-SNE)")
    ax[1].set_xlabel("$y_1$")
    ax[1].set_ylabel("$y_2$")

    st.pyplot(fig)

    st.markdown(r"""
    ---
    
    ### ‚úÖ **∆Øu ƒëi·ªÉm c·ªßa t-SNE**
    - T·∫°o c·ª•m d·ªØ li·ªáu r√µ r√†ng, d·ªÖ quan s√°t.
    - Gi·ªØ ƒë∆∞·ª£c m·ªëi quan h·ªá phi tuy·∫øn t√≠nh trong d·ªØ li·ªáu.

    ### ‚ùå **Nh∆∞·ª£c ƒëi·ªÉm c·ªßa t-SNE**
    - Ch·∫°y ch·∫≠m h∆°n PCA, ƒë·∫∑c bi·ªát v·ªõi d·ªØ li·ªáu l·ªõn.
    - Nh·∫°y c·∫£m v·ªõi tham s·ªë **perplexity** (n·∫øu ch·ªçn sai c√≥ th·ªÉ g√¢y m√©o m√≥ d·ªØ li·ªáu).

    ---
    
    üìå **Ghi nh·ªõ:**  
    - t-SNE ph√π h·ª£p ƒë·ªÉ **tr·ª±c quan h√≥a d·ªØ li·ªáu**, nh∆∞ng **kh√¥ng ph√π h·ª£p cho gi·∫£m chi·ªÅu ph·ª•c v·ª• m√¥ h√¨nh h·ªçc m√°y** (do kh√¥ng b·∫£o to√†n c·∫•u tr√∫c t·ªïng th·ªÉ c·ªßa d·ªØ li·ªáu).  
    """)


def thi_nghiem():
    
    st.title("üìâ Gi·∫£m chi·ªÅu d·ªØ li·ªáu MNIST v·ªõi PCA & t-SNE")

    # Load d·ªØ li·ªáu
    Xmt = np.load("buoi4/X.npy")
    ymt = np.load("buoi4/y.npy")
    X = Xmt.reshape(Xmt.shape[0], -1) 
    y = ymt.reshape(-1) 






    # T√πy ch·ªçn thu·∫≠t to√°n
    method = st.radio("Ch·ªçn ph∆∞∆°ng ph√°p gi·∫£m chi·ªÅu", ["PCA", "t-SNE"])
    n_components = st.slider("S·ªë chi·ªÅu gi·∫£m xu·ªëng", 2, 3, 2)

    # Gi·ªõi h·∫°n s·ªë m·∫´u ƒë·ªÉ tƒÉng t·ªëc (c√≥ th·ªÉ ch·ªânh s·ª≠a)
    num_samples = 5000
    X_subset, y_subset = X[:num_samples], y[:num_samples]

    # N√∫t ch·∫°y thu·∫≠t to√°n
    if st.button("üöÄ Ch·∫°y gi·∫£m chi·ªÅu"):
        with st.spinner("ƒêang x·ª≠ l√Ω..."):
            if method == "PCA":
                reducer = PCA(n_components=n_components)
            else:
                reducer = TSNE(n_components=n_components, perplexity=min(30, num_samples - 1), random_state=42)

            X_reduced = reducer.fit_transform(X_subset)

            # Hi·ªÉn th·ªã k·∫øt qu·∫£
            if n_components == 2:
                fig = px.scatter(x=X_reduced[:, 0], y=X_reduced[:, 1], color=y_subset.astype(str),
                                title=f"{method} gi·∫£m chi·ªÅu xu·ªëng {n_components}D",
                                labels={'x': "Th√†nh ph·∫ßn 1", 'y': "Th√†nh ph·∫ßn 2"})
            else:  # Bi·ªÉu ƒë·ªì 3D
                fig = px.scatter_3d(x=X_reduced[:, 0], y=X_reduced[:, 1], z=X_reduced[:, 2],
                                    color=y_subset.astype(str),
                                    title=f"{method} gi·∫£m chi·ªÅu xu·ªëng {n_components}D",
                                    labels={'x': "Th√†nh ph·∫ßn 1", 'y': "Th√†nh ph·∫ßn 2", 'z': "Th√†nh ph·∫ßn 3"})

            st.plotly_chart(fig)

    st.success("Ho√†n th√†nh!")
    
    
def pca_tsne():
        
    tab1, tab2, tab3 = st.tabs(["üìò L√Ω thuy·∫øt PCA", "üìò L√Ω thuy·∫øt t-NSE", "üìò Gi·∫£m chi·ªÅu"] )

    with tab1:
        explain_pca()

    with tab2:
        explain_tsne()
    
    with tab3:
        thi_nghiem()



if __name__ == "__main__":
    pca_tsne()