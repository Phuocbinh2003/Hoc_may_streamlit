import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
import mlflow
import os
import time
from datetime import datetime
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import Callback
import plotly.express as px

# ======================================
# PH·∫¶N 1: L√ù THUY·∫æT NEURAL NETWORK
# ======================================
def explain_nn():
    st.markdown("""
    ## üß† Neural Network C∆° B·∫£n

    **Neural Network (M·∫°ng n∆°-ron)** l√† m√¥ h√¨nh l·∫•y c·∫£m h·ª©ng t·ª´ ho·∫°t ƒë·ªông c·ªßa n√£o b·ªô, g·ªìm nhi·ªÅu l·ªõp n∆°-ron nh√¢n t·∫°o k·∫øt n·ªëi v·ªõi nhau.

    ### üî∞ Ki·∫øn tr√∫c c∆° b·∫£n:
    """)
    st.image("https://www.researchgate.net/publication/372377465/figure/fig1/AS:11431281141736600@1686735021201/Architecture-of-an-Artificial-Neural-Network-ANN.png", 
             width=600)
    
    st.markdown("""
    ### üìå C√°c th√†nh ph·∫ßn ch√≠nh:
    1. **Input Layer**: L·ªõp ti·∫øp nh·∫≠n d·ªØ li·ªáu ƒë·∫ßu v√†o
    2. **Hidden Layers**: C√°c l·ªõp x·ª≠ l√Ω ·∫©n
    3. **Output Layer**: L·ªõp ƒë∆∞a ra k·∫øt qu·∫£ d·ª± ƒëo√°n

    ### üéØ H√†m k√≠ch ho·∫°t (Activation Functions):
    """)
    col1, col2, col3 = st.columns(3)
    with col1:
        st.image("https://miro.medium.com/v2/resize:fit:1400/1*syRl4D2_FnIyVvy2ZCYCFQ.png", 
                 caption="Sigmoid", width=200)
    with col2:
        st.image("https://upload.wikimedia.org/wikipedia/commons/thumb/c/c9/Rectified_linear_unit.svg/1200px-Rectified_linear_unit.svg.png", 
                 caption="ReLU", width=200)
    with col3:
        st.image("https://paperswithcode.com/media/thumbnails/task/task-0000000607-aa5b1a4e.jpg", 
                 caption="Softmax", width=200)
    
    st.markdown("""
    ### üîÑ Qu√° tr√¨nh lan truy·ªÅn:
    1. **Lan truy·ªÅn thu·∫≠n (Forward Propagation)**: T√≠nh to√°n ƒë·∫ßu ra
    2. **T√≠nh to√°n loss**: So s√°nh v·ªõi gi√° tr·ªã th·ª±c
    3. **Lan truy·ªÅn ng∆∞·ª£c (Backpropagation)**: C·∫≠p nh·∫≠t tr·ªçng s·ªë
    4. **T·ªëi ∆∞u h√≥a**: S·ª≠ d·ª•ng c√°c thu·∫≠t to√°n nh∆∞ GD, Adam

    ### üìâ H√†m m·∫•t m√°t ph·ªï bi·∫øn:
    ```python
    Loss = CrossEntropy(y_true, y_pred)
    ```
    """)

# ======================================
# PH·∫¶N 2: DEMO TRAINING NEURAL NETWORK
# ======================================
def load_mnist():
    mnist = fetch_openml('mnist_784', version=1, parser='auto')
    X = mnist.data.astype('float32')
    y = mnist.target.astype('int64')
    return X, y

def create_model(layers, activations, dropout_rate):
    model = Sequential()
    for i, (units, activation) in enumerate(zip(layers, activations)):
        if i == 0:
            model.add(Dense(units, activation=activation, input_shape=(784,)))
        else:
            model.add(Dense(units, activation=activation))
        if dropout_rate > 0:
            model.add(Dropout(dropout_rate))
    model.add(Dense(10, activation='softmax'))
    return model

class MlflowLogger(Callback):
    def on_epoch_end(self, epoch, logs=None):
        mlflow.log_metrics({
            'train_loss': logs['loss'],
            'train_accuracy': logs['accuracy'],
            'val_loss': logs['val_loss'],
            'val_accuracy': logs['val_accuracy']
        }, step=epoch)

def input_mlflow():
    mlflow.set_tracking_uri("https://dagshub.com/Phuocbinh2003/Hoc_may_python.mlflow")
    os.environ["MLFLOW_TRACKING_USERNAME"] = "Phuocbinh2003"
    os.environ["MLFLOW_TRACKING_PASSWORD"] = "c1495823c8f9156923b06f15899e989db7e62052"
    mlflow.set_experiment("Neural_Network_MNIST")

def train_neural_net():
    st.title("üî¢ Nh·∫≠n di·ªán ch·ªØ s·ªë vi·∫øt tay v·ªõi Neural Network")

    # Load d·ªØ li·ªáu
    X, y = load_mnist()
    
    # Chu·∫©n h√≥a d·ªØ li·ªáu
    scaler = MinMaxScaler()
    X_scaled = scaler.fit_transform(X)
    
    # Chia t·∫≠p train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y, test_size=0.2, random_state=42
    )

    # Sidebar controls
    st.sidebar.header("‚öôÔ∏è Thi·∫øt l·∫≠p tham s·ªë")
    layers = []
    activations = []
    
    num_layers = st.sidebar.slider("S·ªë l·ªõp ·∫©n", 1, 5, 2)
    for i in range(num_layers):
        col1, col2 = st.sidebar.columns(2)
        with col1:
            units = col1.number_input(f"N∆°-ron l·ªõp {i+1}", 32, 512, 128, key=f"units_{i}")
        with col2:
            activation = col2.selectbox(
                f"H√†m k√≠ch ho·∫°t l·ªõp {i+1}",
                ["relu", "sigmoid", "tanh"],
                key=f"activation_{i}"
            )
        layers.append(units)
        activations.append(activation)
    
    dropout_rate = st.sidebar.slider("Dropout rate", 0.0, 0.5, 0.2)
    learning_rate = st.sidebar.selectbox("Learning rate", [1e-2, 1e-3, 1e-4], index=1)
    epochs = st.sidebar.slider("Epochs", 5, 50, 10)
    batch_size = st.sidebar.slider("Batch size", 32, 256, 128)

    # T·∫°o model
    model = create_model(layers, activations, dropout_rate)
    model.compile(optimizer=Adam(learning_rate=learning_rate),
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])

    # MLflow setup
    input_mlflow()
    run_name = st.text_input("Nh·∫≠p t√™n run:", f"Run_{datetime.now().strftime('%Y%m%d%H%M')}")
    
    if st.button("üé¨ B·∫Øt ƒë·∫ßu training"):
        with st.spinner("ƒêang training..."):
            with mlflow.start_run(run_name=run_name):
                # Log parameters
                mlflow.log_params({
                    "num_layers": num_layers,
                    "layers": layers,
                    "activations": activations,
                    "dropout_rate": dropout_rate,
                    "learning_rate": learning_rate,
                    "epochs": epochs,
                    "batch_size": batch_size
                })

                # Training
                start_time = time.time()
                history = model.fit(
                    X_train, y_train,
                    validation_split=0.2,
                    epochs=epochs,
                    batch_size=batch_size,
                    verbose=0,
                    callbacks=[MlflowLogger()]
                )
                training_time = time.time() - start_time

                # ƒê√°nh gi√°
                test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)
                
                # Log metrics
                mlflow.log_metrics({
                    "final_test_loss": test_loss,
                    "final_test_accuracy": test_acc,
                    "training_time": training_time
                })

                # Hi·ªÉn th·ªã k·∫øt qu·∫£
                st.subheader("üìä K·∫øt qu·∫£ training")
                col1, col2, col3 = st.columns(3)
                col1.metric("Train Accuracy", f"{history.history['accuracy'][-1]:.2%}")
                col2.metric("Validation Accuracy", f"{history.history['val_accuracy'][-1]:.2%}")
                col3.metric("Test Accuracy", f"{test_acc:.2%}")

                # V·∫Ω ƒë·ªì th·ªã
                fig = px.line(
                    history.history,
                    y=['loss', 'val_loss'],
                    labels={'value': 'Loss', 'variable': 'Lo·∫°i'},
                    title='Bi·ªÉu ƒë·ªì Loss qua c√°c epochs'
                )
                st.plotly_chart(fig)

                # L∆∞u model
                model.save("model.h5")
                mlflow.log_artifact("model.h5")
                st.success("‚úÖ Training ho√†n t·∫•t!")
                st.markdown(f"### üîó [Theo d√µi tr√™n MLflow UI]({mlflow.get_tracking_uri()})")

# ======================================
# PH·∫¶N 3: GIAO DI·ªÜN CH√çNH
# ======================================
def main():
    st.set_page_config(page_title="Neural Network MNIST", page_icon="üß†")
    
    tab1, tab2, tab3 = st.tabs(["üìö L√Ω thuy·∫øt", "üéÆ Th·ª≠ nghi·ªám", "üìä MLflow"])
    
    with tab1:
        explain_nn()
    
    with tab2:
        train_neural_net()
    
    with tab3:
        st.write("Truy c·∫≠p MLflow ƒë·ªÉ xem chi ti·∫øt c√°c runs:")
        st.markdown("[üîó MLflow Tracking tr√™n DAGsHub](https://dagshub.com/Phuocbinh2003/Hoc_may_python.mlflow)")

if __name__ == "__main__":
    main()