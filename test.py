import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score

# ----------- Gi·∫£i th√≠ch quy tr√¨nh ----------------
def show_explanations():
    st.markdown("""
    ## üìö Gi·∫£i th√≠ch Quy tr√¨nh Ti·ªÅn x·ª≠ l√Ω.
    1. **T·∫£i d·ªØ li·ªáu**: Nh·∫≠p t·∫≠p tin ·∫£nh (.npy) v√† nh√£n t∆∞∆°ng ·ª©ng  
    2. **Ki·ªÉm tra k√≠ch th∆∞·ªõc**: ƒê·∫£m b·∫£o s·ªë l∆∞·ª£ng ·∫£nh v√† nh√£n kh·ªõp nhau  
    3. **L√†m ph·∫≥ng ·∫£nh**: Chuy·ªÉn ·∫£nh 2D (28x28) th√†nh vector 1D  
    4. **M√£ h√≥a nh√£n**: Chuy·ªÉn ƒë·ªïi nh√£n ch·ªØ c√°i th√†nh s·ªë nguy√™n  
    5. **Chu·∫©n h√≥a d·ªØ li·ªáu**: ƒê∆∞a gi√° tr·ªã pixel v·ªÅ kho·∫£ng [0,1]  
    6. **Hu·∫•n luy·ªán m√¥ h√¨nh**: Logistic Regression ho·∫∑c KNN  
    7. **D·ª± ƒëo√°n & ƒê√°nh gi√°**: ƒê·ªô ch√≠nh x√°c + Ma tr·∫≠n nh·∫ßm l·∫´n
    """)

# ----------- Hi·ªÉn th·ªã ·∫£nh m·∫´u ----------------
def display_sample_images(X, y, n_rows=3, n_cols=5):
    st.subheader("üñºÔ∏è Gallery ·∫¢nh M·∫´u")
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 8))
    for i in range(n_rows * n_cols):
        row = i // n_cols
        col = i % n_cols
        idx = np.random.randint(0, len(X))
        try:
            img = X[idx].reshape(28, 28)
            axes[row, col].imshow(img, cmap='gray')
            axes[row, col].set_title(f"Label: {y[idx]}", fontsize=8)
            axes[row, col].axis('off')
        except Exception as e:
            st.warning(f"L·ªói khi hi·ªÉn th·ªã ·∫£nh: {e}")
    st.pyplot(fig)
    plt.close()

# ----------- Ph√¢n ph·ªëi pixel ----------------
def analyze_pixel_distribution(X_flat):
    st.subheader("üìà Ph√¢n ph·ªëi Gi√° tr·ªã Pixel")
    plt.figure(figsize=(10, 4))

    # Tr∆∞·ªõc chu·∫©n h√≥a
    plt.subplot(1, 2, 1)
    plt.hist(X_flat.flatten(), bins=50, color='blue', alpha=0.7)
    plt.title('Ph√¢n ph·ªëi g·ªëc')
    plt.xlabel('Pixel')
    plt.ylabel('T·∫ßn su·∫•t')

    # Sau chu·∫©n h√≥a
    scaler = MinMaxScaler()
    scaled = scaler.fit_transform(X_flat)

    plt.subplot(1, 2, 2)
    plt.hist(scaled.flatten(), bins=50, color='green', alpha=0.7)
    plt.title('Sau chu·∫©n h√≥a')
    plt.xlabel('Pixel (0-1)')

    plt.tight_layout()
    st.pyplot(plt)
    plt.close()

# ----------- Main App ----------------
def main():
    st.set_page_config(page_title="Alphabet Image Preprocessing", layout="wide")
    st.title("üî† Ti·ªÅn X·ª≠ l√Ω & Hu·∫•n luy·ªán ·∫¢nh Ch·ªØ c√°i")
    show_explanations()

    # Upload file
    with st.expander("üì§ T·∫£i l√™n D·ªØ li·ªáu", expanded=True):
        col1, col2 = st.columns(2)
        with col1:
            X_file = st.file_uploader("Ch·ªçn file ·∫£nh (.npy)", type="npy")
        with col2:
            y_file = st.file_uploader("Ch·ªçn file nh√£n (.npy)", type="npy")

    if X_file and y_file:
        try:
            X = np.load(X_file)
            y = np.load(y_file).astype(str)

            if len(X) != len(y):
                st.error("‚ùå S·ªë l∆∞·ª£ng ·∫£nh v√† nh√£n kh√¥ng kh·ªõp.")
                return
            if X.shape[1:] != (28, 28):
                st.error("‚ö†Ô∏è ·∫¢nh c·∫ßn c√≥ k√≠ch th∆∞·ªõc (28x28).")
                return

            st.subheader("üì¶ Th√¥ng tin Dataset")
            st.write(f"S·ªë m·∫´u: {len(X)}")
            st.write(f"K√≠ch th∆∞·ªõc ·∫£nh: {X.shape[1:]}")

            display_sample_images(X, y)

            X_flat = X.reshape(X.shape[0], -1)
            analyze_pixel_distribution(X_flat)

            # Label encoding & normalization
            le = LabelEncoder()
            y_encoded = le.fit_transform(y)
            scaler = MinMaxScaler()
            X_scaled = scaler.fit_transform(X_flat)

            df = pd.DataFrame(X_scaled)
            df['label'] = y_encoded

            # Tabs
            tab1, tab2, tab3, tab4 = st.tabs(["üìä D·ªØ li·ªáu", "üî§ Nh√£n", "üìà Ph√¢n ph·ªëi", "üß† Hu·∫•n luy·ªán"])

            with tab1:
                st.dataframe(df.head(), use_container_width=True)

            with tab2:
                st.dataframe(pd.DataFrame({"K√Ω t·ª±": le.classes_, "M√£ s·ªë": le.transform(le.classes_)}))

            with tab3:
                st.write("Ph√¢n ph·ªëi l·ªõp:")
                class_dist = pd.Series(y).value_counts().reset_index()
                class_dist.columns = ['K√Ω t·ª±', 'S·ªë l∆∞·ª£ng']
                st.bar_chart(class_dist.set_index('K√Ω t·ª±'))

            with tab4:
                st.subheader("üîß C·∫•u h√¨nh Hu·∫•n luy·ªán")
                model_type = st.selectbox("Ch·ªçn m√¥ h√¨nh", ["Logistic Regression", "KNN"])
                test_size = st.slider("T·ªâ l·ªá Test", 0.1, 0.5, 0.2, step=0.05)

                if model_type == "KNN":
                    n_neighbors = st.slider("S·ªë l√°ng gi·ªÅng (K)", 1, 15, 3)

                if st.button("üöÄ B·∫Øt ƒë·∫ßu Hu·∫•n luy·ªán"):
                    X_train, X_test, y_train, y_test = train_test_split(
                        X_scaled, y_encoded, test_size=test_size, random_state=42)

                    model = (LogisticRegression(max_iter=1000)
                             if model_type == "Logistic Regression"
                             else KNeighborsClassifier(n_neighbors=n_neighbors))

                    model.fit(X_train, y_train)
                    y_pred = model.predict(X_test)
                    acc = accuracy_score(y_test, y_pred)
                    st.success(f"üéØ ƒê·ªô ch√≠nh x√°c: {acc*100:.2f}%")

                    # Confusion matrix
                    cm = confusion_matrix(y_test, y_pred)
                    labels_present = le.inverse_transform(np.unique(y_test))
                    fig, ax = plt.subplots(figsize=(8, 6))
                    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels_present)
                    disp.plot(ax=ax, cmap='Blues')
                    st.pyplot(fig)
                    plt.close()

                    # D·ª± ƒëo√°n ·∫£nh m·ªõi
                    st.subheader("üîç D·ª± ƒëo√°n ·∫¢nh M·ªõi")
                    uploaded = st.file_uploader("T·∫£i ·∫£nh .npy ƒë·ªÉ d·ª± ƒëo√°n", type="npy")
                    if uploaded:
                        new_img = np.load(uploaded)
                        if new_img.shape == (28, 28):
                            new_flat = new_img.reshape(1, -1)
                            new_scaled = scaler.transform(new_flat)
                            pred = model.predict(new_scaled)
                            st.image(new_img, caption="·∫¢nh nh·∫≠p", width=150)
                            st.success(f"‚úÖ D·ª± ƒëo√°n: {le.inverse_transform(pred)[0]}")
                        else:
                            st.error("‚ö†Ô∏è ·∫¢nh ph·∫£i c√≥ k√≠ch th∆∞·ªõc 28x28.")

            # Download
            st.download_button("üì• T·∫£i dataset ƒë√£ x·ª≠ l√Ω", df.to_csv(index=False).encode(), "processed.csv", "text/csv")

        except Exception as e:
            st.error(f"‚ö†Ô∏è L·ªói x·ª≠ l√Ω: {str(e)}")

    else:
        st.info("üìå Vui l√≤ng t·∫£i l√™n c·∫£ ·∫£nh v√† nh√£n ƒë·ªÉ b·∫Øt ƒë·∫ßu.")

if __name__ == "__main__":
    main()
